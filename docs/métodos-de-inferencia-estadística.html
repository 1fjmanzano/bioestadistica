<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4.7 Métodos de Inferencia Estadística | Curso de Bioestadística</title>
  <meta name="description" content="4.7 Métodos de Inferencia Estadística | Curso de Bioestadística" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="4.7 Métodos de Inferencia Estadística | Curso de Bioestadística" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4.7 Métodos de Inferencia Estadística | Curso de Bioestadística" />
  
  
  

<meta name="author" content="Javier Manzano" />


<meta name="date" content="2022-08-18" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="contrastes-paramétricos-y-no-paramétricos.html"/>

<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Curso de Bioestadística</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introducción</a>
<ul>
<li class="chapter" data-level="1.1" data-path="prácticas-con-excel.html"><a href="prácticas-con-excel.html"><i class="fa fa-check"></i><b>1.1</b> Prácticas con Excel©</a></li>
<li class="chapter" data-level="1.2" data-path="prácticas-con-rstudio.html"><a href="prácticas-con-rstudio.html"><i class="fa fa-check"></i><b>1.2</b> Prácticas con RStudio</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html"><i class="fa fa-check"></i><b>2</b> Análisis Exploratorio de Datos</a>
<ul>
<li class="chapter" data-level="2.1" data-path="conceptos-previos.html"><a href="conceptos-previos.html"><i class="fa fa-check"></i><b>2.1</b> Conceptos previos</a></li>
<li class="chapter" data-level="2.2" data-path="tipos-de-variables.html"><a href="tipos-de-variables.html"><i class="fa fa-check"></i><b>2.2</b> Tipos de variables</a></li>
<li class="chapter" data-level="2.3" data-path="tablas-de-frecuencias.html"><a href="tablas-de-frecuencias.html"><i class="fa fa-check"></i><b>2.3</b> Tablas de frecuencias</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="tablas-de-frecuencias.html"><a href="tablas-de-frecuencias.html#tabla-de-frecuencias-práctica-con-excel"><i class="fa fa-check"></i><b>2.3.1</b> Tabla de frecuencias (Práctica con Excel©)</a></li>
<li class="chapter" data-level="2.3.2" data-path="tablas-de-frecuencias.html"><a href="tablas-de-frecuencias.html#tabla-de-frecuencias-práctica-con-r"><i class="fa fa-check"></i><b>2.3.2</b> Tabla de frecuencias (Práctica con R)</a></li>
<li class="chapter" data-level="2.3.3" data-path="tablas-de-frecuencias.html"><a href="tablas-de-frecuencias.html#tablas-de-frecuencias-práctica-2con-excel"><i class="fa fa-check"></i><b>2.3.3</b> Tablas de frecuencias (Práctica 2con Excel©)</a></li>
<li class="chapter" data-level="2.3.4" data-path="tablas-de-frecuencias.html"><a href="tablas-de-frecuencias.html#tablas-de-frecuencias-práctica-3-con-excel"><i class="fa fa-check"></i><b>2.3.4</b> Tablas de frecuencias (Práctica 3 con Excel© )</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="números-índices.html"><a href="números-índices.html"><i class="fa fa-check"></i><b>2.4</b> Números índices</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="números-índices.html"><a href="números-índices.html#números-índices-práctica-con-excel"><i class="fa fa-check"></i><b>2.4.1</b> Números índices (Práctica con Excel©)</a></li>
<li class="chapter" data-level="2.4.2" data-path="números-índices.html"><a href="números-índices.html#números-índices-práctica-con-r"><i class="fa fa-check"></i><b>2.4.2</b> Números índices (Práctica con R)</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="representaciones-gráficas.html"><a href="representaciones-gráficas.html"><i class="fa fa-check"></i><b>2.5</b> Representaciones gráficas</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="representaciones-gráficas.html"><a href="representaciones-gráficas.html#introduccción"><i class="fa fa-check"></i><b>2.5.1</b> Introduccción</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="diagramas-de-barras-y-sectores.html"><a href="diagramas-de-barras-y-sectores.html"><i class="fa fa-check"></i><b>2.6</b> Diagramas de barras y sectores</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="diagramas-de-barras-y-sectores.html"><a href="diagramas-de-barras-y-sectores.html#diagramas-de-barras-y-sectores-práctica-con-excel"><i class="fa fa-check"></i><b>2.6.1</b> Diagramas de barras y sectores (Práctica con Excel©)</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="histogramas.html"><a href="histogramas.html"><i class="fa fa-check"></i><b>2.7</b> Histogramas</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="histogramas.html"><a href="histogramas.html#histogramas-con-excel-prácticas"><i class="fa fa-check"></i><b>2.7.1</b> Histogramas con Excel© (Prácticas)</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="otros-gráficos.html"><a href="otros-gráficos.html"><i class="fa fa-check"></i><b>2.8</b> Otros gráficos</a></li>
<li class="chapter" data-level="2.9" data-path="medidas-de-posición-dispersión-y-forma.html"><a href="medidas-de-posición-dispersión-y-forma.html"><i class="fa fa-check"></i><b>2.9</b> Medidas de posición, dispersión y forma</a>
<ul>
<li class="chapter" data-level="2.9.1" data-path="medidas-de-posición-dispersión-y-forma.html"><a href="medidas-de-posición-dispersión-y-forma.html#medidas-de-posición-centrales"><i class="fa fa-check"></i><b>2.9.1</b> Medidas de posición centrales</a></li>
<li class="chapter" data-level="2.9.2" data-path="medidas-de-posición-dispersión-y-forma.html"><a href="medidas-de-posición-dispersión-y-forma.html#medidas-centrales-práctica"><i class="fa fa-check"></i><b>2.9.2</b> Medidas centrales (Práctica)</a></li>
<li class="chapter" data-level="2.9.3" data-path="medidas-de-posición-dispersión-y-forma.html"><a href="medidas-de-posición-dispersión-y-forma.html#medidas-de-posición-no-centrales"><i class="fa fa-check"></i><b>2.9.3</b> Medidas de posición no centrales</a></li>
<li class="chapter" data-level="2.9.4" data-path="medidas-de-posición-dispersión-y-forma.html"><a href="medidas-de-posición-dispersión-y-forma.html#medidas-no-centrales-práctica"><i class="fa fa-check"></i><b>2.9.4</b> Medidas no centrales (Práctica)</a></li>
<li class="chapter" data-level="2.9.5" data-path="medidas-de-posición-dispersión-y-forma.html"><a href="medidas-de-posición-dispersión-y-forma.html#medidas-de-dispersión"><i class="fa fa-check"></i><b>2.9.5</b> Medidas de dispersión</a></li>
<li class="chapter" data-level="2.9.6" data-path="medidas-de-posición-dispersión-y-forma.html"><a href="medidas-de-posición-dispersión-y-forma.html#medidas-de-dispersión-práctica"><i class="fa fa-check"></i><b>2.9.6</b> Medidas de dispersión (Práctica)</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="normalización-de-datos.html"><a href="normalización-de-datos.html"><i class="fa fa-check"></i><b>2.10</b> Normalización de datos</a>
<ul>
<li class="chapter" data-level="2.10.1" data-path="normalización-de-datos.html"><a href="normalización-de-datos.html#normalización-de-datos-práctica"><i class="fa fa-check"></i><b>2.10.1</b> Normalización de datos (Práctica)</a></li>
</ul></li>
<li class="chapter" data-level="2.11" data-path="medidas-de-forma.html"><a href="medidas-de-forma.html"><i class="fa fa-check"></i><b>2.11</b> Medidas de forma</a></li>
<li class="chapter" data-level="2.12" data-path="análisis-de-datos-con-excel-práctica.html"><a href="análisis-de-datos-con-excel-práctica.html"><i class="fa fa-check"></i><b>2.12</b> Análisis de datos con Excel© (Práctica)</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="relación-entre-variables.html"><a href="relación-entre-variables.html"><i class="fa fa-check"></i><b>3</b> Relación entre variables</a>
<ul>
<li class="chapter" data-level="3.1" data-path="relación-entre-variables-numéricas.html"><a href="relación-entre-variables-numéricas.html"><i class="fa fa-check"></i><b>3.1</b> Relación entre variables numéricas</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="relación-entre-variables-numéricas.html"><a href="relación-entre-variables-numéricas.html#diagramas-de-dispersión"><i class="fa fa-check"></i><b>3.1.1</b> Diagramas de dispersión</a></li>
<li class="chapter" data-level="3.1.2" data-path="relación-entre-variables-numéricas.html"><a href="relación-entre-variables-numéricas.html#covarianza"><i class="fa fa-check"></i><b>3.1.2</b> Covarianza</a></li>
<li class="chapter" data-level="3.1.3" data-path="relación-entre-variables-numéricas.html"><a href="relación-entre-variables-numéricas.html#coeficiente-de-correlación"><i class="fa fa-check"></i><b>3.1.3</b> Coeficiente de correlación</a></li>
<li class="chapter" data-level="3.1.4" data-path="relación-entre-variables-numéricas.html"><a href="relación-entre-variables-numéricas.html#correlación-entre-2-variables-numéricas-práctica"><i class="fa fa-check"></i><b>3.1.4</b> Correlación entre 2 variables numéricas (Práctica)</a></li>
<li class="chapter" data-level="3.1.5" data-path="relación-entre-variables-numéricas.html"><a href="relación-entre-variables-numéricas.html#regresión-lineal"><i class="fa fa-check"></i><b>3.1.5</b> Regresión lineal</a></li>
<li class="chapter" data-level="3.1.6" data-path="relación-entre-variables-numéricas.html"><a href="relación-entre-variables-numéricas.html#regresión-práctica"><i class="fa fa-check"></i><b>3.1.6</b> Regresión (Práctica)</a></li>
<li class="chapter" data-level="3.1.7" data-path="relación-entre-variables-numéricas.html"><a href="relación-entre-variables-numéricas.html#regresión-lineal-múltiple"><i class="fa fa-check"></i><b>3.1.7</b> Regresión lineal múltiple</a></li>
<li class="chapter" data-level="3.1.8" data-path="relación-entre-variables-numéricas.html"><a href="relación-entre-variables-numéricas.html#regresión-múltiple-práctica"><i class="fa fa-check"></i><b>3.1.8</b> Regresión múltiple (Práctica)</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="relación-entre-variable-numérica-y-cualitativa.html"><a href="relación-entre-variable-numérica-y-cualitativa.html"><i class="fa fa-check"></i><b>3.2</b> Relación entre variable numérica y cualitativa</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="relación-entre-variable-numérica-y-cualitativa.html"><a href="relación-entre-variable-numérica-y-cualitativa.html#relación-entre-variable-cualitativa-y-numérica-práctica"><i class="fa fa-check"></i><b>3.2.1</b> Relación entre variable cualitativa y numérica (Práctica)</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="relación-entre-variables-cualitativas.html"><a href="relación-entre-variables-cualitativas.html"><i class="fa fa-check"></i><b>3.3</b> Relación entre variables cualitativas</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="relación-entre-variables-cualitativas.html"><a href="relación-entre-variables-cualitativas.html#tablas-de-contingencia"><i class="fa fa-check"></i><b>3.3.1</b> Tablas de contingencia</a></li>
<li class="chapter" data-level="3.3.2" data-path="relación-entre-variables-cualitativas.html"><a href="relación-entre-variables-cualitativas.html#diagrama-de-barras-agrupadas"><i class="fa fa-check"></i><b>3.3.2</b> Diagrama de barras agrupadas</a></li>
<li class="chapter" data-level="3.3.3" data-path="relación-entre-variables-cualitativas.html"><a href="relación-entre-variables-cualitativas.html#gráficos-de-rectángulos-para-comparar-variables-cuantitativas"><i class="fa fa-check"></i><b>3.3.3</b> Gráficos de rectángulos para comparar variables cuantitativas</a></li>
<li class="chapter" data-level="3.3.4" data-path="relación-entre-variables-cualitativas.html"><a href="relación-entre-variables-cualitativas.html#gráficos-o-diagramas-de-rectángulos-práctica"><i class="fa fa-check"></i><b>3.3.4</b> Gráficos o diagramas de rectángulos (Práctica)</a></li>
<li class="chapter" data-level="3.3.5" data-path="relación-entre-variables-cualitativas.html"><a href="relación-entre-variables-cualitativas.html#diagnóstico-clínico"><i class="fa fa-check"></i><b>3.3.5</b> Diagnóstico clínico</a></li>
<li class="chapter" data-level="3.3.6" data-path="relación-entre-variables-cualitativas.html"><a href="relación-entre-variables-cualitativas.html#curvas-roc-receiver-operating-characteristic-curve"><i class="fa fa-check"></i><b>3.3.6</b> Curvas ROC (Receiver Operating characteristic Curve)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="inferencia-estadística.html"><a href="inferencia-estadística.html"><i class="fa fa-check"></i><b>4</b> Inferencia Estadística</a>
<ul>
<li class="chapter" data-level="4.1" data-path="métodos-de-muestreo.html"><a href="métodos-de-muestreo.html"><i class="fa fa-check"></i><b>4.1</b> Métodos de muestreo</a></li>
<li class="chapter" data-level="4.2" data-path="valor-p.html"><a href="valor-p.html"><i class="fa fa-check"></i><b>4.2</b> Valor p</a></li>
<li class="chapter" data-level="4.3" data-path="distribuciones-de-probabilidad.html"><a href="distribuciones-de-probabilidad.html"><i class="fa fa-check"></i><b>4.3</b> Distribuciones de probabilidad</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="distribuciones-de-probabilidad.html"><a href="distribuciones-de-probabilidad.html#distribución-normal"><i class="fa fa-check"></i><b>4.3.1</b> Distribución normal</a></li>
<li class="chapter" data-level="4.3.2" data-path="distribuciones-de-probabilidad.html"><a href="distribuciones-de-probabilidad.html#normalidad-de-los-datos"><i class="fa fa-check"></i><b>4.3.2</b> Normalidad de los datos</a></li>
<li class="chapter" data-level="4.3.3" data-path="distribuciones-de-probabilidad.html"><a href="distribuciones-de-probabilidad.html#normalidad-de-los-datos-práctica"><i class="fa fa-check"></i><b>4.3.3</b> Normalidad de los datos (Práctica)</a></li>
<li class="chapter" data-level="4.3.4" data-path="distribuciones-de-probabilidad.html"><a href="distribuciones-de-probabilidad.html#distribución-z"><i class="fa fa-check"></i><b>4.3.4</b> Distribución Z</a></li>
<li class="chapter" data-level="4.3.5" data-path="distribuciones-de-probabilidad.html"><a href="distribuciones-de-probabilidad.html#cálculo-del-valor-p-práctica"><i class="fa fa-check"></i><b>4.3.5</b> Cálculo del valor p (Práctica)</a></li>
<li class="chapter" data-level="4.3.6" data-path="distribuciones-de-probabilidad.html"><a href="distribuciones-de-probabilidad.html#distribución-t-de-student"><i class="fa fa-check"></i><b>4.3.6</b> Distribución t de Student</a></li>
<li class="chapter" data-level="4.3.7" data-path="distribuciones-de-probabilidad.html"><a href="distribuciones-de-probabilidad.html#distribución-chi2-chi-cuadrado-o-ji.cuadrado"><i class="fa fa-check"></i><b>4.3.7</b> Distribución <span class="math inline">\(\chi^2\)</span> (chi-cuadrado o ji.cuadrado)</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="estimación-de-parámetros.-intervalos-de-confianza.html"><a href="estimación-de-parámetros.-intervalos-de-confianza.html"><i class="fa fa-check"></i><b>4.4</b> Estimación de parámetros. Intervalos de confianza</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="estimación-de-parámetros.-intervalos-de-confianza.html"><a href="estimación-de-parámetros.-intervalos-de-confianza.html#intervalo-de-confianza-para-la-media"><i class="fa fa-check"></i><b>4.4.1</b> Intervalo de confianza para la media</a></li>
<li class="chapter" data-level="4.4.2" data-path="estimación-de-parámetros.-intervalos-de-confianza.html"><a href="estimación-de-parámetros.-intervalos-de-confianza.html#intervalo-de-confianza-para-la-media-práctica"><i class="fa fa-check"></i><b>4.4.2</b> Intervalo de confianza para la media (Práctica)</a></li>
<li class="chapter" data-level="4.4.3" data-path="estimación-de-parámetros.-intervalos-de-confianza.html"><a href="estimación-de-parámetros.-intervalos-de-confianza.html#intervalo-de-confianza-para-una-proporción"><i class="fa fa-check"></i><b>4.4.3</b> Intervalo de confianza para una proporción</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html"><i class="fa fa-check"></i><b>4.5</b> Contrastes de Hipótesis</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#contrastes-bilaterales-y-unilaterales"><i class="fa fa-check"></i><b>4.5.1</b> Contrastes bilaterales y unilaterales</a></li>
<li class="chapter" data-level="4.5.2" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#nivel-de-confianza-y-potencia-estadística"><i class="fa fa-check"></i><b>4.5.2</b> Nivel de confianza y potencia estadística</a></li>
<li class="chapter" data-level="4.5.3" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#tamaño-de-la-muestra"><i class="fa fa-check"></i><b>4.5.3</b> Tamaño de la muestra</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="contrastes-paramétricos-y-no-paramétricos.html"><a href="contrastes-paramétricos-y-no-paramétricos.html"><i class="fa fa-check"></i><b>4.6</b> Contrastes paramétricos y no paramétricos</a></li>
<li class="chapter" data-level="4.7" data-path="métodos-de-inferencia-estadística.html"><a href="métodos-de-inferencia-estadística.html"><i class="fa fa-check"></i><b>4.7</b> Métodos de Inferencia Estadística</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="métodos-de-inferencia-estadística.html"><a href="métodos-de-inferencia-estadística.html#test-de-student-para-muestras-independientes"><i class="fa fa-check"></i><b>4.7.1</b> Test de Student para muestras independientes</a></li>
<li class="chapter" data-level="4.7.2" data-path="métodos-de-inferencia-estadística.html"><a href="métodos-de-inferencia-estadística.html#t-test-práctica"><i class="fa fa-check"></i><b>4.7.2</b> t-test (Práctica)</a></li>
<li class="chapter" data-level="4.7.3" data-path="métodos-de-inferencia-estadística.html"><a href="métodos-de-inferencia-estadística.html#prueba-de-mann-whitney"><i class="fa fa-check"></i><b>4.7.3</b> Prueba de Mann-Whitney</a></li>
<li class="chapter" data-level="4.7.4" data-path="métodos-de-inferencia-estadística.html"><a href="métodos-de-inferencia-estadística.html#anova-de-un-factor"><i class="fa fa-check"></i><b>4.7.4</b> Anova de un factor</a></li>
<li class="chapter" data-level="4.7.5" data-path="métodos-de-inferencia-estadística.html"><a href="métodos-de-inferencia-estadística.html#prueba-de-kruskal-wallis"><i class="fa fa-check"></i><b>4.7.5</b> Prueba de Kruskal-Wallis</a></li>
<li class="chapter" data-level="4.7.6" data-path="métodos-de-inferencia-estadística.html"><a href="métodos-de-inferencia-estadística.html#test-de-student-para-muestras-relacionadas"><i class="fa fa-check"></i><b>4.7.6</b> Test de Student para muestras relacionadas</a></li>
<li class="chapter" data-level="4.7.7" data-path="métodos-de-inferencia-estadística.html"><a href="métodos-de-inferencia-estadística.html#t-test-emparejadas-práctica"><i class="fa fa-check"></i><b>4.7.7</b> t-test emparejadas (Práctica)</a></li>
<li class="chapter" data-level="4.7.8" data-path="métodos-de-inferencia-estadística.html"><a href="métodos-de-inferencia-estadística.html#prueba-de-rangos-con-signo-de-wilcoxon"><i class="fa fa-check"></i><b>4.7.8</b> Prueba de rangos con signo de Wilcoxon</a></li>
<li class="chapter" data-level="4.7.9" data-path="métodos-de-inferencia-estadística.html"><a href="métodos-de-inferencia-estadística.html#test-de-correlación-r"><i class="fa fa-check"></i><b>4.7.9</b> Test de correlación r</a></li>
<li class="chapter" data-level="4.7.10" data-path="métodos-de-inferencia-estadística.html"><a href="métodos-de-inferencia-estadística.html#correlación-de-spearman"><i class="fa fa-check"></i><b>4.7.10</b> Correlación de Spearman</a></li>
<li class="chapter" data-level="4.7.11" data-path="métodos-de-inferencia-estadística.html"><a href="métodos-de-inferencia-estadística.html#prueba-de-la-chi-cuadrado"><i class="fa fa-check"></i><b>4.7.11</b> Prueba de la chi-cuadrado</a></li>
<li class="chapter" data-level="4.7.12" data-path="métodos-de-inferencia-estadística.html"><a href="métodos-de-inferencia-estadística.html#prueba-chi2-práctica"><i class="fa fa-check"></i><b>4.7.12</b> Prueba <span class="math inline">\(\chi^2\)</span> (Práctica)</a></li>
<li class="chapter" data-level="4.7.13" data-path="métodos-de-inferencia-estadística.html"><a href="métodos-de-inferencia-estadística.html#prueba-exacta-de-fisher"><i class="fa fa-check"></i><b>4.7.13</b> Prueba exacta de Fisher</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Curso de Bioestadística</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="métodos-de-inferencia-estadística" class="section level2" number="4.7">
<h2><span class="header-section-number">4.7</span> Métodos de Inferencia Estadística</h2>
<p>Vamos a ver las técnicas de Inferencia Estadística más utilizadas en los problemas de relación entre variables. Se pretende que, dado un problema concreto, el alumno sea capaz de identificar el procedimiento estadístico a seguir, aplicarlo e interpretar los resultados. Veremos ejemplos concretos y sencillos para cada uno de los métodos presentados que, evidentemente, no son todos los existentes pero pueden ser suficientes en la gran mayoría de casos.</p>
<p>La siguiente tabla puede servirnos como resumen de los métodos y como guión a seguir durante ste apartadolo. Presentamos el método paramétrico así como su equivalente no paramétrico.</p>
<p><img src="img/4.7_tabla.png" width="601" /></p>
<div id="test-de-student-para-muestras-independientes" class="section level3" number="4.7.1">
<h3><span class="header-section-number">4.7.1</span> Test de Student para muestras independientes</h3>
<p>También conocido como <strong>t-test</strong>, es posiblemente el más utilizado en Bioestadística. Se utiliza para tratar de determinar si existe una relación significativa entre una variable cualitativa binaria (como, por ejemplo, estar sano o enfermo, ser tratado o no tratado) y una variable numérica (glucemia, presión arterial, etc)
.
El problema de relación entre ambas variables se traduce en un problema de comparación de las medias poblacionales de la variable numérica, <span class="math inline">\(\mu_1\)</span> y<span class="math inline">\(\mu_2\)</span>, correspondientes a cada una de las categorías consideradas. Es decir, la hipótesis inicial a contrastar es:</p>
<p><span class="math inline">\(H_0:\mu_1=\mu_2\)</span></p>
<p>Si seleccionamos de manera independiente sendas muestras aleatorias para cada categoría,el algoritmo al que se someten los datos se denomina <strong>test de Student para muestras independientes</strong>.</p>
<p>A pesar de la sencillez y utilidad del t-test, para que sus resultados sean válidos es necesario que se cumplan una serie de condiciones, entre las que se encuentran:</p>
<ul>
<li><p>Independencia: Las observaciones tienen que ser independientes las unas de las otras. Para ello, el muestreo debe ser aleatorio y el tamaño de la muestra inferior al 10% de la población.</p></li>
<li><p>Normalidad: Las poblaciones que se comparan tienen que seguir una distribución normal. Si bien la condición de normalidad recae sobre las poblaciones, no se suele disponer de información sobre ellas, por lo que se emplean las muestras (dado que son reflejo de la población) para determinarlo. En caso de cierta asimetría, los t-test son considerablemente robustos si el tamaño de las muestras es mayor o igual a 30.</p></li>
<li><p>Igualdad de varianza (<strong>homocedasticidad</strong>): la varianza de las poblaciones comparadas debe de ser igual. Tal como ocurre con la condición de normalidad, si no se dispone de información de las poblaciones, esta condición se ha de asumir a partir de las muestras.</p></li>
</ul>
<p>En caso de no cumplirse esta condición se puede emplear otra prueba como un Welch Two Sample t-test, que incorpora una corrección a través de los grados de libertad que compensa la diferencia de varianzas, con el inconveniente de que pierde poder estadístico.</p>
<p>Consideramos el siguiente ejemplo con 2 pares de muestras (A1, B1) y (A2, B2). Representadas mediante diagramas de cajas y bigotes:</p>
<p><img src="img/4.7.1_grph.png" width="609" /></p>
<p>Observamos que en el primer ejemplo con las variables A1, B1, no se observa diferencia significativa entre ambas mientras que en el segundo ejemplo con los datos A2, B2, al menos por término medio (y mediano), parece que hay diferencia. Vamos analizar si esa diferencia apreciada en la segunda muestra concreta es significativa.</p>
<p>Inicialmente, supondremos que ambas variables no guardan relación (<span class="math inline">\(\mu_A\)</span> = <span class="math inline">\(\mu_b\)</span>) y evaluaremos si la muestra estudiada contradice claramente dicha suposición.</p>
<p>Según el modelo inicial las medias muestrales <span class="math inline">\(\overline{x}_A\)</span> y <span class="math inline">\(\overline{x}_B\)</span> deberían ser parecidas, es decir, la diferencia (en bruto) <span class="math inline">\(\overline{x}_A\)</span> - <span class="math inline">\(\overline{x}_B\)</span> debería ser prácticamente nula (~ 0).</p>
<p>Obviamente, no podemos exigir que sea exactamente igual a 0 porque debemos asumir diferencias entre las muestras debidas exclusivamente al azar inherente al muestreo. El problema es cuantificar qué estamos dispuestos a achacar al azar, lo cual es un problema de Cálculo de Probabilidades. Para ello elegimos el estadístico de contraste. Concretamente, según el modelo inicial, la diferencia de medias muestrales debería seguir un modelo de distribución normal de media 0,de manera que, al tipificarlo, la diferencia de medias muestrales debería seguir una distribución N(0,1).</p>
<p>De esta forma, obtenemos el valor del estadístico de contraste <span class="math inline">\(t_{exp}\)</span> como:</p>
<p><span class="math inline">\(t_{exp}=\frac{\overline{x}_A- \overline{x}_B}{\sqrt{\frac{\sigma_A^2}{n_A}+\frac{\sigma_B^2}{n_B}}}\)</span></p>
<p>Este valor recoge toda la información que aporta la muestra estudiada en lo referente a la hiopótesis nula del contraste de la hipótesis</p>
<p><span class="math inline">\(H_0: \mu_1=\mu_2\)</span></p>
<p>De hecho, su valor absoluto se entiende como una distancia (tipificada) entre las dos medias muestrales que, bajo la hipótesis <span class="math inline">\(H_0: \mu_1=\mu_2\)</span>, debería ser pequeña. Más concretamente, debería ajustarse a un modelo de distribución N(0,1).</p>
<p>El valor p se define en este problema concreto como la probabilidad, según N(0,1), de obtener una distancia (tipificada) entre medias aritméticas al menos tan grande como la observada en la muestra. En otras palabras, el valor p es el área de las colas (contraste bilateral) que determinan | $t_{exp}| y -| $t_{exp}|</p>
<p><img src="img/4.7.1_texp.png" width="433" /></p>
<p>lo cual expresa en qué medida es verosímil la muestra según <span class="math inline">\(H_0\)</span>.</p>
<p>En nuestros ejemplos, obtenemos el valor del estadístico de contraste y el valor p asociado:</p>
<p><img src="img/4.7.1_valorp.png" width="604" /></p>
<p>Así, para A2, B2, el resultado es significativo (valor p &lt; 0,05), es decir, se opta por la hipótesis alternativa <span class="math inline">\(H_1:\mu_{A2} \neq \mu_{B2}\)</span> son distintas como habíamos intuído a la vista de los diagramas de cajas y bigotes.</p>
<p>Sin embargo, para A1, B1, el valor <span class="math inline">\(t_{exp}\)</span> indica una escasa diferencia entre las medias muestrales, sería verosímil desde el punto de vista de la hipótesis inicial <span class="math inline">\(H_0:\mu_{A1=\mu_{B1}}\)</span> asociándose a un valor p alto (0,2898 &gt; 0,05) según la distribución N(0,1). Se entendería entonces que la muestra es compatible con la hipótesis inicial y, en definitiva, no hay diferencia entre las medias.</p>
<p>Con la hoja de cálculo Excel® tenemos los resultados de la prueba que nos da el valor del estadístico t y el valor p así como el valor crítico de t tanto para una cola como para dos colas para una confianza del 95%. En nuestro caso, hemos supuesto que el contraste es bilateral (<span class="math inline">\(H_0:\mu_1=\mu_2\)</span>) por lo que tenemos que mirar el resultado para dos colas.</p>
<p><img src="img/4.7.1_excel.png" width="603" /></p>
</div>
<div id="t-test-práctica" class="section level3" number="4.7.2">
<h3><span class="header-section-number">4.7.2</span> t-test (Práctica)</h3>
<p>Para realizar esta práctica, debe tener descargado en su ordenador el archivo <a href="https://github.com/1fjmanzano/bioestadistica/blob/master/3.practicas.xlsx">3.practicas.xlsx</a> y abrir la hoja/pestaña correspondiente.</p>
<p>En el siguente vídeo se muestran los pasos para realizar la práctica.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/RokI2Ec8gtM" frameborder="0" allow="accelerometer; autoplay; encrypted-media;
  gyroscope; picture-in-picture" allowfullscreen>
</iframe>
</div>
<div id="prueba-de-mann-whitney" class="section level3" number="4.7.3">
<h3><span class="header-section-number">4.7.3</span> Prueba de Mann-Whitney</h3>
<p>Es una alternativa no paramétrica al test de Student que no exige la normalidad de la variable estudiada y que es, por lo tanto, de especial utilidad con muestras pequeñas. Se conoce también como la prueba de la ​suma de rangos de Wilcoxon (Wilcoxon Sum Rank Test). Básicamente consiste en una comparación de los rangos o posiciones promedios de la variable numérica en función de las categorías consideradas. En este caso, se utiliza la mediana en vez de la media.</p>
<p>Se establece como hipótesis nula que las dos muestras son iguales.</p>
<p>La idea en la que se fundamenta este test es la siguiente: si las dos muestras comparadas proceden de la misma población, al juntar todas las observaciones y ordenarlas de menor a mayor, cabría esperar que las observaciones de una y otra muestra estuviesen intercaladas aleatoriamente. Por lo contrario, si una de las muestras pertenece a una población con valores mayores o menores que la otra población, al ordenar las observaciones, estas tenderán a agruparse de modo que las de una muestra queden por encima de las de la otra.</p>
<p>Consideremos como ejemplo un ensayo clínico de Fase II diseñado para investigar la efectividad de un nuevo medicamento para reducir los síntomas del asma en niños. Un total de n = 10 participantes se asignaron al azar para recibir el nuevo medicamento o un placebo. Se les pide a los participantes que registren la cantidad de episodios de falta de aliento durante un período de 1 semana después de recibir el tratamiento asignado. Los datos se muestran a continuación.</p>
<p><img src="img/4.7.3_datos.png" width="340" /></p>
<p>¿Hay alguna diferencia en el número de episodios de falta de aliento durante un período de 1 semana en los participantes que reciben el nuevo medicamento en comparación con los que recibieron el placebo?</p>
<p>A la vista de los datos, parece que los participantes que reciben el placebo tienen más episodios de dificultad respiratoria, pero ¿es esto estadísticamente significativo?</p>
<p>En este ejemplo, el resultado es un recuento y en esta muestra los datos no siguen una distribución normal. Además, el tamaño de la muestra es pequeño (<span class="math inline">\(n_1\)</span> = <span class="math inline">\(n_2\)</span> = 5) por lo que es apropiado usar una prueba no paramétrica.</p>
<p>Establecemos como hipótesis nula</p>
<p><span class="math inline">\(H_0\)</span> las dos muestras son iguales</p>
<p>y un nivel de confianza del 95% (es decir, <span class="math inline">\(\alpha\)</span> = 0.05).</p>
<p>Si la hipótesis nula es cierta (es decir, las dos poblaciones son iguales), esperamos ver un número similar de episodios de dificultad respiratoria en cada uno de los dos grupos de tratamiento y esperaríamos ver algunos participantes con pocos episodios y otros con más episodios en cada grupo. Este no parece ser el caso con los datos observados. Se necesita una prueba de hipótesis para determinar si los datos observados son evidencia de una diferencia estadísticamente significativa en las poblaciones
.
El primer paso es asignar rangos y para ello ordenamos los datos de menor a mayor. Esto se hace en la muestra total o combinada (es decir, agrupando los datos de los dos grupos de tratamiento (n = 10)), y asignando rangos de 1 a 10, de la siguiente manera:</p>
<p><img src="img/4.7.3_rangos.png" width="323" /></p>
<p>El rango 4.5 se corresponde al valor 4 de los 2 grupos. Serían los rangos 4 y 5 pero, al ser iguales, se toma como rango 4.5. Análogamente sucede con los rangos 7 y 8.</p>
<p>Vemos que los rangos inferiores (por ejemplo, 1, 2 y 3) se asignan a las respuestas en el nuevo grupo de medicamentos, mientras que los rangos más altos (por ejemplo, 9, 10) se asignan alas respuestas en el grupo de placebo. El objetivo de la prueba es determinar si los datos observados apoyan una diferencia en las poblaciones de respuestas.</p>
<p>En las pruebas paramétricas (analizadas en los módulos sobre pruebas de hipótesis), al comparar las medias entre dos grupos, analizamos la diferencia en las medias de la muestra en relación con su variabilidad y resumimos la información de la muestra en un estadístico de prueba. Un enfoque similar se emplea aquí. Específicamente, producimos una prueba basada en los rangos.</p>
<p>Primero, sumamos los rangos de cada grupo. Para el placebo, obtenemos una suma de 37 mientras que para el nuevo medicamento, obtenemos una suma de rangos de 18.
Como notación, llamamos 1 al grupo del placebo y 2 al grupo del nuevo medicamento. De este modo, si llamamos <span class="math inline">\(R_1\)</span> a la suma de rangos del grupo 1 (placebo) y <span class="math inline">\(R_2\)</span> a la suma de rangos del grupo 2 (nuevo medicamento), tenemos que <span class="math inline">\(R_1\)</span> = 37 y <span class="math inline">\(R_2\)</span> = 18.</p>
<p>Si la hipótesis nula fuese cierta ( las dos muestras son iguales), esperamos valores similares de
<span class="math inline">\(R_1\)</span> y <span class="math inline">\(R_2\)</span>.</p>
<p>En este ejemplo, los valores más bajos (rangos inferiores) se agrupan en el nuevo grupo de nuevo medicamento (grupo 2), mientras que los valores más altos (rangos más altos) se agrupan en el grupo de placebo (grupo 1). Sin embargo, ¿es la diferencia observada en las sumas de los rangos simplemente debido al azar?</p>
<p>Para responder esto, vamos a calcular un estadístico de prueba para resumir la información de la muestra y buscar el valor correspondiente en una distribución de probabilidad.</p>
<p>El estadístico de contraste para la prueba de Mann-Whitney se denota como U y es el valor más pequeño entre <span class="math inline">\(U_!\)</span> y <span class="math inline">\(U_2\)</span> definidos como:</p>
<p><span class="math inline">\(U_1=n_1\cdot n_2+\frac{n_1(n_1+1)}{2}-R_1\)</span></p>
<p><span class="math inline">\(U_2=n_1\cdot n_2+\frac{n_2(n_2+1)}{2}-R_1\)</span></p>
<p>En nuestro ejemplo:</p>
<p><span class="math inline">\(U_1=5\cdot 5+\frac{5\cdot6}{2}-37= 40 - 37 = 3\)</span></p>
<p><span class="math inline">\(U_2=5\cdot 5+\frac{5\cdot6}{2}-18 = 40-18=22\)</span></p>
<p>El valor del estadístico de contraste U es el menor de esos valores, es decir U = 3.</p>
<p>¿Es esta evidencia en apoyo de la hipótesis nula? Antes de abordar esta pregunta, consideramos el rango del estadístico de prueba U en dos casos extremos.</p>
<p><strong>Los dos grupos son diferentes</strong></p>
<p>En este caso, suponemos que los grupos son completamente diferentes. En nuestro ejemplo, esto implica que los 5 primeros rangos corresponden a un grupo y los otros 5 al otro, es decir, si todos los números más altos de episodios de dificultad respiratoria (y, por lo tanto, todos los rangos más altos) están en el grupo de placebo, y todos los números más bajos de episodios (y rangos) están en el nuevo grupo de fármacos, entonces:</p>
<p><span class="math inline">\(R_1= 6 + 7 + 8 + 9 + 10 = 40\)</span> y <span class="math inline">\(R_2= 1 + 2 + 3 + 4 + 5 = 15\)</span> .</p>
<p>de donde <span class="math inline">\(U_1= 40-40 =0\)</span> y <span class="math inline">\(U_2=40-15=25\)</span>.</p>
<p>Así U, el menor de esos valores, es 0 cuando hay una diferencia clara entre grupos.</p>
<p><strong>Los dos grupos son iguales</strong></p>
<p>El otro caso extremo es considerar que los grupos son exactamente iguales. Así, en nuestro ejemplo, si los rangos de 2, 4, 6, 8 y 10 se asignan a la cantidad de episodios de dificultad respiratoria en el grupo de placebo y los rangos de 1, 3, 5, 7 y 9 se asignan a la cantidad de episodios de insuficiencia en el grupo de nuevo medicamento, entonces:</p>
<p><span class="math inline">\(R_1= 2 + 4 + 6 + 8 + 10 = 30\)</span> y <span class="math inline">\(R_2= 1 + 3 + 5 + 7 + 9 = 25\)</span> .</p>
<p>de donde <span class="math inline">\(U_1=40-30=10\)</span> y <span class="math inline">\(U_2=40-25=15\)</span>.</p>
<p>Así U sería 10 cuando no hay una diferencia clara entre grupos.</p>
<p>Si tenemos en cuenta que en cada prueba, <span class="math inline">\(U_1\)</span> + <span class="math inline">\(U_2\)</span> es siempre igual a n​1 ·​ n​2,​ en el ejemplo anterior, U puede variar de 0 a 25 y valores más pequeños de U apoyan la hipótesis alternativa (es decir, rechazamos H​0 si U es pequeña). El procedimiento para determinar exactamente cuándo rechazar H​0​ se describe a continuación.</p>
<p>El valor crítico de U se puede encontrar en la siguiente tabla:</p>
<p><img src="img/4.7.3_utabla.png" width="454" /></p>
<p>Para determinar el valor crítico, necesitamos los tamaños de muestra (<span class="math inline">\(n_1\)</span> = <span class="math inline">\(m_2\)</span> = 5) y nuestro nivel de significancia bilateral <span class="math inline">\(\alpha\)</span> = 0.05 (la tabla da los valores críticos para 0.05 y 0.01).</p>
<p>En nuestro caso, el valor crítico que nos da la tabla es 2 y la regla de decisión es rechazar $H_0$0 si U &lt; 2.</p>
<p>Nosotros habíamos obtenido un valor U = 3 por lo que no rechazamos <span class="math inline">\(H_0\)</span> ya que 3 &gt; 2.</p>
<p>También podemos calcular el valor p con la aplicación web <a href="https://homepage.divms.uiowa.edu/~mbognar/applets/mw.html" class="uri">https://homepage.divms.uiowa.edu/~mbognar/applets/mw.html</a>:</p>
<p><img src="img/4.7.3_bognar.png" width="490" /></p>
<p>Obtenemos un valor p = 0,02778 que es mayor, por muy poco, que 0,025 (es un contraste bilateral, de 2 colas).
De este modo, no tenemos pruebas estadísticamente significativas a <span class="math inline">\(\alpha\)</span> = 0.05 para mostrar que las dos poblaciones de episodios de dificultad respiratoria son distintos. Sin embargo, en este ejemplo, el hecho de no alcanzar una significación estadística puede deberse a una baja potencia. Los datos de la muestra sugieren una diferencia pero los tamaños de la muestra son demasiado pequeños para concluir que existe una diferencia estadísticamente significativa.</p>
<p>Para realizar esta práctica, debe tener descargado en su ordenador el archivo <a href="https://github.com/1fjmanzano/bioestadistica/blob/master/3.practicas.xlsx">3.practicas.xlsx</a> y abrir la hoja/pestaña correspondiente.</p>
<p>En el siguente vídeo, además de la explicaciones teóricas, se muestran los pasos para realizar la práctica.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/TY0fIxJTm-M" frameborder="0" allow="accelerometer; autoplay; encrypted-media;
  gyroscope; picture-in-picture" allowfullscreen>
</iframe>
</div>
<div id="anova-de-un-factor" class="section level3" number="4.7.4">
<h3><span class="header-section-number">4.7.4</span> Anova de un factor</h3>
<p>Este test es una generalización del test de Student para dos muestras independientes que se aplica para un mismo tipo de estudio y de diseño, con la salvedad de que podemos distinguir un número de categorías y, por lo tanto, de medias, mayor de dos.</p>
<p>El test que resuelve el contraste se denomina <strong>anova de una vía</strong> o factor (analisis of variance i. e. análisis de la varianza) y requiere en principio de las mismas condiciones de validez que el test de Student para dos muestras independientes, es decir;</p>
<ul>
<li>Las muestras aleatorias elegidas deben ser <strong>independientes</strong>. Además, dentro de cada tratamiento, las observaciones son independientes entre sí.</li>
<li>Las observaciones proceden de <strong>poblaciones normales</strong> de modo que las variables correspondientes al mismo tratamiento tienen la misma media.</li>
<li><strong>Hipotesis de homocedasticidad</strong>: cada población tiene la misma varianza</li>
</ul>
<p>La prueba Anova es una prueba de hipótesis que es apropiada para comparar medias de una variable continua en dos o más grupos de comparación independientes. Por ejemplo, en algunos ensayos clínicos hay más de dos grupos de comparación. En un ensayo clínico para evaluar un nuevo medicamento para el asma, los investigadores podrían comparar un medicamento experimental con un placebo y con un tratamiento estándar (es decir, un medicamento que se esté usando actualmente). En un estudio observacional como el estudio del corazón de Framingham, podría ser interesante comparar la presión arterial media o los niveles medios de colesterol en personas con bajo peso, peso normal, sobrepeso y obesidad.</p>
<p>Vamos a considerar un ejemplo con grupos independientes y una medida de resultado continua. Los grupos independientes pueden definirse por una característica particular de los participantes, como el IMC (p. ej., Bajo peso, peso normal, sobrepeso, obesidad) o por el investigador (p. ej., Asignación aleatoria de participantes a uno de los cuatro tratamientos A, B, C y D). Supongamos que el resultado es la presión arterial sistólica y queremos comprobar si existe una diferencia estadísticamente significativa en la presión arterial sistólica media entre los cuatro grupos. Los datos de muestra se organizan de la siguiente manera:</p>
<p><img src="img/4.7.4_datos.png" width="598" /></p>
<p>Las hipótesis son:</p>
<p><span class="math inline">\(H_0:\mu_1 = \mu_2 = ... = \mu_k\)</span></p>
<p><span class="math inline">\(H_1\)</span>: las medias no son iguales</p>
<p>Al aplicar ANOVA de un factor se calcula un estadístico de contraste denominado F. El estadístico F o F-test (se llama F en honor al estadístico Ronald Fisher) se obtiene al estimar la variación de las medias entre los grupos de la variable independiente y dividirla por la estimación de la variación de las medias dentro de los grupos. Así, si</p>
<ul>
<li>N es el número total de observaciones</li>
<li><span class="math inline">\(\overline{x}\)</span> es la media de todos los datos</li>
<li><span class="math inline">\(\overline{x_i}\)</span> es la media del grupo i = 1, 2, …, k</li>
</ul>
<p>El estadístico F se obtiene como:</p>
<p><span class="math inline">\(F=\frac{\frac{\sum n_j(\overline{x}_j-\overline{x})^2}{k-1}}{\frac{\sum\sum(x_i-\overline{x}_j)^2}{N-k}}\)</span></p>
<p>El cálculo del estadístico F divide la variación entre los grupos por la variación dentro de los grupos. Si las medias entre los grupos varían mucho y la media dentro de un grupo varía poco, es decir, los grupos son heterogéneos entre ellos y similares internamente, el valor de F será más alto, y por tanto, las variables estarán relacionadas. El estadístico F se distribuye según el modelo de probabilidad F de Snedecor siendo los grados de libertad del numerador el número de grupos menos 1 y los del denominador, el número total de observaciones menos el número de grupos).</p>
<p>En conclusión, <strong>cuanto más difieren las medias de la variable dependiente entre los grupos de la variable independiente, más alto será el valor de F</strong>. Si hacemos varios análisis de ANOVA de un factor, aquel con F más alto indicará que hay más diferencias y por tanto una relación más fuerte entre las variables.</p>
<p>Vamos a considerar el siguiente ejemplo: se realiza un ensayo clínico para comparar programas de pérdida de peso y los participantes se asignan al azar a uno de los programas de comparación y los participantes siguen el programa asignado durante 8 semanas. El resultado de interés es la pérdida de peso, definida como la diferencia en el peso medido al inicio del estudio (línea de base) y el peso medido al final del estudio (8 semanas), medido en kilogramos. Las diferencias positivas indican pérdidas de peso y las negativas indican ganancias de peso.</p>
<p><img src="img/4.7.4_datos2.png" width="747" /></p>
<p>Suponemos que las muestras elegidas son independientes y dentro de cada tratamiento, las observaciones son independientes entre sí, que las observaciones proceden de poblaciones normales y que cada población tiene la misma varianza.</p>
<p>Con la hoja de cálculo, hacemos el <strong>Análisis de varianza de un factor</strong> obteniendo los siguientes resultados:</p>
<p><img src="img/4.7.4_excel.png" width="748" /></p>
<p>Obtenemos pues un valor del estadístico de contraste F = 8,56 siendo el valor crítico 3,24 para α = 0,05. Además, nos indica un valor p de 0,001277742.</p>
<p>Entonces rechazamos <span class="math inline">\(H_0\)</span> porque 8,56 &gt; 3.24 (o porque 0,001 &lt; 0,05), es decir, tenemos pruebas estadísticamente significativas con una confianza del 95% (<span class="math inline">\(\alpha\)</span>= 0.05) para concluir que <strong>existe una diferencia en la pérdida de peso promedio entre las cuatro dietas</strong>.</p>
<p>Para realizar esta práctica, debe tener descargado en su ordenador el archivo <a href="https://github.com/1fjmanzano/bioestadistica/blob/master/3.practicas.xlsx">3.practicas.xlsx</a> y abrir la hoja/pestaña correspondiente.</p>
<p>En el siguente vídeo, además de la explicaciones teóricas, se muestran los pasos para realizar la práctica.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/cJM9qtGuYVw" frameborder="0" allow="accelerometer; autoplay; encrypted-media;
  gyroscope; picture-in-picture" allowfullscreen>
</iframe>
</div>
<div id="prueba-de-kruskal-wallis" class="section level3" number="4.7.5">
<h3><span class="header-section-number">4.7.5</span> Prueba de Kruskal-Wallis</h3>
<p>Hemos visto técnicas para probar la igualdad de medias en más de dos muestras independientes utilizando análisis de varianza (ANOVA).</p>
<p>Un supuesto subyacente para el uso apropiado de ANOVA es que el resultado continuo se distribuye aproximadamente de manera normal o que las muestras eran suficientemente grandes (generalmente <span class="math inline">\(n_j\)</span> &gt; 30, donde j = 1, 2, …, k y k denota el número de grupos).</p>
<p>Un supuesto adicional para el uso apropiado de ANOVA es la igualdad de varianzas en los k grupos de comparación. ANOVA es generalmente robusto cuando los tamaños de muestra son pequeños pero iguales. Cuando el resultado no se distribuye normalmente y las muestras son pequeñas, una prueba no paramétrica es apropiada.</p>
<p>Una prueba no paramétrica popular para comparar resultados entre más de dos grupos independientes es la prueba de Kruskal Wallis. La prueba de Kruskal Wallis se usa para comparar medianas entre k grupos de comparación (k&gt; 2) y algunas veces se describe como un ANOVA con los datos reemplazados por sus rangos. Las hipótesis nula y de investigación para la prueba no paramétrica de Kruskal Wallis se exponen a continuación:</p>
<p><span class="math inline">\(H_0\)</span>: Las k medianas de la población son iguales</p>
<p><span class="math inline">\(H_1\)</span>: Las k medianas de población no son todas iguales</p>
<p>El procedimiento para la prueba implica agrupar las observaciones de las k muestras en una muestra combinada, hacer un seguimiento de la muestra de cada observación y luego clasificar de 1 a N, con N = <span class="math inline">\(n_1\)</span>, <span class="math inline">\(n_2\)</span>, … , <span class="math inline">\(n_k\)</span>. Para ilustrar el procedimiento, vamos a considerar el siguiente ejemplo:</p>
<p>Un estudio clínico está diseñado para evaluar las diferencias en los niveles de albúmina en adultos que siguen dietas con diferentes cantidades de proteínas. Las dietas bajas en proteínas a menudo se prescriben para pacientes con insuficiencia renal. La albúmina es la proteína más abundante en la sangre y su concentración en el suero se mide en gramos por decilitro (g / dL). Clínicamente, las concentraciones de albúmina sérica también se utilizan para evaluar si los pacientes obtienen suficiente proteína en sus dietas. Se comparan tres dietas, que varían de 5% a 15% de proteínas, y la dieta de 15% de proteínas representa una dieta típica estadounidense. Los niveles de albúmina de los participantes después de cada dieta se muestran a continuación.</p>
<p><img src="img/4.7.5_datos.png" width="399" /></p>
<p>Parece que que hay una diferencia en los niveles de albúmina sérica entre los sujetos en las tres dietas diferentes. Como referencia, los niveles normales de albúmina están generalmente entre 3.4 y 5.4 g / dL. A simple vista, parece que los participantes que siguen la dieta con 15% de proteínas tienen niveles de albúmina más altos que los que siguen la dieta con 5% de proteínas. El problema es comprobar si esta diferencia observada es estadísticamente significativa.</p>
<p>En este ejemplo, la variable es cuantitativa continua, pero los tamaños de muestra son pequeños y no son iguales entre los grupos de comparación (<span class="math inline">\(n_1\)</span> = 3, <span class="math inline">\(n_2\)</span> = 5, <span class="math inline">\(n_3\)</span> = 4). Por lo tanto, una prueba no paramétrica es apropiada. Las hipótesis que se van a probar se dan a continuación y tomaremos un nivel de significación del 5% (<span class="math inline">\(\alpha\)</span> = 0.05).</p>
<p><span class="math inline">\(H_0\)</span>: las medianas de los grupos son iguales</p>
<p><span class="math inline">\(H_1\)</span>: al menos uno de los grupos tiene mediana distinta a las otras</p>
<p>Para realizar la prueba, primero ordenamos los datos en la muestra total combinada de 12 sujetos, de menor a mayor y asignar los rangos correspondientes:</p>
<p><img src="img/4.7.5_rangos.png" width="443" /></p>
<p>Se observa que los rangos más bajos (por ejemplo, 1, 2.5, 4) se asignan al grupo de dieta con 5% de proteínas, mientras que los rangos más altos (por ejemplo, 10, 11 y 12) se asignan al grupo de dieta con 15% de proteínas.</p>
<p>Nuevamente, el objetivo de la prueba es determinar si los datos observados apoyan una diferencia en las tres medianas de la población. Recuerde que en las pruebas paramétricas cuando comparamos medias entre más de dos grupos, analizamos la diferencia entre las medias muestrales (media cuadrada entre grupos) en relación con su variabilidad dentro del grupo y resumimos la información de la muestra en una prueba estadística (estadística F). En la prueba de Kruskal Wallis, nuevamente resumimos la información de la muestra en una estadística de prueba basada en los rangos.</p>
<p>El estadístico de prueba para la prueba de Kruskal Wallis se denota H y se define como sigue:</p>
<p><span class="math inline">\(H=\left( \frac{12}{N(N+1)}\sum_{j=1}^k \frac{R_j^2}{n_j}\right) -3(N+1)\)</span></p>
<p>donde k es el número de grupos de comparación, N el tamaño total de la muestra, <span class="math inline">\(n_j\)</span> es el tamaño de la muestra en el grupo j y R​j​ es la suma de los rangos en el grupo j.</p>
<p>En este ejemplo, <span class="math inline">\(R_1\)</span> = 7.5, <span class="math inline">\(R_2\)</span> = 30.5 y <span class="math inline">\(R_3\)</span> = 40. Recuerde que la suma de los rangos siempre será igual a <span class="math inline">\(\frac{n(n-1)}{2}\)</span>.</p>
<p>El estadístico H para este ejemplo se calcula de la siguiente manera:</p>
<p><span class="math inline">\(H=\left( \frac{12}{N(N+1)}\sum_{j=1}^k \frac{R_j^2}{n_j}\right) -3(N+1)= \frac{12}{12\cdot 13}\left( \frac{7,5^2}{3}+\frac{30,5^2}{5}+\frac{40^2}{4}\right) -3(13)=7.52\)</span></p>
<p>Ahora debemos determinar si el estadístico de prueba obtenido H respalda la hipótesis nula o de investigación. Una vez más, esto se hace estableciendo un valor crítico de H.</p>
<ul>
<li><p>Si el valor observado de H es mayor o igual al valor crítico, rechazamos <span class="math inline">\(H_0\)</span> a favor de <span class="math inline">\(H_1\)</span>.</p></li>
<li><p>Si el valor observado de H es menor que el valor crítico, no rechazamos <span class="math inline">\(H_0\)</span></p></li>
</ul>
<p>El valor crítico de H se puede encontrar en la siguiente tabla:</p>
<p><img src="img/4.7.5_tabla.png" width="150%" /></p>
<p>Para determinar el valor crítico apropiado, al tener 3 observaciones con tamaños de muestra <span class="math inline">\(n_1\)</span> = 3, <span class="math inline">\(n_2\)</span> = 5 y <span class="math inline">\(n_3\)</span>= 4 con un nivel de significación <span class="math inline">\(\alpha\)</span> = 0.05, buscamos en la fila 5, 4, 3 y la columna <span class="math inline">\(\alpha\)</span> = 0.05. Para este ejemplo, el valor crítico es 5,656.</p>
<p>Por lo tanto rechazamos <span class="math inline">\(H_0\)</span> porque 7,52 &gt; 5,656 y concluimos que <strong>al menos uno de los grupos tiene mediana distinta a las otras entre las tres dietas diferentes</strong>.</p>
<p>Hay que tener en cuenta que la tabla contiene valores críticos para la prueba de Kruskal Wallis para pruebas que comparan 3, 4 o 5 grupos con tamaños de muestra pequeños. Si hay 3 o más grupos de comparación y 5 o más observaciones en cada uno de los grupos de comparación, se puede mostrar que el estadístico de prueba H se aproxima a una distribución chi-cuadrado con el número de grados de libertad df = k - 1.</p>
<p>Por lo tanto, en una prueba de Kruskal Wallis con 3 o más grupos de comparación y 5 o más observaciones en cada grupo, el valor crítico para la prueba se puede encontrar en la tabla de Valores críticos de la distribución <span class="math inline">\(\chi^2\)</span> a continuación.</p>
<p><img src="img/4.7.5_tabla2.png" width="150%" /></p>
<p>Vamos a verlo con otro ejemplo</p>
<p>¿El ejercicio físico alivia la depresión? Realizamos un estudio con un grupo de personas deprimidas de manera equivalente. Luego asignamos a cada persona al azar a uno de tres grupos: sin ejercicio; 20 minutos de ejercicio físico por día o 60 minutos de ejercicio por día. Al final de un mes, le pedimos a cada participante que califique su grado de depresión en una escala Likert que va desde 1 (totalmente deprimido) hasta 100 (totalmente feliz) obteniendo los siguientes resultados:</p>
<p><img src="img/4.7.5_datos2.png" width="264" /></p>
<p>Parece que hay diferencias entre los 3 grupos:</p>
<p><img src="img/4.7.5_tabla3.png" width="375" /></p>
<p>Para comprobar si hay diferencias estadísticamente significativas (α = 0.05), aplicamos la prueba de Kruskal-Wallis.
Las hipótesis nula y de investigación para la prueba no paramétrica de Kruskal Wallis son:</p>
<p><span class="math inline">\(H_0\)</span>: las medianas de los grupos son iguales</p>
<p><span class="math inline">\(H_1\)</span>: al menos uno de los grupos tiene mediana distinta a las otras</p>
<p>Establecemos el rango para cada medición:</p>
<p><img src="img/4.7.5_rangos2.png" width="329" /></p>
<p>El estadístico de prueba para la prueba de Kruskal Wallis es:</p>
<p><span class="math inline">\(H=\left( \frac{12}{N(N+1)}\sum_{j=1}^k \frac{R_j^2}{n_j}\right) -3(N+1)\)</span></p>
<p>En este ejemplo, <span class="math inline">\(R_1\)</span> = 77, <span class="math inline">\(R_2\)</span> = 80.5 y <span class="math inline">\(R_3\)</span> = 142,5 con 8 datos en cada grupo para un total de 24. Así, haciendo los cálculos, obtenemos:</p>
<p><span class="math inline">\(H=\left( \frac{12}{N(N+1)}\sum_{j=1}^k \frac{R_j^2}{n_j}\right) -3(N+1)= \frac{24}{24\cdot 25}\left( \frac{77^2}{8}+\frac{80,5^2}{8}+\frac{142,5^2}{8}\right) -3(25)=6,78875\)</span></p>
<p>Como hemos comentado, en este segundo ejemplo usamos la tabla de la chi-cuadrado. Tenemos que los grados de libertad son igual al número de grupos menos uno, es decir 3 -1 = 2 grados de libertad (df).</p>
<p>Entonces, en la tabla de la <span class="math inline">\(\chi^2\)</span> buscamos el valor crítico para 2 grados de libertad con un nivel de significación <span class="math inline">\(\alpha\)</span> = 0.05 obteniendo un valor <span class="math inline">\(\chi^2_{.0.05}\)</span> = 5,991.</p>
<p>Comenzamos comparando nuestro H de 6,79 con 5.99. Con 2 grados de libertad, es probable que un valor de Chi-cuadrado tan grande como 5.99 ocurra por casualidad solo 5 veces en cien, es decir, tiene una p de 0,05. Nuestro valor obtenido de 6,79 es incluso mayor que esto, por lo que esto nos dice que nuestro valor de H es incluso menos probable que ocurra por casualidad. Nuestra H ocurrirá por casualidad con una probabilidad de menos de 0,05.</p>
<p>Así, podemos concluir que la prueba de Kruskal-Wallis indica que hay un efecto significativo del ejercicio en los niveles de depresión (H = 6,79, p &lt; 0,05). Las medias de cada grupo sugieren que, en comparación con el grupo de control “sin ejercicio”, la depresión se redujo significativamente con 60 minutos de ejercicio diario, pero no con 20 minutos de ejercicio. Hay que tener en cuenta que una puntuación más alta en este estudio equivale a un nivel de ánimo más alto y, por lo tanto, un nivel de depresión más bajo).</p>
<p>Sin utilizar la tabla, podríamos haber obtenido el valor p correspondiente a 6,79 con 2 grados de libertad utilizando la hoja de cálculo o la aplicación web:</p>
<p><img src="img/4.7.5_valorp.png" width="667" /></p>
</div>
<div id="test-de-student-para-muestras-relacionadas" class="section level3" number="4.7.6">
<h3><span class="header-section-number">4.7.6</span> Test de Student para muestras relacionadas</h3>
<p>Cuando se trata de comparar dos grupos de observaciones, es importante distinguir el caso en el que son independientes de aquel en el que los datos están apareados. Las series dependientes surgen normalmente cuando se evalúa un mismo dato más de una vez en cada sujeto de la muestra. También se puede encontrar este tipo de observaciones en estudios de casos y controles donde cada caso se aparea individualmente con un control.</p>
<p>Así, podemos seleccionar una muestra aleatoria de n individuos a los que se les mide una variable numérica antes de iniciar un tratamiento para volver a medírsela después. En tal caso, no estaremos hablando de una variable sino de dos variables distintas, <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span>, medidas antes y después del tratamiento respectivamente, sobre una única población, sin distinguir categorías.</p>
<p>Si el tratamiento es efectivo debe producirse una evolución, es decir, un cambio entre los valores de <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span>. No estamos en condiciones de exigir que ese cambio se dé en el mismo sentido para todos los individuos, pero sí al menos que se dé por término medio, de ahí que el problema se traduzca finalmente en una comparación entre las respectivas medias <span class="math inline">\(\mu_1\)</span> y <span class="math inline">\(\mu_2\)</span>.
Tomemos el siguiente ejemplo: en la siguiente tabla:</p>
<p><img src="img/4.7.6_datos.png" width="404" /></p>
<p>tenemos el peso de 75 individuos antes y después de someterse a una dieta y queremos comprobar si realmente se produce una pérdida de peso significativa.</p>
<p>Así, no interesa la variabilidad que puede haber entre los individuos sino en las diferencias que se observan en un mismo sujeto entre un momento y otro. Por este motivo, se establece como hipótesis:</p>
<p><span class="math inline">\(H_0\)</span>: La pérdida de peso es nula</p>
<p>frente a la alternativa de que la pérdida de peso sea importante (es decir, distinta de cero).</p>
<p>La veracidad de dicha hipótesis puede ser contrastada mediante el test t de Student. Este tipo de métodos tienen como hipótesis fundamental la normalidad de los datos. En este caso, sin embargo, no será necesario que las observaciones en ambos grupos provengan de poblaciones normales, sino que únicamente se requiere verificar la normalidad de su diferencia.</p>
<p>Si representamos los datos mediante diagramas de cajas y bigotes:</p>
<p><img src="img/4.7.6_boxplot.png" width="341" /></p>
<p>se observa una diferencia (descenso) entre los mismos.</p>
<p>El estadístico de contrastedel t.test para muestras emparejadas es:</p>
<p><span class="math inline">\(t=\frac{\overline{d}}{s_d}\sqrt{n}\)</span></p>
<p>donde <span class="math inline">\(\overline{d}\)</span> denota la media de la pérdida de peso estimada a partir de la muestra, <span class="math inline">\(s_d\)</span> es la cuasivarianza muestral de la diferencia y n el número de datos.</p>
<p>Utilizando la Prueba t para medias de dos muestras emparejadas del análisis de datos de Excel©, obtenemos:</p>
<p><img src="img/4.7.6_ttest.png" width="478" /></p>
<p>Es decir, el valor del estadístico t obtenido es 18,645, muy superior a los valores críticos para una cola (1,6657) o para dos colas (1,9925) para una confianza del 95% (valor p &lt; 0,05) con valores p en ambos casos casi nulos (5<span class="math inline">\(5,5\cdot 10^{-30}\)</span> y <span class="math inline">\(1,1\cdot 10^{-29}\)</span> respectivamente). De este modo, podemos concluir que hay una pérdida de peso significativamente distinta de cero.</p>
</div>
<div id="t-test-emparejadas-práctica" class="section level3" number="4.7.7">
<h3><span class="header-section-number">4.7.7</span> t-test emparejadas (Práctica)</h3>
<p>Para realizar esta práctica, debe tener descargado en su ordenador el archivo <a href="https://github.com/1fjmanzano/bioestadistica/blob/master/3.practicas.xlsx">3.practicas.xlsx</a> y abrir la hoja/pestaña correspondiente.</p>
<p>En el siguente vídeo, además de la explicaciones teóricas, se muestran los pasos para realizar la práctica.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/-LY2CwmM7q8" frameborder="0" allow="accelerometer; autoplay; encrypted-media;
  gyroscope; picture-in-picture" allowfullscreen>
</iframe>
</div>
<div id="prueba-de-rangos-con-signo-de-wilcoxon" class="section level3" number="4.7.8">
<h3><span class="header-section-number">4.7.8</span> Prueba de rangos con signo de Wilcoxon</h3>
<p>El test no paramétrico prueba de los rangos con signo de Wilcoxon (<strong>Wilcoxon signed-rank test</strong>), permite comparar poblaciones cuando sus distribuciones (normalmente interpretadas a partir de las muestras) no satisfacen las condiciones necesarias para otros test paramétricos. Es una alternativa a la prueba t de Student (t-test) para muestras dependientes cuando las muestras no siguen una distribución normal (muestran asimetría o colas) o cuando tienen un tamaño demasiado reducido para poder determinar si realmente proceden de poblaciones normales.</p>
<p>Como condiciones para utilizar la prueba de rangos con signo de Wilcoxon tenemos:</p>
<ul>
<li>Los datos tienen que ser dependientes.</li>
<li>Los datos tienen que ser ordinales, es decir, se tienen que poder ordenar de menor a mayor o viceversa.</li>
<li>No es necesario asumir que las muestras se distribuyen de forma normal o que proceden de poblaciones normales pero sea cual sea el tipo de distribución de las diferencias, tiene que ser simétrica.</li>
<li>A pesar de considerarse el equivalente no paramétrico del t-test, el Wilcoxon signed-rank test trabaja con medianas, no con medias.</li>
<li>Preferible al t-test cuando hay valores atípicos, no hay normalidad de los datos o el tamaño de las muestras es pequeño.</li>
</ul>
<p>Vamos a trabajar con el siguiente ejemplo: se estudia la efectividad de un nuevo medicamento diseñado para reducir las conductas repetitivas en niños afectados con autismo. Un total de 8 niños con autismo se inscriben en el estudio y la cantidad de tiempo que cada niño está involucrado en un comportamiento repetitivo durante períodos de observación de tres horas se mide antes del tratamiento y luego nuevamente después de tomar la nueva medicación durante un período de 1 semana. Los datos se muestran a continuación.</p>
<p><img src="img/4.7.8_datos.png" width="425" /></p>
<p>Ahora, calculamos las diferencias para cada paciente:</p>
<p><img src="img/4.7.8_dif.png" width="558" /></p>
<p>El siguiente paso es ordenar de menor a mayor esas diferencias en valor absoluto, esto es, sin tener en cuenta el signo y asignarles un rango (un número de posición) siendo la posición 1 para el valor más pequeño. En caso de haber valores repetidos, fenómeno conocido como ligadura o ties, se les asigna como valor de posición la media de las posiciones que ocupan. En la asignación de posiciones se ignoran las diferencias que sean 0. Finalmente, se añade el signo (positivo o negativo) de las diferencias observadas a cada rango como se muestra a continuación.</p>
<p><img src="img/4.7.8_rangos.png" width="645" /></p>
<p>Las hipótesis para la prueba se refieren a la mediana de la población de las puntuaciones de diferencia. La hipótesis de investigación puede ser unilateral o bilateral (una cola o dos colas). Aquí consideramos una prueba unilateral con <span class="math inline">\(\alpha\)</span> = 0.05 y como hipótesis:</p>
<p><span class="math inline">\(H_0\)</span>: La diferencia de medianas es cero</p>
<p><span class="math inline">\(H_1\)</span>: La diferencia de medianas es positiva</p>
<p>El estadístico de contraste para la prueba es W, definido como el menor de W+ (suma de los rangos positivos) y W- (valor absoluto de la suma de los rangos negativos). Si la hipótesis nula es cierta, esperamos ver números similares de rangos más altos y más bajos que sean positivos y negativos (es decir, W+ y W- serían similares). Si la hipótesis alternativa es cierta, esperamos ver rangos más altos y positivos (en este ejemplo, más niños con una mejora sustancial en el comportamiento repetitivo después del tratamiento en comparación con el anterior), es decir, W+ mucho más grande que W-).</p>
<p>En nuestro ejemplo <span class="math inline">\(W+ = 3 + 3 + 5 + 6 +7+8=32\)</span> y <span class="math inline">\(W-=|-1-3|=4\)</span> por lo que el estadístico de contraste en nuestro ejemplo es el menor de esos valores, es decir, <span class="math inline">\(W = 4\)</span>.</p>
<p>Ahora, debemos determinar si el estadístico de contraste obtenido W = 4 respalda la hipótesis nula o la alternativa. Así, determinamos un valor crítico de W tal que si el valor observado de W es menor o igual al valor crítico, rechazamos <span class="math inline">\(H_0\)</span> a favor de <span class="math inline">\(H_1\)</span> y, si el valor observado de W excede el valor crítico, no rechazamos <span class="math inline">\(H_0\)</span>.</p>
<p>El valor crítico de W para dos colas se puede encontrar en la siguiente tabla:</p>
<p><img src="img/4.7.8_tablaw.png" width="582" /></p>
<p>Para una prueba de una cola, se duplica el valor alfa (0,05·2 = 0,10) y se usa la misma tabla. De este modo, el valor crítico W para nuestro ejemplo (n = 8) es 5 y la regla de decisión es rechazar <span class="math inline">\(H_0\)</span> si W &lt; 5. Por lo tanto, rechazamos <span class="math inline">\(H_0\)</span> ya que 4 &lt; 5.</p>
<p>Podemos concluir que, <strong>con los datos de la muestra, hay diferencias estadísticamente significativas que avalan la efectividad del nuevo medicamento diseñado para reducir las conductas repetitivas en niños afectados con autismo</strong>.</p>
<p>Sin utilizar tablas, también podemos calcular tanto el valor del estadístico de contraste W como el valor p para la prueba con la aplicación web <a href="https://homepage.divms.uiowa.edu/~mbognar/applets/wilcoxon-signed-rank.html" class="uri">https://homepage.divms.uiowa.edu/~mbognar/applets/wilcoxon-signed-rank.html</a>:</p>
<p><img src="img/4.7.8_bognar.png" width="569" /></p>
<p>Vemos un valor p = 0,027 &lt; 0,05 por lo que es estadísticamente significativo.</p>
<p>Por lo tanto, tenemos evidencia estadísticamente significativa en <span class="math inline">\(\alpha\)</span> = 0.05, para mostrar que la mediana de la diferencia es positiva (es decir, que el medicamento mejora el comportamiento repetitivo).</p>
</div>
<div id="test-de-correlación-r" class="section level3" number="4.7.9">
<h3><span class="header-section-number">4.7.9</span> Test de correlación r</h3>
<p>Hemos visto cómo calcular el coeficiente de correlación de Pearson (r) para 2 variables cuantitativas que nos indica el grado de relación lineal entre ambas variables.</p>
<p>En Excel® se calcula con la función =COEF.DE.CORREL. En esta imagen, tenemos un ejemplo:</p>
<p><img src="img/4.7.9_excel.png" width="578" /></p>
<p>Ahora, una vez calculado dicho coeficiente, debemos determinar si dicho coeficiente es estadísticamente diferente de cero, es decir, si las variables X e Y están relacionadas en realidad o tan solo presentan dicha relación como consecuencia del azar. Para dicho cálculo se aplica un test basado en la distribución de la t de student.</p>
<p>El coeficiente de correlación de Pearson (r) puede calcularse en cualquier grupo de datos numéricos pero del test de hipótesis sobre la correlación entre las variables requiere:</p>
<ul>
<li>que las dos variables procedan de una muestra aleatoria de individuos.</li>
<li>que al menos una de las variables tenga una distribución normal en la población</li>
</ul>
<p>Para el cálculo válido de un intervalo de confianza del coeficiente de correlación de r ambas variables deben tener una distribución normal. Si los datos no tienen una distribución normal, se calcularía un coeficiente de correlación no paramétrico (coeficiente de correlación de Spearman) que tiene el mismo significado que el coeficiente de correlación de Pearson y se calcula utilizando el rango de las observaciones.</p>
<p>Se dice que el coeficiente de correlación es significativo si se puede afirmar, con una cierta probabilidad, que es diferente de cero. En términos estadísticos, preguntarse por la significación de un cierto coeficiente de correlación no es otra cosa que preguntarse por la probabilidad de que tal coeficiente proceda de una población cuyo valor sea de cero. Así, establecemos como hipótesis:</p>
<p><span class="math inline">\(H_0\)</span>: r = 0 (las variables no están relacionadas)</p>
<p><span class="math inline">\(H_1\)</span> r <span class="math inline">\(\neq\)</span> 0 (las variables están relacionadas)</p>
<p>Desde el supuesto de la Hipótesis nula se demuestra que la distribución muestral de correlaciones procedentes de una población caracterizada por una correlación igual a cero
(r = 0) sigue una distribución t de Student con n - 2 grados de libertad de media el valor poblacional y desviación típica:</p>
<p><span class="math inline">\(S=\sqrt{\frac{1-r^2}{n-2}}\)</span></p>
<p>Entonces, ​una vez calculado r ​se trata de comprobar si dicho coeficiente es posible que se encuentre dentro de la distribución muestral especificada por la Hipótesis nula. A efectos prácticos, se calcula el número de desviaciones tipo que se encuentra el coeficiente obtenido del centro de la distribución mediante el estadístico de contraste:</p>
<p><span class="math inline">\(S=\frac{r}{\sqrt{\frac{1-r^2}{n-2}}}\)</span></p>
<p>que se compara el valor crítico de la t de Student para un cierto nivel de significación α (confianza 95%) y n - 2 grados de libertad.</p>
<p>En nuestro ejemplo:</p>
<p><span class="math inline">\(S=\frac{0,92}{\sqrt{\frac{1-0,92^2}{12-2}}}=7,42\)</span></p>
<p>Como el contraste es bilateral (<span class="math inline">\(H_0\)</span>: r = 0), el valor crítico asociado a una confianza del 95% para una t de Student con 2 colas con 12 - 2 = 10 grados de libertad es 2,63. Este valor se puede obtener de la tabla, con Excel® mediante la función =INV.T.2C(0,025;10) o con la aplicación web:</p>
<p><img src="img/4.7.9_bognar.png" width="364" /></p>
<p>Como el valor del estadístico de contraste obtenido S = 8,03 es mayor que el valor crítico 2,63, rechazamos la hipótesis nula (<span class="math inline">\(H_0\)</span>: r = 0) y podemos concluir que, con una confianza del 95%, las variables están relacionadas.</p>
<p>Para terminar, tenemos que indicar que <strong>correlación no implica causalidad</strong>:</p>
<p><em>Cuando se dice que la frase correlación no implica causalidad (en latín, <a href="https://es.wikipedia.org/wiki/Cum_hoc_ergo_propter_hoc%5D">Cum hoc ergo procter hoc</a> ) es cierta lo que se quiere decir es que el hecho de que haya correlación entre dos variables no significa que una provoque a la otra, pero eso no significa que si encontramos correlación entre dos variables automáticamente podamos descartar que una sea causa de la otra. Hay casos en los que A es la causa de que ocurra B, en otros es al revés, en otros hay alguna variable adicional la que hace que se produzca esa correlación…y a veces todo es fruto de la casualidad (sí, casualidad, no «causalidad»)</em>.</p>
<p><a href="https://www.gaussianos.com/hay-que-decirlo-mas-correlacion-implica-causalidad/">Fuente</a></p>
</div>
<div id="correlación-de-spearman" class="section level3" number="4.7.10">
<h3><span class="header-section-number">4.7.10</span> Correlación de Spearman</h3>
<p>En el caso de que no se cumplan los supuestos para calcular el coeficiente de correlación r de Pearson, tenemos la alternativa no paramétrica del coeficiente de correlación de Spearman. En este caso, este coeficiente es una medida de asociación lineal que utiliza los rangos o números de orden, de cada grupo de sujetos y compara dichos rangos.</p>
<p>El coeficiente de correlación de Spearman es recomendable utilizarlo cuando los datos presentan valores externos ya que dichos valores afectan mucho el coeficiente de correlación de Pearson, o ante distribuciones no normales.</p>
<p>El coeficiente de correlación de Spearman viene dado por la fórmula:</p>
<p><span class="math inline">\(R_S=1-\frac{6\sum d_i^2}{n(n^2-1)}\)</span></p>
<p>Donde <span class="math inline">\(D_i=r_{X_i}-r_{Y_i}\)</span> es la diferencia entre los rangos de X e Y.</p>
<p>Veamos un ejemplo: dos médicos evalúan la condición de ocho pacientes que sufren ciertos síntomas. Para ello, clasifican a los pacientes de 1 (mejor) a 8 (peor). Los resultados de los 8 pacientes se muestran en la siguiente imagen:</p>
<p><img src="img/4.7.10_datos.png" width="236" /></p>
<p>Veamos ahora la correlación entre las valoraciones de los 2 médicos. En este caso, tenemos una variable cualitativa ordinal (escala de valoración) que no cumple con los criterios de normalidad para el cálculo del coeficiente de correlación de Pearson. Vamos pues a calcular el coeficiente de correlación de Spearman.</p>
<p>En este ejemplo tenemos ya el rango para cada paciente (X: valoración del médico A, Y: valoración del médico B). Si no estuviese ordenado por rangos, en Excel® utilizaríamos la función =JERARQUIA.MEDIA().</p>
<p>Calculamos las diferencias d de rangos y los cuadrados de dichas diferencias <span class="math inline">\(d^2\)</span> así como la suma de dichos cuadrados obteniendo un valor = 12.</p>
<p><img src="img/4.7.10_calculod.png" width="357" /></p>
<p>Entonces, el coeficiente de correlación de Spearman es:</p>
<p><span class="math inline">\(R_S=1-\frac{6\sum d_i^2}{n(n^2-1)}= 1-\frac{6\cdot 12}{8(8^2-1)}=0.857\)</span></p>
<p>Como la interpretación del coeficiente <span class="math inline">\(R_S\)</span> de Spearman es similar a la Pearson, el valor obtenido (0.857) indica que existe evidencia de un buen acuerdo entre las evaluaciones de los médicos.</p>
<p>El cálculo de los intervalos de confianza de <span class="math inline">\(R_S\)</span> se puede realizar utilizando la misma metodología previamente explicada para el coeficiente de correlación de Pearson. Como hipótesis, tendremos:</p>
<p><span class="math inline">\(H_0\)</span>: <span class="math inline">\(R_S\)</span> = 0 (no hay acuerdo entre las valoraciones de los médicos)</p>
<p><span class="math inline">\(H_1\)</span>: <span class="math inline">\(R_S\)</span> ≠ 0 (hay acuerdo entre las valoraciones de los médicos)</p>
<p>El estadístico de contraste S es:</p>
<p><span class="math inline">\(S=\frac{R_S}{\sqrt{\frac{1-R_S^2}{n-2}}}\)</span></p>
<p>En nuestro ejemplo, tenemos que:</p>
<p><span class="math inline">\(S==\frac{0.857}{\sqrt{\frac{1-0.857^2}{8-2}}}=4.08\)</span></p>
<p>que nos da un valor p = 0.0065.</p>
<p><img src="img/4.7.10_valorp.png" width="402" /></p>
<p>Como el valor p &lt; 0.05, se concluye que, <strong>con una confianza del 95%, rechazamos la hipótesis nula y aceptamos que hay acuerdo entre las valoraciones de los médicos</strong>.</p>
</div>
<div id="prueba-de-la-chi-cuadrado" class="section level3" number="4.7.11">
<h3><span class="header-section-number">4.7.11</span> Prueba de la chi-cuadrado</h3>
<p>Cuando nos encontramos con datos o variables de tipo cualitativo mediante las cuales un grupo de individuos se clasifican en dos o más categorías mutuamente excluyentes, la prueba de la <span class="math inline">\(\chi^2\)</span> (chi cuadrado o ji-cuadrado) nos permite comprobar si hay diferencias estadísticamente significativas entre los grupos.</p>
<p>Para aplicarlo, es necesario que las frecuencias esperadas de las distintas modalidades no sea inferior a cinco.</p>
<p>Las proporciones son una forma habitual de expresar frecuencias cuando la variable objeto de estudio tiene dos posibles respuestas (sano/enfermo, etc.). Cuando lo que se pretende es comparar dos o más grupos de sujetos con respecto a una variable categórica, los resultados se presentan mediante tablas de doble entrada llamadas tablas de contingencia.</p>
<p>Del mismo modo que los estadísticos “z”, con su distribución normal y “t”, con su distribución t de Student, nos han servido para someter a prueba hipótesis que involucran a promedios y porcentajes, el estadístico chi cuadrado, que tiene distribución de probabilidad del mismo nombre, nos servirá para someter a prueba hipótesis referidas a distribuciones de frecuencias.</p>
<p>Consideramos el siguiente ejemplo: tenemos datos de 258 personas categorizadas por la variable colesterol, con tres grupos: bajo, medio y alto y la variable sexo, con dos grupos: hombre y mujer.</p>
<p>La tabla de contingencia de los datos es:</p>
<p><img src="img/4.7.11_datos.png" width="410" /></p>
<p>Si suponemos que las variables son independientes, calculamos la tabla de contingencia de los datos teóricos (o esperados si las variables son independientes). Para obtener el número de individuos esperado no hay más que multiplicar las frecuencias marginales y dividir el resultado por el número total de individuos:</p>
<p><img src="img/4.7.11_datosteoricos.png" width="374" /></p>
<p>Así, comparando los diagramas de rectángulos asociados a las dos tablas contingencia (datos observados y datos teóricos):</p>
<p><img src="img/4.7.11_diagrect.png" width="742" /></p>
<p>donde parece no haber diferencia por lo que parece que la variables sexo y colesterol son independientes. Vamos a comprobarlo mediante la prueba de la chi cuadrado si hay diferencia estadísticamente significativa entre ambos conjuntos de datos.</p>
<p>Establecemos como hipótesis:</p>
<p><span class="math inline">\(H_0\)</span>: No hay asociación entre las variables (son independientes)</p>
<p><span class="math inline">\(H_1\)</span>: Sí hay asociación entre las variables</p>
<p>Es decir, nuestra hipótesis nula implica que el sexo y el nivel de colesterol son independientes. El estadístico de contraste es:</p>
<p><span class="math inline">\(\chi^2=\sum_{i=1}^r \sum_{j=1}^k \frac{(O_{ij}-E_{ij})^2}{E_{ij}}\)</span></p>
<p>Donde:</p>
<p><span class="math inline">\(O_{ij}\)</span> son las frecuencias observadas. Es el número de casos observados clasificados en la fila i de la columna j.</p>
<p><span class="math inline">\(E_{ij}\)</span> son las frecuencias esperadas o teóricas. Es el número de casos esperados correspondientes a cada fila y columna.</p>
<p>Así, el estadístico <span class="math inline">\(\chi^2\)</span> mide la diferencia entre el valor que debiera resultar si las dos variables fuesen independientes y el que se ha observado en la realidad. Cuanto mayor sea esa
diferencia (y, por lo tanto, el valor del estadístico), mayor será la relación entre ambas variables. El hecho de que las diferencias entre los valores observados y esperados estén elevadas al cuadrado convierte cualquier diferencia en positiva.</p>
<p>La prueba χ 2 es un test no dirigido (test de 2 colas), que nos indica si existe o no relación entre dos factores pero no en qué sentido se produce tal asociación.</p>
<p>En nuestro ejemplo, el valor del estadístico <span class="math inline">\(\chi^2\)</span> es:</p>
<p><span class="math inline">\(\chi^2=\frac{(115-103.5)^2}{103.5}+\frac{(23-32)^2}{32}+\frac{(21-23.4)^2}{23.4}+ \frac{(53-64.5)^2}{64.5}+\frac{(29-20)^2}{20}+\frac{(17-14.6)^2}{14.6}=10.61\)</span></p>
<p>Ahora, debemos comparar el valor obtenido con el valor crítico de <span class="math inline">\(\chi^2\)</span> . Se sabe que bajo la hipótesis nula de independencia, los valores del estadístico <span class="math inline">\(\chi^2\)</span> se distribuyen según una
distribución conocida denominada ji-cuadrado, que depende de un parámetro llamado “grados de libertad” (df).</p>
<p>Para el caso de una tabla de contingencia de r filas y k columnas, los df son igual al producto del número de filas menos 1 (r-1) por el número de columnas menos 1 (k-1). Así, en nuestro ejemplo, el número de filas es 2 y el de columnas 3 por lo que los grados de libertad son 2 ((2 - 1)·(3 - 1) = 1·2 = 2).</p>
<p>Si utilizamos la tabla de valores críticos de la distribución <span class="math inline">\(\chi^2\)</span> vemos que el valor crítico asociado a 2 grados de libertad y una confianza del 95% (valor p &lt; 0,05) es 5.991.</p>
<p><img src="img/4.7.11_tablachi.png" width="150%" /></p>
<p>En nuestro ejemplo, el valor del estadístico obtenido era 10.61. Como 10.61 &gt; 5.991 rechazamos la hipótesis nula <span class="math inline">\(H_0\)</span> y aceptamos la hipótesis alternativa <span class="math inline">\(H_1\)</span>.como probablemente cierta y tenemos que concluir que, a la vista de los resultados, las dos variables no son independientes, sino que están asociadasa, es decir, que con los datos de la muestra, las variables sexo y nivel de colesterol están relacionadas.</p>
<p>Otra forma de comprobar el contraste de hipótesis es con Excel© que nos calcula directamente el valor p mediante la función PRUEBA.CHICUAD:</p>
<p><img src="img/4.7.11_excelchi.png" width="458" /></p>
<p>Así vemos que el valor p obtenido es 0.00495 &lt; 0,05 por lo que, evidentemente, llegaríamos a la misma conclusión.</p>
</div>
<div id="prueba-chi2-práctica" class="section level3" number="4.7.12">
<h3><span class="header-section-number">4.7.12</span> Prueba <span class="math inline">\(\chi^2\)</span> (Práctica)</h3>
<p>Para realizar esta práctica, debe tener descargado en su ordenador el archivo <a href="https://github.com/1fjmanzano/bioestadistica/blob/master/3.practicas.xlsx">3.practicas.xlsx</a> y abrir la hoja/pestaña correspondiente.</p>
<p>En el siguente vídeo se muestran los pasos para realizar la práctica.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/39wALperFR8" frameborder="0" allow="accelerometer; autoplay; encrypted-media;
  gyroscope; picture-in-picture" allowfullscreen>
</iframe>
</div>
<div id="prueba-exacta-de-fisher" class="section level3" number="4.7.13">
<h3><span class="header-section-number">4.7.13</span> Prueba exacta de Fisher</h3>
<p>La prueba o test exacto de Fisher permite analizar si dos variables dicotómicas están asociadas cuando la muestra a estudiar es demasiado pequeña y no se cumplen las condiciones necesarias para que la aplicación del test <span class="math inline">\(\chi^2\)</span> sea adecuada. Estas condiciones exigían que los valoresesperados de al menos el 80% de las celdas en una tabla de contingencia fuesen mayores de 5.</p>
<p>En la gran mayoría de casos, el test de Fisher se aplica para comparar dos variables categóricas con dos niveles cada una (tabla 2x2).</p>
<p>A diferencia de la mayoría de las pruebas estadísticas, la prueba exacta de Fisher no usa una función matemática que estima la probabilidad de un valor de una estadística de prueba sino que calcula la probabilidad de obtener los datos observados y todos los conjuntos de datos con desviaciones más extremas, bajo la hipótesis nula de que las proporciones son las mismas.</p>
<p>Vamos a considerar el siguiente ejemplo tomado de <a href="https://www.nejm.org/doi/full/10.1056/nejmoa1205037">Nood et al. (2013)</a>. Se estudiaron pacientes con infecciones por Clostridium difficile, que causan diarrea persistente. Una variable nominal fue el tratamiento: a algunos pacientes se les administró el antibiótico vancomicina y a algunos pacientes se les realizó un trasplante fecal. La otra variable nominal fue el resultado: cada paciente se curó o no se curó. El porcentaje de personas que recibieron un trasplante fecal y se curaron (13 de 16 o el 81%) es mayor que el porcentaje de personas que recibieron vancomicina y se curaron (4 de 13 o 31%), lo que parece prometedor, Pero los tamaños de muestra parecen un poco pequeños. La prueba exacta de Fisher nos dirá si esta diferencia entre 81 y 31% es estadísticamente significativa.</p>
<p>Los datos del estudio se muestran en la siguiente tabla:</p>
<p><img src="img/4.7.13_datos.png" width="357" /></p>
<p>La hipótesis nula es que las proporciones relativas de una variable son independientes de la segunda variable; en otras palabras, las proporciones en una variable son las mismas para diferentes valores de la segunda variable. En nuestro ejemplo, la hipótesis nula es que la probabilidad de curarse es la misma si se recibe un trasplante fecal o vancomicina.</p>
<p>El test exacto de Fisher se basa en evaluar la probabilidad asociada a cada una de las tablas 2 x 2 que se pueden formar manteniendo los mismos totales de filas y columnas que los de la tabla observada. Cada una de estas probabilidades se obtiene bajo la hipótesis nula de independencia de las dos variables que se están considerando.</p>
<p><img src="img/4.7.13_fischerdatos.png" width="414" /></p>
<p>La probabilidad exacta de observar un conjunto concreto de frecuencias a, b, c y d en una tabla 2 x 2 cuando se asume independencia y los totales de filas y columnas se consideran fijos viene dada por la distribución hipergeométrica:</p>
<p><span class="math inline">\(p=\frac{(a+b)!~ (c+d)!~ (a+c)!~ (b+d)!}{n!~ a!~ b!~ c!~ d!}\)</span></p>
<p>Esta fórmula se obtiene calculando todas las posibles formas en las que podemos disponer n sujetos en una tabla 2 x 2 de modo que los totales de filas y columnas sean siempre los mismos, (a+b), (c+d), (a+c) y (b+d).</p>
<p>Así, en nuestro ejemplo, la probabilidad asociada a los datos que han sido observados es:</p>
<p><span class="math inline">\(p=\frac{12!~ 17!~ 16!~ 13!}{29!~ 3!~ 9!~ 13!~ 4!}=0.007715441\)</span></p>
<p>Con Excel© no es muy complicado obtener dicho valor:</p>
<p><img src="img/4.7.13_excel.png" width="633" /></p>
<p>Ahora, hacemos lo mismo con todas las posibles combinaciones de frecuencias que se podrían obtener con los mismos totales marginales.</p>
<p><img src="img/4.7.13_excel2.png" width="635" /></p>
<p>El valor de la p asociado al test exacto de Fisher puede entonces calcularse sumando las probabilidades de las tablas que resultan ser menores o iguales a la probabilidad de la tabla que ha sido observada, 0,0077 en nuestro ejemplo.</p>
<p>Vemos que las probabilidades menores que ese valor corresponden a valores de Enfermos con transplante de 0, 1, 2, 11 y 12. Sumando esas 5 probabilidades a la probabilidad asociada a los datos que han sido observados:</p>
<p><span class="math inline">\(p=0.007715441+0.000661+2.4E-05+2.51E-07+0.001094+3,51E-05=0.009530323\)</span></p>
<p>obtenemos un valor p de 0.009530323 que es menor que 0,05 lo que indica que aceptamos la hipótesis alternativa de que la <strong>probabilidad de curarse no es la misma si se recibe un trasplante fecal o vancomicina</strong> como habíamos intuido.</p>

</div>
</div>
<!-- </div> -->
            </section>

          </div>
        </div>
      </div>
<a href="contrastes-paramétricos-y-no-paramétricos.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/1fjmanzano/bioestadistica/edit/master/04-inferencia.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/1fjmanzano/bioestadistica/blob/master/04-inferencia.Rmd",
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
