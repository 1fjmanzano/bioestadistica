<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4.7 Métodos de Inferencia Estadística | Curso de Bioestadística</title>
  <meta name="description" content="4.7 Métodos de Inferencia Estadística | Curso de Bioestadística" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="4.7 Métodos de Inferencia Estadística | Curso de Bioestadística" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4.7 Métodos de Inferencia Estadística | Curso de Bioestadística" />
  
  
  

<meta name="author" content="Javier Manzano" />


<meta name="date" content="2022-08-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="contrastes-paramétricos-y-no-paramétricos.html"/>

<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>




<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Curso de Bioestadística</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introducción</a>
<ul>
<li class="chapter" data-level="1.1" data-path="prácticas-con-excel.html"><a href="prácticas-con-excel.html"><i class="fa fa-check"></i><b>1.1</b> Prácticas con Excel©</a></li>
<li class="chapter" data-level="1.2" data-path="prácticas-con-rstudio.html"><a href="prácticas-con-rstudio.html"><i class="fa fa-check"></i><b>1.2</b> Prácticas con RStudio</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html"><i class="fa fa-check"></i><b>2</b> Análisis Exploratorio de Datos</a>
<ul>
<li class="chapter" data-level="2.1" data-path="conceptos-previos.html"><a href="conceptos-previos.html"><i class="fa fa-check"></i><b>2.1</b> Conceptos previos</a></li>
<li class="chapter" data-level="2.2" data-path="tipos-de-variables.html"><a href="tipos-de-variables.html"><i class="fa fa-check"></i><b>2.2</b> Tipos de variables</a></li>
<li class="chapter" data-level="2.3" data-path="tablas-de-frecuencias.html"><a href="tablas-de-frecuencias.html"><i class="fa fa-check"></i><b>2.3</b> Tablas de frecuencias</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="tablas-de-frecuencias.html"><a href="tablas-de-frecuencias.html#tabla-de-frecuencias-práctica-con-excel"><i class="fa fa-check"></i><b>2.3.1</b> Tabla de frecuencias (Práctica con Excel©)</a></li>
<li class="chapter" data-level="2.3.2" data-path="tablas-de-frecuencias.html"><a href="tablas-de-frecuencias.html#tabla-de-frecuencias-práctica-con-r"><i class="fa fa-check"></i><b>2.3.2</b> Tabla de frecuencias (Práctica con R)</a></li>
<li class="chapter" data-level="2.3.3" data-path="tablas-de-frecuencias.html"><a href="tablas-de-frecuencias.html#tablas-de-frecuencias-práctica-2con-excel"><i class="fa fa-check"></i><b>2.3.3</b> Tablas de frecuencias (Práctica 2con Excel©)</a></li>
<li class="chapter" data-level="2.3.4" data-path="tablas-de-frecuencias.html"><a href="tablas-de-frecuencias.html#tablas-de-frecuencias-práctica-3-con-excel"><i class="fa fa-check"></i><b>2.3.4</b> Tablas de frecuencias (Práctica 3 con Excel© )</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="números-índices.html"><a href="números-índices.html"><i class="fa fa-check"></i><b>2.4</b> Números índices</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="números-índices.html"><a href="números-índices.html#números-índices-práctica-con-excel"><i class="fa fa-check"></i><b>2.4.1</b> Números índices (Práctica con Excel©)</a></li>
<li class="chapter" data-level="2.4.2" data-path="números-índices.html"><a href="números-índices.html#números-índices-práctica-con-r"><i class="fa fa-check"></i><b>2.4.2</b> Números índices (Práctica con R)</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="representaciones-gráficas.html"><a href="representaciones-gráficas.html"><i class="fa fa-check"></i><b>2.5</b> Representaciones gráficas</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="representaciones-gráficas.html"><a href="representaciones-gráficas.html#introduccción"><i class="fa fa-check"></i><b>2.5.1</b> Introduccción</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="diagramas-de-barras-y-sectores.html"><a href="diagramas-de-barras-y-sectores.html"><i class="fa fa-check"></i><b>2.6</b> Diagramas de barras y sectores</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="diagramas-de-barras-y-sectores.html"><a href="diagramas-de-barras-y-sectores.html#diagramas-de-barras-y-sectores-práctica-con-excel"><i class="fa fa-check"></i><b>2.6.1</b> Diagramas de barras y sectores (Práctica con Excel©)</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="histogramas.html"><a href="histogramas.html"><i class="fa fa-check"></i><b>2.7</b> Histogramas</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="histogramas.html"><a href="histogramas.html#histogramas-con-excel-prácticas"><i class="fa fa-check"></i><b>2.7.1</b> Histogramas con Excel© (Prácticas)</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="otros-gráficos.html"><a href="otros-gráficos.html"><i class="fa fa-check"></i><b>2.8</b> Otros gráficos</a></li>
<li class="chapter" data-level="2.9" data-path="medidas-de-posición-dispersión-y-forma.html"><a href="medidas-de-posición-dispersión-y-forma.html"><i class="fa fa-check"></i><b>2.9</b> Medidas de posición, dispersión y forma</a>
<ul>
<li class="chapter" data-level="2.9.1" data-path="medidas-de-posición-dispersión-y-forma.html"><a href="medidas-de-posición-dispersión-y-forma.html#medidas-de-posición-centrales"><i class="fa fa-check"></i><b>2.9.1</b> Medidas de posición centrales</a></li>
<li class="chapter" data-level="2.9.2" data-path="medidas-de-posición-dispersión-y-forma.html"><a href="medidas-de-posición-dispersión-y-forma.html#medidas-centrales-práctica"><i class="fa fa-check"></i><b>2.9.2</b> Medidas centrales (Práctica)</a></li>
<li class="chapter" data-level="2.9.3" data-path="medidas-de-posición-dispersión-y-forma.html"><a href="medidas-de-posición-dispersión-y-forma.html#medidas-de-posición-no-centrales"><i class="fa fa-check"></i><b>2.9.3</b> Medidas de posición no centrales</a></li>
<li class="chapter" data-level="2.9.4" data-path="medidas-de-posición-dispersión-y-forma.html"><a href="medidas-de-posición-dispersión-y-forma.html#medidas-no-centrales-práctica"><i class="fa fa-check"></i><b>2.9.4</b> Medidas no centrales (Práctica)</a></li>
<li class="chapter" data-level="2.9.5" data-path="medidas-de-posición-dispersión-y-forma.html"><a href="medidas-de-posición-dispersión-y-forma.html#medidas-de-dispersión"><i class="fa fa-check"></i><b>2.9.5</b> Medidas de dispersión</a></li>
<li class="chapter" data-level="2.9.6" data-path="medidas-de-posición-dispersión-y-forma.html"><a href="medidas-de-posición-dispersión-y-forma.html#medidas-de-dispersión-práctica"><i class="fa fa-check"></i><b>2.9.6</b> Medidas de dispersión (Práctica)</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="normalización-de-datos.html"><a href="normalización-de-datos.html"><i class="fa fa-check"></i><b>2.10</b> Normalización de datos</a>
<ul>
<li class="chapter" data-level="2.10.1" data-path="normalización-de-datos.html"><a href="normalización-de-datos.html#normalización-de-datos-práctica"><i class="fa fa-check"></i><b>2.10.1</b> Normalización de datos (Práctica)</a></li>
</ul></li>
<li class="chapter" data-level="2.11" data-path="medidas-de-forma.html"><a href="medidas-de-forma.html"><i class="fa fa-check"></i><b>2.11</b> Medidas de forma</a></li>
<li class="chapter" data-level="2.12" data-path="análisis-de-datos-con-excel-práctica.html"><a href="análisis-de-datos-con-excel-práctica.html"><i class="fa fa-check"></i><b>2.12</b> Análisis de datos con Excel© (Práctica)</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="relación-entre-variables.html"><a href="relación-entre-variables.html"><i class="fa fa-check"></i><b>3</b> Relación entre variables</a>
<ul>
<li class="chapter" data-level="3.1" data-path="relación-entre-variables-numéricas.html"><a href="relación-entre-variables-numéricas.html"><i class="fa fa-check"></i><b>3.1</b> Relación entre variables numéricas</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="relación-entre-variables-numéricas.html"><a href="relación-entre-variables-numéricas.html#diagramas-de-dispersión"><i class="fa fa-check"></i><b>3.1.1</b> Diagramas de dispersión</a></li>
<li class="chapter" data-level="3.1.2" data-path="relación-entre-variables-numéricas.html"><a href="relación-entre-variables-numéricas.html#covarianza"><i class="fa fa-check"></i><b>3.1.2</b> Covarianza</a></li>
<li class="chapter" data-level="3.1.3" data-path="relación-entre-variables-numéricas.html"><a href="relación-entre-variables-numéricas.html#coeficiente-de-correlación"><i class="fa fa-check"></i><b>3.1.3</b> Coeficiente de correlación</a></li>
<li class="chapter" data-level="3.1.4" data-path="relación-entre-variables-numéricas.html"><a href="relación-entre-variables-numéricas.html#correlación-entre-2-variables-numéricas-práctica"><i class="fa fa-check"></i><b>3.1.4</b> Correlación entre 2 variables numéricas (Práctica)</a></li>
<li class="chapter" data-level="3.1.5" data-path="relación-entre-variables-numéricas.html"><a href="relación-entre-variables-numéricas.html#regresión-lineal"><i class="fa fa-check"></i><b>3.1.5</b> Regresión lineal</a></li>
<li class="chapter" data-level="3.1.6" data-path="relación-entre-variables-numéricas.html"><a href="relación-entre-variables-numéricas.html#regresión-práctica"><i class="fa fa-check"></i><b>3.1.6</b> Regresión (Práctica)</a></li>
<li class="chapter" data-level="3.1.7" data-path="relación-entre-variables-numéricas.html"><a href="relación-entre-variables-numéricas.html#regresión-lineal-múltiple"><i class="fa fa-check"></i><b>3.1.7</b> Regresión lineal múltiple</a></li>
<li class="chapter" data-level="3.1.8" data-path="relación-entre-variables-numéricas.html"><a href="relación-entre-variables-numéricas.html#regresión-múltiple-práctica"><i class="fa fa-check"></i><b>3.1.8</b> Regresión múltiple (Práctica)</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="relación-entre-variable-numérica-y-cualitativa.html"><a href="relación-entre-variable-numérica-y-cualitativa.html"><i class="fa fa-check"></i><b>3.2</b> Relación entre variable numérica y cualitativa</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="relación-entre-variable-numérica-y-cualitativa.html"><a href="relación-entre-variable-numérica-y-cualitativa.html#relación-entre-variable-cualitativa-y-numérica-práctica"><i class="fa fa-check"></i><b>3.2.1</b> Relación entre variable cualitativa y numérica (Práctica)</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="relación-entre-variables-cualitativas.html"><a href="relación-entre-variables-cualitativas.html"><i class="fa fa-check"></i><b>3.3</b> Relación entre variables cualitativas</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="relación-entre-variables-cualitativas.html"><a href="relación-entre-variables-cualitativas.html#tablas-de-contingencia"><i class="fa fa-check"></i><b>3.3.1</b> Tablas de contingencia</a></li>
<li class="chapter" data-level="3.3.2" data-path="relación-entre-variables-cualitativas.html"><a href="relación-entre-variables-cualitativas.html#diagrama-de-barras-agrupadas"><i class="fa fa-check"></i><b>3.3.2</b> Diagrama de barras agrupadas</a></li>
<li class="chapter" data-level="3.3.3" data-path="relación-entre-variables-cualitativas.html"><a href="relación-entre-variables-cualitativas.html#gráficos-de-rectángulos-para-comparar-variables-cuantitativas"><i class="fa fa-check"></i><b>3.3.3</b> Gráficos de rectángulos para comparar variables cuantitativas</a></li>
<li class="chapter" data-level="3.3.4" data-path="relación-entre-variables-cualitativas.html"><a href="relación-entre-variables-cualitativas.html#gráficos-o-diagramas-de-rectángulos-práctica"><i class="fa fa-check"></i><b>3.3.4</b> Gráficos o diagramas de rectángulos (Práctica)</a></li>
<li class="chapter" data-level="3.3.5" data-path="relación-entre-variables-cualitativas.html"><a href="relación-entre-variables-cualitativas.html#diagnóstico-clínico"><i class="fa fa-check"></i><b>3.3.5</b> Diagnóstico clínico</a></li>
<li class="chapter" data-level="3.3.6" data-path="relación-entre-variables-cualitativas.html"><a href="relación-entre-variables-cualitativas.html#curvas-roc-receiver-operating-characteristic-curve"><i class="fa fa-check"></i><b>3.3.6</b> Curvas ROC (Receiver Operating characteristic Curve)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="inferencia-estadística.html"><a href="inferencia-estadística.html"><i class="fa fa-check"></i><b>4</b> Inferencia Estadística</a>
<ul>
<li class="chapter" data-level="4.1" data-path="métodos-de-muestreo.html"><a href="métodos-de-muestreo.html"><i class="fa fa-check"></i><b>4.1</b> Métodos de muestreo</a></li>
<li class="chapter" data-level="4.2" data-path="valor-p.html"><a href="valor-p.html"><i class="fa fa-check"></i><b>4.2</b> Valor p</a></li>
<li class="chapter" data-level="4.3" data-path="distribuciones-de-probabilidad.html"><a href="distribuciones-de-probabilidad.html"><i class="fa fa-check"></i><b>4.3</b> Distribuciones de probabilidad</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="distribuciones-de-probabilidad.html"><a href="distribuciones-de-probabilidad.html#distribución-normal"><i class="fa fa-check"></i><b>4.3.1</b> Distribución normal</a></li>
<li class="chapter" data-level="4.3.2" data-path="distribuciones-de-probabilidad.html"><a href="distribuciones-de-probabilidad.html#normalidad-de-los-datos"><i class="fa fa-check"></i><b>4.3.2</b> Normalidad de los datos</a></li>
<li class="chapter" data-level="4.3.3" data-path="distribuciones-de-probabilidad.html"><a href="distribuciones-de-probabilidad.html#normalidad-de-los-datos-práctica"><i class="fa fa-check"></i><b>4.3.3</b> Normalidad de los datos (Práctica)</a></li>
<li class="chapter" data-level="4.3.4" data-path="distribuciones-de-probabilidad.html"><a href="distribuciones-de-probabilidad.html#distribución-z"><i class="fa fa-check"></i><b>4.3.4</b> Distribución Z</a></li>
<li class="chapter" data-level="4.3.5" data-path="distribuciones-de-probabilidad.html"><a href="distribuciones-de-probabilidad.html#cálculo-del-valor-p-práctica"><i class="fa fa-check"></i><b>4.3.5</b> Cálculo del valor p (Práctica)</a></li>
<li class="chapter" data-level="4.3.6" data-path="distribuciones-de-probabilidad.html"><a href="distribuciones-de-probabilidad.html#distribución-t-de-student"><i class="fa fa-check"></i><b>4.3.6</b> Distribución t de Student</a></li>
<li class="chapter" data-level="4.3.7" data-path="distribuciones-de-probabilidad.html"><a href="distribuciones-de-probabilidad.html#distribución-chi2-chi-cuadrado-o-ji.cuadrado"><i class="fa fa-check"></i><b>4.3.7</b> Distribución <span class="math inline">\(\chi^2\)</span> (chi-cuadrado o ji.cuadrado)</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="estimación-de-parámetros.-intervalos-de-confianza.html"><a href="estimación-de-parámetros.-intervalos-de-confianza.html"><i class="fa fa-check"></i><b>4.4</b> Estimación de parámetros. Intervalos de confianza</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="estimación-de-parámetros.-intervalos-de-confianza.html"><a href="estimación-de-parámetros.-intervalos-de-confianza.html#intervalo-de-confianza-para-la-media"><i class="fa fa-check"></i><b>4.4.1</b> Intervalo de confianza para la media</a></li>
<li class="chapter" data-level="4.4.2" data-path="estimación-de-parámetros.-intervalos-de-confianza.html"><a href="estimación-de-parámetros.-intervalos-de-confianza.html#intervalo-de-confianza-para-la-media-práctica"><i class="fa fa-check"></i><b>4.4.2</b> Intervalo de confianza para la media (Práctica)</a></li>
<li class="chapter" data-level="4.4.3" data-path="estimación-de-parámetros.-intervalos-de-confianza.html"><a href="estimación-de-parámetros.-intervalos-de-confianza.html#intervalo-de-confianza-para-una-proporción"><i class="fa fa-check"></i><b>4.4.3</b> Intervalo de confianza para una proporción</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html"><i class="fa fa-check"></i><b>4.5</b> Contrastes de Hipótesis</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#contrastes-bilaterales-y-unilaterales"><i class="fa fa-check"></i><b>4.5.1</b> Contrastes bilaterales y unilaterales</a></li>
<li class="chapter" data-level="4.5.2" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#nivel-de-confianza-y-potencia-estadística"><i class="fa fa-check"></i><b>4.5.2</b> Nivel de confianza y potencia estadística</a></li>
<li class="chapter" data-level="4.5.3" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#tamaño-de-la-muestra"><i class="fa fa-check"></i><b>4.5.3</b> Tamaño de la muestra</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="contrastes-paramétricos-y-no-paramétricos.html"><a href="contrastes-paramétricos-y-no-paramétricos.html"><i class="fa fa-check"></i><b>4.6</b> Contrastes paramétricos y no paramétricos</a></li>
<li class="chapter" data-level="4.7" data-path="métodos-de-inferencia-estadística.html"><a href="métodos-de-inferencia-estadística.html"><i class="fa fa-check"></i><b>4.7</b> Métodos de Inferencia Estadística</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="métodos-de-inferencia-estadística.html"><a href="métodos-de-inferencia-estadística.html#test-de-student-para-muestras-independientes"><i class="fa fa-check"></i><b>4.7.1</b> Test de Student para muestras independientes</a></li>
<li class="chapter" data-level="4.7.2" data-path="métodos-de-inferencia-estadística.html"><a href="métodos-de-inferencia-estadística.html#t-test-práctica"><i class="fa fa-check"></i><b>4.7.2</b> t-test (Práctica)</a></li>
<li class="chapter" data-level="4.7.3" data-path="métodos-de-inferencia-estadística.html"><a href="métodos-de-inferencia-estadística.html#prueba-de-mann-whitney"><i class="fa fa-check"></i><b>4.7.3</b> Prueba de Mann-Whitney</a></li>
<li class="chapter" data-level="4.7.4" data-path="métodos-de-inferencia-estadística.html"><a href="métodos-de-inferencia-estadística.html#anova-de-un-factor"><i class="fa fa-check"></i><b>4.7.4</b> Anova de un factor</a></li>
<li class="chapter" data-level="4.7.5" data-path="métodos-de-inferencia-estadística.html"><a href="métodos-de-inferencia-estadística.html#prueba-de-kruskal-wallis"><i class="fa fa-check"></i><b>4.7.5</b> Prueba de Kruskal-Wallis</a></li>
<li class="chapter" data-level="4.7.6" data-path="métodos-de-inferencia-estadística.html"><a href="métodos-de-inferencia-estadística.html#t-test-emparejadas-práctica"><i class="fa fa-check"></i><b>4.7.6</b> t-test emparejadas (Práctica)</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Curso de Bioestadística</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="métodos-de-inferencia-estadística" class="section level2" number="4.7">
<h2><span class="header-section-number">4.7</span> Métodos de Inferencia Estadística</h2>
<p>Vamos a ver las técnicas de Inferencia Estadística más utilizadas en los problemas de relación entre variables. Se pretende que, dado un problema concreto, el alumno sea capaz de identificar el procedimiento estadístico a seguir, aplicarlo e interpretar los resultados. Veremos ejemplos concretos y sencillos para cada uno de los métodos presentados que, evidentemente, no son todos los existentes pero pueden ser suficientes en la gran mayoría de casos.</p>
<p>La siguiente tabla puede servirnos como resumen de los métodos y como guión a seguir durante ste apartadolo. Presentamos el método paramétrico así como su equivalente no paramétrico.</p>
<p><img src="img/4.7_tabla.png" width="601" /></p>
<div id="test-de-student-para-muestras-independientes" class="section level3" number="4.7.1">
<h3><span class="header-section-number">4.7.1</span> Test de Student para muestras independientes</h3>
<p>También conocido como <strong>t-test</strong>, es posiblemente el más utilizado en Bioestadística. Se utiliza para tratar de determinar si existe una relación significativa entre una variable cualitativa binaria (como, por ejemplo, estar sano o enfermo, ser tratado o no tratado) y una variable numérica (glucemia, presión arterial, etc)
.
El problema de relación entre ambas variables se traduce en un problema de comparación de las medias poblacionales de la variable numérica, <span class="math inline">\(\mu_1\)</span> y<span class="math inline">\(\mu_2\)</span>, correspondientes a cada una de las categorías consideradas. Es decir, la hipótesis inicial a contrastar es:</p>
<p><span class="math inline">\(H_0:\mu_1=\mu_2\)</span></p>
<p>Si seleccionamos de manera independiente sendas muestras aleatorias para cada categoría,el algoritmo al que se someten los datos se denomina <strong>test de Student para muestras independientes</strong>.</p>
<p>A pesar de la sencillez y utilidad del t-test, para que sus resultados sean válidos es necesario que se cumplan una serie de condiciones, entre las que se encuentran:</p>
<ul>
<li><p>Independencia: Las observaciones tienen que ser independientes las unas de las otras. Para ello, el muestreo debe ser aleatorio y el tamaño de la muestra inferior al 10% de la población.</p></li>
<li><p>Normalidad: Las poblaciones que se comparan tienen que seguir una distribución normal. Si bien la condición de normalidad recae sobre las poblaciones, no se suele disponer de información sobre ellas, por lo que se emplean las muestras (dado que son reflejo de la población) para determinarlo. En caso de cierta asimetría, los t-test son considerablemente robustos si el tamaño de las muestras es mayor o igual a 30.</p></li>
<li><p>Igualdad de varianza (<strong>homocedasticidad</strong>): la varianza de las poblaciones comparadas debe de ser igual. Tal como ocurre con la condición de normalidad, si no se dispone de información de las poblaciones, esta condición se ha de asumir a partir de las muestras.</p></li>
</ul>
<p>En caso de no cumplirse esta condición se puede emplear otra prueba como un Welch Two Sample t-test, que incorpora una corrección a través de los grados de libertad que compensa la diferencia de varianzas, con el inconveniente de que pierde poder estadístico.</p>
<p>Consideramos el siguiente ejemplo con 2 pares de muestras (A1, B1) y (A2, B2). Representadas mediante diagramas de cajas y bigotes:</p>
<p><img src="img/4.7.1_grph.png" width="609" /></p>
<p>Observamos que en el primer ejemplo con las variables A1, B1, no se observa diferencia significativa entre ambas mientras que en el segundo ejemplo con los datos A2, B2, al menos por término medio (y mediano), parece que hay diferencia. Vamos analizar si esa diferencia apreciada en la segunda muestra concreta es significativa.</p>
<p>Inicialmente, supondremos que ambas variables no guardan relación (<span class="math inline">\(\mu_A\)</span> = <span class="math inline">\(\mu_b\)</span>) y evaluaremos si la muestra estudiada contradice claramente dicha suposición.</p>
<p>Según el modelo inicial las medias muestrales <span class="math inline">\(\overline{x}_A\)</span> y <span class="math inline">\(\overline{x}_B\)</span> deberían ser parecidas, es decir, la diferencia (en bruto) <span class="math inline">\(\overline{x}_A\)</span> - <span class="math inline">\(\overline{x}_B\)</span> debería ser prácticamente nula (~ 0).</p>
<p>Obviamente, no podemos exigir que sea exactamente igual a 0 porque debemos asumir diferencias entre las muestras debidas exclusivamente al azar inherente al muestreo. El problema es cuantificar qué estamos dispuestos a achacar al azar, lo cual es un problema de Cálculo de Probabilidades. Para ello elegimos el estadístico de contraste. Concretamente, según el modelo inicial, la diferencia de medias muestrales debería seguir un modelo de distribución normal de media 0,de manera que, al tipificarlo, la diferencia de medias muestrales debería seguir una distribución N(0,1).</p>
<p>De esta forma, obtenemos el valor del estadístico de contraste <span class="math inline">\(t_{exp}\)</span> como:</p>
<p><span class="math inline">\(t_{exp}=\frac{\overline{x}_A- \overline{x}_B}{\sqrt{\frac{\sigma_A^2}{n_A}+\frac{\sigma_B^2}{n_B}}}\)</span></p>
<p>Este valor recoge toda la información que aporta la muestra estudiada en lo referente a la hiopótesis nula del contraste de la hipótesis</p>
<p><span class="math inline">\(H_0: \mu_1=\mu_2\)</span></p>
<p>De hecho, su valor absoluto se entiende como una distancia (tipificada) entre las dos medias muestrales que, bajo la hipótesis <span class="math inline">\(H_0: \mu_1=\mu_2\)</span>, debería ser pequeña. Más concretamente, debería ajustarse a un modelo de distribución N(0,1).</p>
<p>El valor p se define en este problema concreto como la probabilidad, según N(0,1), de obtener una distancia (tipificada) entre medias aritméticas al menos tan grande como la observada en la muestra. En otras palabras, el valor p es el área de las colas (contraste bilateral) que determinan | $t_{exp}| y -| $t_{exp}|</p>
<p><img src="img/4.7.1_texp.png" width="433" /></p>
<p>lo cual expresa en qué medida es verosímil la muestra según <span class="math inline">\(H_0\)</span>.</p>
<p>En nuestros ejemplos, obtenemos el valor del estadístico de contraste y el valor p asociado:</p>
<p><img src="img/4.7.1_valorp.png" width="604" /></p>
<p>Así, para A2, B2, el resultado es significativo (valor p &lt; 0,05), es decir, se opta por la hipótesis alternativa <span class="math inline">\(H_1:\mu_{A2} \neq \mu_{B2}\)</span> son distintas como habíamos intuído a la vista de los diagramas de cajas y bigotes.</p>
<p>Sin embargo, para A1, B1, el valor <span class="math inline">\(t_{exp}\)</span> indica una escasa diferencia entre las medias muestrales, sería verosímil desde el punto de vista de la hipótesis inicial <span class="math inline">\(H_0:\mu_{A1=\mu_{B1}}\)</span> asociándose a un valor p alto (0,2898 &gt; 0,05) según la distribución N(0,1). Se entendería entonces que la muestra es compatible con la hipótesis inicial y, en definitiva, no hay diferencia entre las medias.</p>
<p>Con la hoja de cálculo Excel® tenemos los resultados de la prueba que nos da el valor del estadístico t y el valor p así como el valor crítico de t tanto para una cola como para dos colas para una confianza del 95%. En nuestro caso, hemos supuesto que el contraste es bilateral (<span class="math inline">\(H_0:\mu_1=\mu_2\)</span>) por lo que tenemos que mirar el resultado para dos colas.</p>
<p><img src="img/4.7.1_excel.png" width="603" /></p>
</div>
<div id="t-test-práctica" class="section level3" number="4.7.2">
<h3><span class="header-section-number">4.7.2</span> t-test (Práctica)</h3>
<p>Para realizar esta práctica, debe tener descargado en su ordenador el archivo <a href="https://github.com/1fjmanzano/bioestadistica/blob/master/3.practicas.xlsx">3.practicas.xlsx</a> y abrir la hoja/pestaña correspondiente.</p>
<p>En el siguente vídeo se muestran los pasos para realizar la práctica.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/RokI2Ec8gtM" frameborder="0" allow="accelerometer; autoplay; encrypted-media;
  gyroscope; picture-in-picture" allowfullscreen>
</iframe>
</div>
<div id="prueba-de-mann-whitney" class="section level3" number="4.7.3">
<h3><span class="header-section-number">4.7.3</span> Prueba de Mann-Whitney</h3>
<p>Es una alternativa no paramétrica al test de Student que no exige la normalidad de la variable estudiada y que es, por lo tanto, de especial utilidad con muestras pequeñas. Se conoce también como la prueba de la ​suma de rangos de Wilcoxon (Wilcoxon Sum Rank Test). Básicamente consiste en una comparación de los rangos o posiciones promedios de la variable numérica en función de las categorías consideradas. En este caso, se utiliza la mediana en vez de la media.</p>
<p>Se establece como hipótesis nula que las dos muestras son iguales.</p>
<p>La idea en la que se fundamenta este test es la siguiente: si las dos muestras comparadas proceden de la misma población, al juntar todas las observaciones y ordenarlas de menor a mayor, cabría esperar que las observaciones de una y otra muestra estuviesen intercaladas aleatoriamente. Por lo contrario, si una de las muestras pertenece a una población con valores mayores o menores que la otra población, al ordenar las observaciones, estas tenderán a agruparse de modo que las de una muestra queden por encima de las de la otra.</p>
<p>Consideremos como ejemplo un ensayo clínico de Fase II diseñado para investigar la efectividad de un nuevo medicamento para reducir los síntomas del asma en niños. Un total de n = 10 participantes se asignaron al azar para recibir el nuevo medicamento o un placebo. Se les pide a los participantes que registren la cantidad de episodios de falta de aliento durante un período de 1 semana después de recibir el tratamiento asignado. Los datos se muestran a continuación.</p>
<p><img src="img/4.7.3_datos.png" width="340" /></p>
<p>¿Hay alguna diferencia en el número de episodios de falta de aliento durante un período de 1 semana en los participantes que reciben el nuevo medicamento en comparación con los que recibieron el placebo?</p>
<p>A la vista de los datos, parece que los participantes que reciben el placebo tienen más episodios de dificultad respiratoria, pero ¿es esto estadísticamente significativo?</p>
<p>En este ejemplo, el resultado es un recuento y en esta muestra los datos no siguen una distribución normal. Además, el tamaño de la muestra es pequeño (<span class="math inline">\(n_1\)</span> = <span class="math inline">\(n_2\)</span> = 5) por lo que es apropiado usar una prueba no paramétrica.</p>
<p>Establecemos como hipótesis nula</p>
<p><span class="math inline">\(H_0\)</span> las dos muestras son iguales</p>
<p>y un nivel de confianza del 95% (es decir, <span class="math inline">\(\alpha\)</span> = 0.05).</p>
<p>Si la hipótesis nula es cierta (es decir, las dos poblaciones son iguales), esperamos ver un número similar de episodios de dificultad respiratoria en cada uno de los dos grupos de tratamiento y esperaríamos ver algunos participantes con pocos episodios y otros con más episodios en cada grupo. Este no parece ser el caso con los datos observados. Se necesita una prueba de hipótesis para determinar si los datos observados son evidencia de una diferencia estadísticamente significativa en las poblaciones
.
El primer paso es asignar rangos y para ello ordenamos los datos de menor a mayor. Esto se hace en la muestra total o combinada (es decir, agrupando los datos de los dos grupos de tratamiento (n = 10)), y asignando rangos de 1 a 10, de la siguiente manera:</p>
<p><img src="img/4.7.3_rangos.png" width="323" /></p>
<p>El rango 4.5 se corresponde al valor 4 de los 2 grupos. Serían los rangos 4 y 5 pero, al ser iguales, se toma como rango 4.5. Análogamente sucede con los rangos 7 y 8.</p>
<p>Vemos que los rangos inferiores (por ejemplo, 1, 2 y 3) se asignan a las respuestas en el nuevo grupo de medicamentos, mientras que los rangos más altos (por ejemplo, 9, 10) se asignan alas respuestas en el grupo de placebo. El objetivo de la prueba es determinar si los datos observados apoyan una diferencia en las poblaciones de respuestas.</p>
<p>En las pruebas paramétricas (analizadas en los módulos sobre pruebas de hipótesis), al comparar las medias entre dos grupos, analizamos la diferencia en las medias de la muestra en relación con su variabilidad y resumimos la información de la muestra en un estadístico de prueba. Un enfoque similar se emplea aquí. Específicamente, producimos una prueba basada en los rangos.</p>
<p>Primero, sumamos los rangos de cada grupo. Para el placebo, obtenemos una suma de 37 mientras que para el nuevo medicamento, obtenemos una suma de rangos de 18.
Como notación, llamamos 1 al grupo del placebo y 2 al grupo del nuevo medicamento. De este modo, si llamamos <span class="math inline">\(R_1\)</span> a la suma de rangos del grupo 1 (placebo) y <span class="math inline">\(R_2\)</span> a la suma de rangos del grupo 2 (nuevo medicamento), tenemos que <span class="math inline">\(R_1\)</span> = 37 y <span class="math inline">\(R_2\)</span> = 18.</p>
<p>Si la hipótesis nula fuese cierta ( las dos muestras son iguales), esperamos valores similares de
<span class="math inline">\(R_1\)</span> y <span class="math inline">\(R_2\)</span>.</p>
<p>En este ejemplo, los valores más bajos (rangos inferiores) se agrupan en el nuevo grupo de nuevo medicamento (grupo 2), mientras que los valores más altos (rangos más altos) se agrupan en el grupo de placebo (grupo 1). Sin embargo, ¿es la diferencia observada en las sumas de los rangos simplemente debido al azar?</p>
<p>Para responder esto, vamos a calcular un estadístico de prueba para resumir la información de la muestra y buscar el valor correspondiente en una distribución de probabilidad.</p>
<p>El estadístico de contraste para la prueba de Mann-Whitney se denota como U y es el valor más pequeño entre <span class="math inline">\(U_!\)</span> y <span class="math inline">\(U_2\)</span> definidos como:</p>
<p><span class="math inline">\(U_1=n_1\cdot n_2+\frac{n_1(n_1+1)}{2}-R_1\)</span></p>
<p><span class="math inline">\(U_2=n_1\cdot n_2+\frac{n_2(n_2+1)}{2}-R_1\)</span></p>
<p>En nuestro ejemplo:</p>
<p><span class="math inline">\(U_1=5\cdot 5+\frac{5\cdot6}{2}-37= 40 - 37 = 3\)</span></p>
<p><span class="math inline">\(U_2=5\cdot 5+\frac{5\cdot6}{2}-18 = 40-18=22\)</span></p>
<p>El valor del estadístico de contraste U es el menor de esos valores, es decir U = 3.</p>
<p>¿Es esta evidencia en apoyo de la hipótesis nula? Antes de abordar esta pregunta, consideramos el rango del estadístico de prueba U en dos casos extremos.</p>
<p><strong>Los dos grupos son diferentes</strong></p>
<p>En este caso, suponemos que los grupos son completamente diferentes. En nuestro ejemplo, esto implica que los 5 primeros rangos corresponden a un grupo y los otros 5 al otro, es decir, si todos los números más altos de episodios de dificultad respiratoria (y, por lo tanto, todos los rangos más altos) están en el grupo de placebo, y todos los números más bajos de episodios (y rangos) están en el nuevo grupo de fármacos, entonces:</p>
<p><span class="math inline">\(R_1= 6 + 7 + 8 + 9 + 10 = 40\)</span> y <span class="math inline">\(R_2= 1 + 2 + 3 + 4 + 5 = 15\)</span> .</p>
<p>de donde <span class="math inline">\(U_1= 40-40 =0\)</span> y <span class="math inline">\(U_2=40-15=25\)</span>.</p>
<p>Así U, el menor de esos valores, es 0 cuando hay una diferencia clara entre grupos.</p>
<p><strong>Los dos grupos son iguales</strong></p>
<p>El otro caso extremo es considerar que los grupos son exactamente iguales. Así, en nuestro ejemplo, si los rangos de 2, 4, 6, 8 y 10 se asignan a la cantidad de episodios de dificultad respiratoria en el grupo de placebo y los rangos de 1, 3, 5, 7 y 9 se asignan a la cantidad de episodios de insuficiencia en el grupo de nuevo medicamento, entonces:</p>
<p><span class="math inline">\(R_1= 2 + 4 + 6 + 8 + 10 = 30\)</span> y <span class="math inline">\(R_2= 1 + 3 + 5 + 7 + 9 = 25\)</span> .</p>
<p>de donde <span class="math inline">\(U_1=40-30=10\)</span> y <span class="math inline">\(U_2=40-25=15\)</span>.</p>
<p>Así U sería 10 cuando no hay una diferencia clara entre grupos.</p>
<p>Si tenemos en cuenta que en cada prueba, <span class="math inline">\(U_1\)</span> + <span class="math inline">\(U_2\)</span> es siempre igual a n​1 ·​ n​2,​ en el ejemplo anterior, U puede variar de 0 a 25 y valores más pequeños de U apoyan la hipótesis alternativa (es decir, rechazamos H​0 si U es pequeña). El procedimiento para determinar exactamente cuándo rechazar H​0​ se describe a continuación.</p>
<p>El valor crítico de U se puede encontrar en la siguiente tabla:</p>
<p><img src="img/4.7.3_utabla.png" width="454" /></p>
<p>Para determinar el valor crítico, necesitamos los tamaños de muestra (<span class="math inline">\(n_1\)</span> = <span class="math inline">\(m_2\)</span> = 5) y nuestro nivel de significancia bilateral <span class="math inline">\(\alpha\)</span> = 0.05 (la tabla da los valores críticos para 0.05 y 0.01).</p>
<p>En nuestro caso, el valor crítico que nos da la tabla es 2 y la regla de decisión es rechazar $H_0$0 si U &lt; 2.</p>
<p>Nosotros habíamos obtenido un valor U = 3 por lo que no rechazamos <span class="math inline">\(H_0\)</span> ya que 3 &gt; 2.</p>
<p>También podemos calcular el valor p con la aplicación web <a href="https://homepage.divms.uiowa.edu/~mbognar/applets/mw.html" class="uri">https://homepage.divms.uiowa.edu/~mbognar/applets/mw.html</a>:</p>
<p><img src="img/4.7.3_bognar.png" width="490" /></p>
<p>Obtenemos un valor p = 0,02778 que es mayor, por muy poco, que 0,025 (es un contraste bilateral, de 2 colas).
De este modo, no tenemos pruebas estadísticamente significativas a <span class="math inline">\(\alpha\)</span> = 0.05 para mostrar que las dos poblaciones de episodios de dificultad respiratoria son distintos. Sin embargo, en este ejemplo, el hecho de no alcanzar una significación estadística puede deberse a una baja potencia. Los datos de la muestra sugieren una diferencia pero los tamaños de la muestra son demasiado pequeños para concluir que existe una diferencia estadísticamente significativa.</p>
<p>Para realizar esta práctica, debe tener descargado en su ordenador el archivo <a href="https://github.com/1fjmanzano/bioestadistica/blob/master/3.practicas.xlsx">3.practicas.xlsx</a> y abrir la hoja/pestaña correspondiente.</p>
<p>En el siguente vídeo, además de la explicaciones teóricas, se muestran los pasos para realizar la práctica.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/TY0fIxJTm-M" frameborder="0" allow="accelerometer; autoplay; encrypted-media;
  gyroscope; picture-in-picture" allowfullscreen>
</iframe>
</div>
<div id="anova-de-un-factor" class="section level3" number="4.7.4">
<h3><span class="header-section-number">4.7.4</span> Anova de un factor</h3>
<p>Este test es una generalización del test de Student para dos muestras independientes que se aplica para un mismo tipo de estudio y de diseño, con la salvedad de que podemos distinguir un número de categorías y, por lo tanto, de medias, mayor de dos.</p>
<p>El test que resuelve el contraste se denomina <strong>anova de una vía</strong> o factor (analisis of variance i. e. análisis de la varianza) y requiere en principio de las mismas condiciones de validez que el test de Student para dos muestras independientes, es decir;</p>
<ul>
<li>Las muestras aleatorias elegidas deben ser <strong>independientes</strong>. Además, dentro de cada tratamiento, las observaciones son independientes entre sí.</li>
<li>Las observaciones proceden de <strong>poblaciones normales</strong> de modo que las variables correspondientes al mismo tratamiento tienen la misma media.</li>
<li><strong>Hipotesis de homocedasticidad</strong>: cada población tiene la misma varianza</li>
</ul>
<p>La prueba Anova es una prueba de hipótesis que es apropiada para comparar medias de una variable continua en dos o más grupos de comparación independientes. Por ejemplo, en algunos ensayos clínicos hay más de dos grupos de comparación. En un ensayo clínico para evaluar un nuevo medicamento para el asma, los investigadores podrían comparar un medicamento experimental con un placebo y con un tratamiento estándar (es decir, un medicamento que se esté usando actualmente). En un estudio observacional como el estudio del corazón de Framingham, podría ser interesante comparar la presión arterial media o los niveles medios de colesterol en personas con bajo peso, peso normal, sobrepeso y obesidad.</p>
<p>Vamos a considerar un ejemplo con grupos independientes y una medida de resultado continua. Los grupos independientes pueden definirse por una característica particular de los participantes, como el IMC (p. ej., Bajo peso, peso normal, sobrepeso, obesidad) o por el investigador (p. ej., Asignación aleatoria de participantes a uno de los cuatro tratamientos A, B, C y D). Supongamos que el resultado es la presión arterial sistólica y queremos comprobar si existe una diferencia estadísticamente significativa en la presión arterial sistólica media entre los cuatro grupos. Los datos de muestra se organizan de la siguiente manera:</p>
<p><img src="img/4.7.4_datos.png" width="598" /></p>
<p>Las hipótesis son:</p>
<p><span class="math inline">\(H_0:\mu_1 = \mu_2 = ... = \mu_k\)</span></p>
<p><span class="math inline">\(H_1\)</span>: las medias no son iguales</p>
<p>Al aplicar ANOVA de un factor se calcula un estadístico de contraste denominado F. El estadístico F o F-test (se llama F en honor al estadístico Ronald Fisher) se obtiene al estimar la variación de las medias entre los grupos de la variable independiente y dividirla por la estimación de la variación de las medias dentro de los grupos. Así, si</p>
<ul>
<li>N es el número total de observaciones</li>
<li><span class="math inline">\(\overline{x}\)</span> es la media de todos los datos</li>
<li><span class="math inline">\(\overline{x_i}\)</span> es la media del grupo i = 1, 2, …, k</li>
</ul>
<p>El estadístico F se obtiene como:</p>
<p><span class="math inline">\(F=\frac{\frac{\sum n_j(\overline{x}_j-\overline{x})^2}{k-1}}{\frac{\sum\sum(x_i-\overline{x}_j)^2}{N-k}}\)</span></p>
<p>El cálculo del estadístico F divide la variación entre los grupos por la variación dentro de los grupos. Si las medias entre los grupos varían mucho y la media dentro de un grupo varía poco, es decir, los grupos son heterogéneos entre ellos y similares internamente, el valor de F será más alto, y por tanto, las variables estarán relacionadas. El estadístico F se distribuye según el modelo de probabilidad F de Snedecor siendo los grados de libertad del numerador el número de grupos menos 1 y los del denominador, el número total de observaciones menos el número de grupos).</p>
<p>En conclusión, <strong>cuanto más difieren las medias de la variable dependiente entre los grupos de la variable independiente, más alto será el valor de F</strong>. Si hacemos varios análisis de ANOVA de un factor, aquel con F más alto indicará que hay más diferencias y por tanto una relación más fuerte entre las variables.</p>
<p>Vamos a considerar el siguiente ejemplo: se realiza un ensayo clínico para comparar programas de pérdida de peso y los participantes se asignan al azar a uno de los programas de comparación y los participantes siguen el programa asignado durante 8 semanas. El resultado de interés es la pérdida de peso, definida como la diferencia en el peso medido al inicio del estudio (línea de base) y el peso medido al final del estudio (8 semanas), medido en kilogramos. Las diferencias positivas indican pérdidas de peso y las negativas indican ganancias de peso.</p>
<p><img src="img/4.7.4_datos2.png" width="747" /></p>
<p>Suponemos que las muestras elegidas son independientes y dentro de cada tratamiento, las observaciones son independientes entre sí, que las observaciones proceden de poblaciones normales y que cada población tiene la misma varianza.</p>
<p>Con la hoja de cálculo, hacemos el <strong>Análisis de varianza de un factor</strong> obteniendo los siguientes resultados:</p>
<p><img src="img/4.7.4_excel.png" width="748" /></p>
<p>Obtenemos pues un valor del estadístico de contraste F = 8,56 siendo el valor crítico 3,24 para α = 0,05. Además, nos indica un valor p de 0,001277742.</p>
<p>Entonces rechazamos <span class="math inline">\(H_0\)</span> porque 8,56 &gt; 3.24 (o porque 0,001 &lt; 0,05), es decir, tenemos pruebas estadísticamente significativas con una confianza del 95% (<span class="math inline">\(\alpha\)</span>= 0.05) para concluir que <strong>existe una diferencia en la pérdida de peso promedio entre las cuatro dietas</strong>.</p>
<p>Para realizar esta práctica, debe tener descargado en su ordenador el archivo <a href="https://github.com/1fjmanzano/bioestadistica/blob/master/3.practicas.xlsx">3.practicas.xlsx</a> y abrir la hoja/pestaña correspondiente.</p>
<p>En el siguente vídeo, además de la explicaciones teóricas, se muestran los pasos para realizar la práctica.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/cJM9qtGuYVw" frameborder="0" allow="accelerometer; autoplay; encrypted-media;
  gyroscope; picture-in-picture" allowfullscreen>
</iframe>
</div>
<div id="prueba-de-kruskal-wallis" class="section level3" number="4.7.5">
<h3><span class="header-section-number">4.7.5</span> Prueba de Kruskal-Wallis</h3>
<p>Hemos visto técnicas para probar la igualdad de medias en más de dos muestras independientes utilizando análisis de varianza (ANOVA).</p>
<p>Un supuesto subyacente para el uso apropiado de ANOVA es que el resultado continuo se distribuye aproximadamente de manera normal o que las muestras eran suficientemente grandes (generalmente <span class="math inline">\(n_j\)</span> &gt; 30, donde j = 1, 2, …, k y k denota el número de grupos).</p>
<p>Un supuesto adicional para el uso apropiado de ANOVA es la igualdad de varianzas en los k grupos de comparación. ANOVA es generalmente robusto cuando los tamaños de muestra son pequeños pero iguales. Cuando el resultado no se distribuye normalmente y las muestras son pequeñas, una prueba no paramétrica es apropiada.</p>
<p>Una prueba no paramétrica popular para comparar resultados entre más de dos grupos independientes es la prueba de Kruskal Wallis. La prueba de Kruskal Wallis se usa para comparar medianas entre k grupos de comparación (k&gt; 2) y algunas veces se describe como un ANOVA con los datos reemplazados por sus rangos. Las hipótesis nula y de investigación para la prueba no paramétrica de Kruskal Wallis se exponen a continuación:</p>
<p><span class="math inline">\(H_0\)</span>: Las k medianas de la población son iguales</p>
<p><span class="math inline">\(H_1\)</span>: Las k medianas de población no son todas iguales</p>
<p>El procedimiento para la prueba implica agrupar las observaciones de las k muestras en una muestra combinada, hacer un seguimiento de la muestra de cada observación y luego clasificar de 1 a N, con N = <span class="math inline">\(n_1\)</span>, <span class="math inline">\(n_2\)</span>, … , <span class="math inline">\(n_k\)</span>. Para ilustrar el procedimiento, vamos a considerar el siguiente ejemplo:</p>
<p>Un estudio clínico está diseñado para evaluar las diferencias en los niveles de albúmina en adultos que siguen dietas con diferentes cantidades de proteínas. Las dietas bajas en proteínas a menudo se prescriben para pacientes con insuficiencia renal. La albúmina es la proteína más abundante en la sangre y su concentración en el suero se mide en gramos por decilitro (g / dL). Clínicamente, las concentraciones de albúmina sérica también se utilizan para evaluar si los pacientes obtienen suficiente proteína en sus dietas. Se comparan tres dietas, que varían de 5% a 15% de proteínas, y la dieta de 15% de proteínas representa una dieta típica estadounidense. Los niveles de albúmina de los participantes después de cada dieta se muestran a continuación.</p>
<p><img src="img/4.7.5_datos.png" width="399" /></p>
<p>Parece que que hay una diferencia en los niveles de albúmina sérica entre los sujetos en las tres dietas diferentes. Como referencia, los niveles normales de albúmina están generalmente entre 3.4 y 5.4 g / dL. A simple vista, parece que los participantes que siguen la dieta con 15% de proteínas tienen niveles de albúmina más altos que los que siguen la dieta con 5% de proteínas. El problema es comprobar si esta diferencia observada es estadísticamente significativa.</p>
<p>En este ejemplo, la variable es cuantitativa continua, pero los tamaños de muestra son pequeños y no son iguales entre los grupos de comparación (<span class="math inline">\(n_1\)</span> = 3, <span class="math inline">\(n_2\)</span> = 5, <span class="math inline">\(n_3\)</span> = 4). Por lo tanto, una prueba no paramétrica es apropiada. Las hipótesis que se van a probar se dan a continuación y tomaremos un nivel de significación del 5% (<span class="math inline">\(\alpha\)</span> = 0.05).</p>
<p><span class="math inline">\(H_0\)</span>: las medianas de los grupos son iguales</p>
<p><span class="math inline">\(H_1\)</span>: al menos uno de los grupos tiene mediana distinta a las otras</p>
<p>Para realizar la prueba, primero ordenamos los datos en la muestra total combinada de 12 sujetos, de menor a mayor y asignar los rangos correspondientes:</p>
<p><img src="img/4.7.5_rangos.png" width="443" /></p>
<p>Se observa que los rangos más bajos (por ejemplo, 1, 2.5, 4) se asignan al grupo de dieta con 5% de proteínas, mientras que los rangos más altos (por ejemplo, 10, 11 y 12) se asignan al grupo de dieta con 15% de proteínas.</p>
<p>Nuevamente, el objetivo de la prueba es determinar si los datos observados apoyan una diferencia en las tres medianas de la población. Recuerde que en las pruebas paramétricas cuando comparamos medias entre más de dos grupos, analizamos la diferencia entre las medias muestrales (media cuadrada entre grupos) en relación con su variabilidad dentro del grupo y resumimos la información de la muestra en una prueba estadística (estadística F). En la prueba de Kruskal Wallis, nuevamente resumimos la información de la muestra en una estadística de prueba basada en los rangos.</p>
<p>El estadístico de prueba para la prueba de Kruskal Wallis se denota H y se define como sigue:</p>
<p><span class="math inline">\(H=\left( \frac{12}{N(N+1)}\sum_{j=1}^k \frac{R_j^2}{n_j}\right) -3(N+1)\)</span></p>
<p>donde k es el número de grupos de comparación, N el tamaño total de la muestra, <span class="math inline">\(n_j\)</span> es el tamaño de la muestra en el grupo j y R​j​ es la suma de los rangos en el grupo j.</p>
<p>En este ejemplo, <span class="math inline">\(R_1\)</span> = 7.5, <span class="math inline">\(R_2\)</span> = 30.5 y <span class="math inline">\(R_3\)</span> = 40. Recuerde que la suma de los rangos siempre será igual a <span class="math inline">\(\frac{n(n-1)}{2}\)</span>.</p>
<p>El estadístico H para este ejemplo se calcula de la siguiente manera:</p>
<p><span class="math inline">\(H=\left( \frac{12}{N(N+1)}\sum_{j=1}^k \frac{R_j^2}{n_j}\right) -3(N+1)= \frac{12}{12\cdot 13}\left( \frac{7,5^2}{3}+\frac{30,5^2}{5}+\frac{40^2}{4}\right) -3(13)=7.52\)</span></p>
<p>Ahora debemos determinar si el estadístico de prueba obtenido H respalda la hipótesis nula o de investigación. Una vez más, esto se hace estableciendo un valor crítico de H.</p>
<ul>
<li><p>Si el valor observado de H es mayor o igual al valor crítico, rechazamos <span class="math inline">\(H_0\)</span> a favor de <span class="math inline">\(H_1\)</span>.</p></li>
<li><p>Si el valor observado de H es menor que el valor crítico, no rechazamos <span class="math inline">\(H_0\)</span></p></li>
</ul>
<p>El valor crítico de H se puede encontrar en la siguiente tabla:</p>
<p><img src="img/4.7.5_tabla.png" width="150%" /></p>
<p>Para determinar el valor crítico apropiado, al tener 3 observaciones con tamaños de muestra <span class="math inline">\(n_1\)</span> = 3, <span class="math inline">\(n_2\)</span> = 5 y <span class="math inline">\(n_3\)</span>= 4 con un nivel de significación <span class="math inline">\(\alpha\)</span> = 0.05, buscamos en la fila 5, 4, 3 y la columna <span class="math inline">\(\alpha\)</span> = 0.05. Para este ejemplo, el valor crítico es 5,656.</p>
<p>Por lo tanto rechazamos <span class="math inline">\(H_0\)</span> porque 7,52 &gt; 5,656 y concluimos que <strong>al menos uno de los grupos tiene mediana distinta a las otras entre las tres dietas diferentes</strong>.</p>
<p>Hay que tener en cuenta que la tabla contiene valores críticos para la prueba de Kruskal Wallis para pruebas que comparan 3, 4 o 5 grupos con tamaños de muestra pequeños. Si hay 3 o más grupos de comparación y 5 o más observaciones en cada uno de los grupos de comparación, se puede mostrar que el estadístico de prueba H se aproxima a una distribución chi-cuadrado con el número de grados de libertad df = k - 1.</p>
<p>Por lo tanto, en una prueba de Kruskal Wallis con 3 o más grupos de comparación y 5 o más observaciones en cada grupo, el valor crítico para la prueba se puede encontrar en la tabla de Valores críticos de la distribución <span class="math inline">\(\chi^2\)</span> a continuación.</p>
<p><img src="img/4.7.5_tabla2.png" width="150%" /></p>
<p>Vamos a verlo con otro ejemplo</p>
<p>¿El ejercicio físico alivia la depresión? Realizamos un estudio con un grupo de personas deprimidas de manera equivalente. Luego asignamos a cada persona al azar a uno de tres grupos: sin ejercicio; 20 minutos de ejercicio físico por día o 60 minutos de ejercicio por día. Al final de un mes, le pedimos a cada participante que califique su grado de depresión en una escala Likert que va desde 1 (totalmente deprimido) hasta 100 (totalmente feliz) obteniendo los siguientes resultados:</p>
<p><img src="img/4.7.5_datos2.png" width="264" /></p>
<p>Parece que hay diferencias entre los 3 grupos:</p>
<p><img src="img/4.7.5_tabla3.png" width="375" /></p>
<p>Para comprobar si hay diferencias estadísticamente significativas (α = 0.05), aplicamos la prueba de Kruskal-Wallis.
Las hipótesis nula y de investigación para la prueba no paramétrica de Kruskal Wallis son:</p>
<p><span class="math inline">\(H_0\)</span>: las medianas de los grupos son iguales</p>
<p><span class="math inline">\(H_1\)</span>: al menos uno de los grupos tiene mediana distinta a las otras</p>
<p>Establecemos el rango para cada medición:</p>
<p><img src="img/4.7.5_rangos2.png" width="329" /></p>
<p>El estadístico de prueba para la prueba de Kruskal Wallis es:</p>
<p><span class="math inline">\(H=\left( \frac{12}{N(N+1)}\sum_{j=1}^k \frac{R_j^2}{n_j}\right) -3(N+1)\)</span></p>
<p>En este ejemplo, <span class="math inline">\(R_1\)</span> = 77, <span class="math inline">\(R_2\)</span> = 80.5 y <span class="math inline">\(R_3\)</span> = 142,5 con 8 datos en cada grupo para un total de 24. Así, haciendo los cálculos, obtenemos:</p>
<p><span class="math inline">\(H=\left( \frac{12}{N(N+1)}\sum_{j=1}^k \frac{R_j^2}{n_j}\right) -3(N+1)= \frac{24}{24\cdot 25}\left( \frac{77^2}{8}+\frac{80,5^2}{8}+\frac{142,5^2}{8}\right) -3(25)=6,78875\)</span></p>
<p>Como hemos comentado, en este segundo ejemplo usamos la tabla de la chi-cuadrado. Tenemos que los grados de libertad son igual al número de grupos menos uno, es decir 3 -1 = 2 grados de libertad (df).</p>
<p>Entonces, en la tabla de la <span class="math inline">\(\chi^2\)</span> buscamos el valor crítico para 2 grados de libertad con un nivel de significación <span class="math inline">\(\alpha\)</span> = 0.05 obteniendo un valor <span class="math inline">\(\chi^2_{.0.05}\)</span> = 5,991.</p>
<p>Comenzamos comparando nuestro H de 6,79 con 5.99. Con 2 grados de libertad, es probable que un valor de Chi-cuadrado tan grande como 5.99 ocurra por casualidad solo 5 veces en cien, es decir, tiene una p de 0,05. Nuestro valor obtenido de 6,79 es incluso mayor que esto, por lo que esto nos dice que nuestro valor de H es incluso menos probable que ocurra por casualidad. Nuestra H ocurrirá por casualidad con una probabilidad de menos de 0,05.</p>
<p>Así, podemos concluir que la prueba de Kruskal-Wallis indica que hay un efecto significativo del ejercicio en los niveles de depresión (H = 6,79, p &lt; 0,05). Las medias de cada grupo sugieren que, en comparación con el grupo de control “sin ejercicio”, la depresión se redujo significativamente con 60 minutos de ejercicio diario, pero no con 20 minutos de ejercicio. Hay que tener en cuenta que una puntuación más alta en este estudio equivale a un nivel de ánimo más alto y, por lo tanto, un nivel de depresión más bajo).</p>
<p>Sin utilizar la tabla, podríamos haber obtenido el valor p correspondiente a 6,79 con 2 grados de libertad utilizando la hoja de cálculo o la aplicación web:</p>
<p><img src="img/4.7.5_valorp.png" width="667" /></p>
</div>
<div id="t-test-emparejadas-práctica" class="section level3" number="4.7.6">
<h3><span class="header-section-number">4.7.6</span> t-test emparejadas (Práctica)</h3>
<p>Para realizar esta práctica, debe tener descargado en su ordenador el archivo <a href="https://github.com/1fjmanzano/bioestadistica/blob/master/3.practicas.xlsx">3.practicas.xlsx</a> y abrir la hoja/pestaña correspondiente.</p>
<p>En el siguente vídeo, además de la explicaciones teóricas, se muestran los pasos para realizar la práctica.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/-LY2CwmM7q8" frameborder="0" allow="accelerometer; autoplay; encrypted-media;
  gyroscope; picture-in-picture" allowfullscreen>
</iframe>

</div>
</div>
<!-- </div> -->
            </section>

          </div>
        </div>
      </div>
<a href="contrastes-paramétricos-y-no-paramétricos.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/1fjmanzano/bioestadistica/edit/master/04-inferencia.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/1fjmanzano/bioestadistica/blob/master/04-inferencia.Rmd",
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
