[["index.html", "Curso de Bioestadística Capítulo 1 Introducción", " Curso de Bioestadística Javier Manzano 2022-08-18 Capítulo 1 Introducción La Estadística se ocupa de estudiar los métodos y procedimientos para recoger y analizar datos. Podemos distinguir 2 bloques genéricos: Análisis exploratorio de datos: técnicas y métodos necesarios para clasificar, representar y resumir datos. Inferencia Estadística: procedimientos para extraer conclusiones "],["prácticas-con-excel.html", "1.1 Prácticas con Excel©", " 1.1 Prácticas con Excel© A lo largo del curso utilizaremos hojas de cálculo (Excel o LibreOffice) para ejemplificar estos conceptos y técnicas de una forma sencilla. Puede descargarse los libros de Excel con las prácticas desde estos enlaces: 1.Prácticas 2.Prácticas 3.Prácticas Para cada práctica, tendrá un vídeo explicativo de cómo realizarla. "],["prácticas-con-rstudio.html", "1.2 Prácticas con RStudio", " 1.2 Prácticas con RStudio A pesar de la potencia de las hojas de cálculo, hay ocasiones en las que ciertas tareas resultan demasiado arduas. En paralelo al uso de Excel©, vamos a utilizar un recurso más potente para almacenar y trabajar con los datos: el lenguaje R. R es un lenguaje funcional e interpretado que, de manera interactiva, permite operar sobre listas, vectores y matrices de datos de manera extremadamente sencilla. Gran parte de su versatilidad estriba en la inmediatez para aplicar cualquier operación sobre todos los elementos de una de esas estructuras (o partes de ellas) en un solo paso, así como en la extensa biblioteca de paquetes disponibles (en The Comprehensive R Archive Network CRAN) para resolver prácticamente cualquier problema que se nos ocurra (obviamente siempre circunscrito al campo del análisis de datos). RStudio es un entorno de desarrollo integrado (IDE) para el lenguaje de programación R. Para descargar e instalar R y RStudio: Descargue e instale R desde https://cran.r-project.org Descargue e instale RStudio Desktop desde https://www.rstudio.com/products/rstudio/download/ "],["análisis-exploratorio-de-datos.html", "Capítulo 2 Análisis Exploratorio de Datos", " Capítulo 2 Análisis Exploratorio de Datos En este apartado estudiaremos los conceptos básicos y las técnicas elementales para analizar un conjunto de datos y descubrir estructuras y relaciones entre ellos. Muchos de ellos son de sobra conocidos pero creemos que es importante citarlos todos evitando dar por conocidos aspectos básicos necesarios para estudios más avanzados "],["conceptos-previos.html", "2.1 Conceptos previos", " 2.1 Conceptos previos Vamos a definir una serie de conceptos que nos van a aparecer al hacer estudios estadísticos: Población: un grupo de individuos que comparten al menos una característica en común. En un nivel macro, esto podría referirse a toda la humanidad. En el nivel de una investigación clínica, la población puede referirse a las personas con cierta enfermedad o factor de riesgo. Es bastante posible tener una población bastante pequeña, es decir, en el caso de una condición muy rara. Los hallazgos de un estudio infieren sus resultados a una población más grande. Individuo: miembro de una población sobre el que se quiere investigar. Muestra: es una selección de miembros dentro de la población. La investigación se realiza utilizando ese conjunto de muestras de miembros y los resultados se pueden inferir a la población de la que se tomó la muestra. Este uso del análisis estadístico hace posible la investigación clínica ya que generalmente es casi imposible incluir a la población completa. Para que la muestra sea representativa es fundamental diseñ̃ar un buen método de muestreo. Parámetro: es valor que se calcula a partir de todos los valores en una población completa. Por ejemplo, si conociéramos la edad de cada individuo en la Tierra y calculamos la edad promedio o media, esa edad sería un parámetro Estadístico: es un valor que se calcula a partir de todos los valores de una muestra. Por ejemplo, la edad media de todos los participantes en un estudio sería un estadístico. Variable: hace referencia a cada una de las características de los individuos que son objeto de estudio. "],["tipos-de-variables.html", "2.2 Tipos de variables", " 2.2 Tipos de variables De cara a aplicar distintas técnicas estadísticas, es muy importante saber de qué tipo es la variable con la que estamos trabajando ya que, dependiendo del tipo de variable, se aplican distintas técnicas o tests estadísticos. En un principio podemos distinguir 2 tipos: Cualitativas: expresan una cualidad. Cuantitativas: toman valores numéricos. Ejemplos de variables cualitativas son el sexo de un individuo, su lugar de nacimiento, el tipo de enfermedad o la respuesta a un tratamiento (mejora, no varía o empeora). Así, podemos distinguir 2 tipos de variables cualitativas: Nominal: caracteriza un elemento de la población. En estas variables, no tienen sentido ni el orden ni operaciones aritméticas como el cálculo de la media. Ejemplo de variables cualitativas nominales son el sexo de un individuo o si está enfermo o sano.. Ordinal: implica una posición ordenada o calificación. En el ejemplo anterior de enfermo o sano, podemos matizar y establecer grados de intensidad como leve, moderado o grave. De este modo, se establece un orden en esta clasificación. Respecto a las variables cuantitativas o numéricas, atendiendo a la escala de medida, podemos distinguir 2 tipos: De Intervalo: además de clasificar y ordenar, establece diferencias numéricas exactas entre valores y permite fijar distancias entre valores a través de una unidad de medida y unos valores numéricos precisos. No existe el cero absoluto, se trata de un cero arbitrario o convencional. Por ejemplo, la temperatura de un paciente es una variable cuantitativa de intervalo ya que el 0 es convencional (pensemos en grados Celsius o Farenheit) ya que no significa ausencia de temperatura. De Razón :están definidas con el nivel de medićión de intervalo y ,además ,se puede establecer un origen o punto cero que representa la ausencia absoluta de la característica que se desea medir. Como ejemplos de este tipo de variables podemos citar la edad de un paciente, el número de plaquetas por microlitro o la presión sanguínea sistólica. De cara a implementar estudios estadísticos, debemos ser prácticos a la hora de entender el tipo de variable. Hay veces en que variables cualitativas conviene que tomen valores discretos, por ejemplo, si un paciente desarrolla una complicación (valor 1) o no (valor 0). Y, por otro lado, cabe considerar como variables continuas a variables que, en el fondo, son discretas. Un ejemplo de esa situación puede ser la variable número de plaquetas por microlitro que es discreta pero, a efectos prácticos, se considera continua debido al gran número de valores distintos que toma. "],["tablas-de-frecuencias.html", "2.3 Tablas de frecuencias", " 2.3 Tablas de frecuencias La construcción de tablas de frecuencias a partir de datos ha constituido hasta hace bien poco la herramienta para la elaboración de gráficos y el cálculo de valores típicos en un estudio estadístico. Con la aparición de programas estadísticos (SPSS© o R) que generan automáticamente los gráficos y cálculos deseados, las tablas de frecuencia han perdido cierto protagonismo. Sin embargo no las vamos a obviar ya que son muy útiles para entender conceptos básicos en cualquier estudio estadístico, nos van a permitir introducir la notación matemática en Estadística y, con ellas, vamos a realizar nuestras primeras prácticas con la hoja de cálculo. Una tabla de frecuencias básica nos indica qué valores concretos se dan en la muestra y con qué frecuencia. Vamos a ilustrarlo con una serie de ejemplos sencillos para distintos tipos de variables. Ejemplo 1: en un estudio médico con 50 pacientes, se consideró la variable “número de piezas dentales perdidas” obteniéndose los siguientes datos: 1, 3, 0, 3, 2, 0, 2, 0, 0, 2, 0, 1, 0, 0, 1, 0, 1, 4, 0, 0, 1, 4, 0, 1, 0, 0, 1, 0, 0, 2, 5, 4, 2, 1, 1, 0, 0, 0, 5, 1, 3, 0, 1, 0, 1, 2, 0, 2, 1, 0 El tamaño de la muestra es n = 50. Si llamamos X a la variable Número de piezas dentales perdidas, vemos que ésta toma 6 valores distintos X = {0, 1, 2, 3, 4, 5]. Definimos: Frecuencia absoluta \\(f_i\\) del valor \\(x_i\\): número de datos iguales a \\(x_i\\). Frecuencia relativa \\(p_i\\) del valor \\(x_i\\): cociente entre la frecuencia absoluta y el tamaño de la muestra \\(\\left( p_i=\\frac{f_i}{n} \\right)\\) Porcentaje del valor \\(x_i\\): producto de la frecuencia relativa por 100. Frecuencia absoluta acumulada \\(F_i\\) del valor \\(x_i\\): número de datos menores o iguales a xi. Frecuencia relativa acumulada \\(H_i\\) del valor \\(x_i\\): cociente entre la frecuencia absoluta acumulada y el tamaño de la muestra\\(\\left( H_i=\\frac{h_i}{n} \\right)\\) Porcentaje acumulado del valor \\(x_i\\): producto de la frecuencia relativa acumulada por 100. Así, en la siguiente imagen puede verse la tabla de frecuencias del ejemplo anterior (con 2 decimales) construida con Excel. 2.3.1 Tabla de frecuencias (Práctica con Excel©) Para realizar esta práctica, debe tener descargado en su ordenador el archivo 1.practicas.xlsx. En el siguente vídeo se muestran los pasos para realizar la práctica. 2.3.2 Tabla de frecuencias (Práctica con R) Para realizar esta práctica, abra RStudio. Le aparecerá una ventana como la siguiente: En el espacio de trabajo (Workspace) de abajo a la izquierda no tiene más que escribir (o copiar y pegar) el código que se le irá proporcionando y pulsar la tecla enter para ejecutarlo. Recordamos que nuestra práctica consiste en obtener tablas de frecuencias de un conjunto de datos. Recordamos que en nuestra práctica tenemos datos de 50 pacientes con el número de piezas dentales perdidas. Con el siguiente código ejecutable, vamos a almacenar esos 50 datos en un vector (serie de números) con el nombre de piezas_perdidas. R utiliza la expresion &lt;- para definir el nombre con el que almacenamos los datos, piezas_perdidas en nuestro ejemplo, y la función c( ) ( de concatenar) para almacenar los datos. Ejecute el siguente código en RStudio (tiene la opción de copiarlo haciendo clic en el icono Copy to Clipboard): piezas_perdidas &lt;- c(1, 3, 0, 3, 2, 0, 2, 0, 0, 2, 0, 1, 0, 0, 1, 0, 1, 4, 0, 0, 1, 4, 0, 1, 0, 0, 1, 0, 0, 2, 5, 4, 2, 1, 1, 0, 0, 0, 5, 1, 3, 0, 1, 0, 1, 2, 0, 2, 1, 0) Verá que en la ventana Environment (arriba a la derecha) le ha aparecido un elemento llamado piezas_perdidas de tipo numérico y longitud 50. RStudio ha almacenado el vector con los 50 datos. Vamos a obtener de forma muy sencilla la primera tabla de frecuencias absolutas ejecutando el siguiente código: table(piezas_perdidas) ## piezas_perdidas ## 0 1 2 3 4 5 ## 22 13 7 3 3 2 Así, R ha contado el número de datos del vector piezas_perdidas y en el resultado podemos ver que hay 22 pacientes con 0 piezas perdidas, 13 con 1 pieza perdida, etc. Para las frecuencias relativas, vamos a almacenar la tabla de frecuencias absolutas con el monbre de tabla y obtendremos la tabla de frecuencias relativas con la función prop.table: tabla &lt;- table(piezas_perdidas) prop.table(tabla) ## piezas_perdidas ## 0 1 2 3 4 5 ## 0.44 0.26 0.14 0.06 0.06 0.04 Pruebe a comparar estos resultados con los de Excel©. Así, la frecuencia relativa de pacientes con 1 pieza perdida es 0.26 (26%). Ahora, podemos obtener la tabla de frecuencias absolutas acumuladas: cumsum(tabla) ## 0 1 2 3 4 5 ## 22 35 42 45 48 50 Así, hay 45 pacientes con 3 o menos piezas dentales perdidas. 2.3.3 Tablas de frecuencias (Práctica 2con Excel©) Para realizar esta práctica, debe tener descargado en su ordenador el archivo 1.practicas.xlsx y abrir la hoja/pestaña 350 datos. En el siguente vídeo se muestran los pasos para realizar la práctica. 2.3.4 Tablas de frecuencias (Práctica 3 con Excel© ) Para realizar esta práctica, debe tener descargado en su ordenador el archivo 1.practicas.xlsx y abrir la hoja/pestaña 350 datos. En el siguente vídeo se muestran los pasos para realizar la práctica. "],["números-índices.html", "2.4 Números índices", " 2.4 Números índices Cuando tenemos datos a lo largo del tiempo, conviene compararlos en base a un valor determinado llamado periodo base. Así, los números índices muestran el movimiento de valores en una serie de tiempo convirtiendo las cantidades reales medidas en forma de índice o cantidades relativas. Estos valores se especifican en relación con un período base, por lo general designado como 100 o 100%. Por ejemplo, consideremos los datos anuales del número de fallecidos en accidentes de tráfico 30 días después del accidente: Fuente: https://www.epdata.es/muertos-accidentes-trafico-vias-urbanas-interurbanas/83166792-22f9-4c0f-8be9-392f0dd432a1/espana/106 Podemos representar gráficamente estos datos con un sencillo diagrama de líneas: De este modo, si consideramos como periodo base el año 1993, los números índices del resto de años se calculan dividiendo el número de fallecidos en cada año entre el número de fallecidos en 1993 (multiplicando por 100), es decir: \\(I_{t,1993}=\\frac{x_t}{x_{1993}}\\cdot 100\\) Así, obtenemos: Vemos entonces que, en porcentaje, la disminución en 1994 respecto a 1993 fue del 12% (número índice = 88). Puede interesar elegir otro periodo base. En nuestro ejemplo, vemos que a partir de 2003, se produce una disminución bastante significativa en el número de fallecidos debida, probablemente, al impacto de campañas de seguridad vial. Si ahora consideramos como periodo base el año 2003, tendremos: \\(I_{t,20033}=\\frac{x_t}{x_{2003}}\\cdot 100\\) Podemos representar esa variación en base al año 2003 con un diagrama de barras: 2.4.1 Números índices (Práctica con Excel©) Para realizar esta práctica, debe tener descargado en su ordenador el archivo 1.practicas.xlsx y abrir la hoja/pestaña Nº accidentes. En el siguente vídeo se muestran los pasos para realizar la práctica. 2.4.2 Números índices (Práctica con R) Para realizar la práctica en R, debemos cargar los datos. El archivo original está disponible en este enlace Puede descargar el archivo en formato csv (Comma Separated Values) en su ordenador. Le pedirá que se registre. La otra opción es visualizar el contenido de ese archivo en este enlace Vemos que los datos están en 3 columnas (de nombres “Año”; “Periodo”; “Accidentes de tráfico”) separados por puntos y comas. Debajo, vemos varias filas de metadatos del documento. Prodecemos a cargar los datos desde la web y almacenarlos con el nombre data. Primero cargamos el paquete (library) readr de R y utilizamos la instrucción real_delim que nos permite leer el archivo. Finalmente indicamos con delim = “;” que los datos están separados por puntos y comas. Así, ejecute el siguiente código en RStudio: library(readr) data &lt;- read_delim(&quot;https://raw.githubusercontent.com/1fjmanzano/bioestadistica/master/fallecidos_trafico.csv&quot;, delim = &quot;;&quot;) ## Warning: One or more parsing issues, see `problems()` for details ## Rows: 41 Columns: 3 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: &quot;;&quot; ## chr (2): Año, Periodo ## dbl (1): Accidentes de tráfico ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. Vemos que nos han aparecido algunos mensajes de aviso. En la ventana Environment (arriba a la derecha) verá que ha aparecido un elemento llamado data, de tipo spec_tbl_df (data frame) con 41 observaciones de 3 variables. Puede visualizar su contenido haciendo clic en el icono de la derecha o, también, ejecutando la orden View(data) en la consola. Arriba a la izquierda le aparecerá una ventana con el contenido cargado en data. Vemos que disponemos de datos desde 1993 hasta 2019. Procedemos a la limpieza del archivo antes de obtener los números índices. Vemos que para nuestra práctica, únicamente necesitamos las filas 1 ,2, 3, …, 27, es decir, nos sobran las filas 28:41. Vamos a seleccionar las filas 1 a 27. En nuestro conjunto de datos (data frame) necesitamos especificar dos dimensiones, filas y columnas. Para ello, usamos corchetes con la sintaxis objeto[filas,columnas]. Con la instrucción 1:27 antes de la coma (filas), seleccionamos las filas 1 a 27. Después de la coma no indicamos nada. Seguimos guardando los datos con el nombre de data. data &lt;- data[1:27,] Si comprueba el resultado, verá que han desaparecido las filas 28:41. En la ventana de Environment verá que se ha actualizado la dimension de data (ahora 27 obd. de 3 variables). Para nuestro propósito, nos sobra la seguna columna Periodo. Procedemos a eliminarla usando corchetes. Ahora, como es una columna, debemos indicar la instrucción -2 (elimina la segunda columna) después de la coma. data &lt;- data[, -2] Puede comprobar que ha desaparecido la segunda columna (27 obs. de 2 variables). Vamos a obtener un gráfico con los datos. Queremos representar los datos de la segunda columna Accidentes de tráfico. Para indicar a R que esos datos son los que queremos, usamos el símbolo del dólar $ después del nombre del dataframe. Además, como el nombre de la variable Accidentes de tráfico tiene espacios, debemos escribirlo entre comillas simples. R y en general cualquier lenguaje de programación, “se llevan mal” con los espacios en blanco. Para generar el gráfico, usamos la función plot(). plot(data$`Accidentes de tráfico`) R ha generado un gráfico de puntos con los 27 datos disponibles (de 1993 a 2019). Si queremos un gráfico de líneas, no tenemos más que añadir una coma y la instrucción type = “l”. plot(data$`Accidentes de tráfico`,type = &quot;l&quot;) Finalmente, vemos que en el eje X (horizontal) no aparecen los años. Para ello, podemos considerar los datos como una serie de tiempo time.series con la función ts() del dataframe data (quitando la primera columna) e indicando el comienzo y el final para, finalmente, obtener el gráfico con plot(). time.series &lt;- ts(data[,-1], start=1993, end=2019) plot(time.series) Vamos a generar en el dataframe data una columna con los números índices en base al número de fallecidos por accidente de tráfico en 1993. Comenzamos guardando el la variable fallecidos1993 dicho valor (de 6.378). Para ello, indicamos que en la columna Accidentes de tráfico de data queremos el primer valor ([1]). fallecidos1993 &lt;- data$`Accidentes de tráfico`[1] fallecidos1993 ## [1] 6.378 Cuidado porque el valor numérico tiene un punto decimal lo que indica que la unidad de medida es de miles como podíamos observar en el eje vertical de los gráficos anteriores. Ahora, definimos una nueva columna i1993 sin más que dividir los valores de la columna Accidentes de tráfico entre el valor fallecidos1993. data$i1993 &lt;- data$`Accidentes de tráfico`/fallecidos1993 Puede comprobar que, ahora. el dataframe data tiene 27 obs. de 3 variables. La columna que acabamos de generar, tiene valores numériicos con muchos decimales. Podemos redondear a 2 decimales. data$i1993 &lt;- format(round(data$i1993,2)) Si queremos obtener los números índices en base a 2003, no tenemos más que ejecutar el siguiente código teniendo en cuenta que, ahora, queremos el valor 11 (correspondiente al año 2003) de la columna Accidentes de tráfico. fallecidos2003 &lt;- data$`Accidentes de tráfico`[11] data$i2003 &lt;- data$`Accidentes de tráfico`/fallecidos2003 "],["representaciones-gráficas.html", "2.5 Representaciones gráficas", " 2.5 Representaciones gráficas 2.5.1 Introduccción Se suele decir que una imagen vale más que mil palabras y esto es muy cierto en estudios estadísticos. Como ejemplo de la aplicación de visualización de datos en ámbito médico, podemos citar el caso de Florence Nightingale considerada la madre de la enfermería moderna. En 1854 es enviada a prestar servicios en la guerra de Crimea (actual Ucrania). Allí, Nightingale y sus compañeras de trabajo reformaron a fondo el hospital con lo que lograron reducir la tasa de mortalidad desde el 40% al 2%. Para ilustrar las causas de mortalidad del ejército en el hospital que dirigía, en vez de utilizar complejas tablas con datos numéricos, hizo uso de gráficos que facilitaban la comprensión de los hechos para que las autoridades comprendieran la situación y tomaran medidas al respecto. Así, dependiendo del tipo de variable que estemos estudiando, será más conveniente utilizar un gráfico u otro. Diagrama de las causas de la mortalidad del ejército del Este. Fuente: Wikipedia "],["diagramas-de-barras-y-sectores.html", "2.6 Diagramas de barras y sectores", " 2.6 Diagramas de barras y sectores Este tipo de gráficos, de sobra conocidos, se utilizan para variables cualitativas y cuantitativas discretas. Así, los datos de la siguiente tabla: están representados como diagrama de barras y gráfico de sectores: Las hojas de cálculo tienen herramientas que permiten cambiar parámetros de configuración en estos gráficos añadiendo leyendas, porcentajes, etc. Generalmente, comparamos mejor utilizando medidas lineales que circulares. Otras forma de ver esos datos es con un diagrama de barras apiladas: Además, los diagramas de barras agrupados permiten comparar variables de forma visual. Por ejemplo, los datos de la siguiente tabla, contienen datos sobre la evolución de 3 grupos de pacientes (a los que se les puede haber suministrado distintos tratamientos, por ejemplo). Así, los diagramas de barras: aportan una información visual de dichos datos comparándolos por grupo o por evolución. El posterior análisis estadístico de estos datos permitirá establecer si hay diferencias significativas entre estos grupos y la evolución pero con estas gráficas, podemos intuir estos resultados. 2.6.1 Diagramas de barras y sectores (Práctica con Excel©) Para realizar esta práctica, debe tener descargado en su ordenador el archivo 1.practicas.xlsx y abrir la hoja/pestaña correspondiente. En los siguentes vídeos se muestran los pasos para realizar la práctica. "],["histogramas.html", "2.7 Histogramas", " 2.7 Histogramas Los histogramas son una generalización de los diagramas de barras en los que la variable es cuantitativa continua o discreta con un número elevado de valores. Un ejemplo podemos verlo en el siguiente gráfico: en el que tenemos agrupados, por intervalos de edad, el número de defunciones en España en 2017. Los datos han sido tomados del Instituto Nacional de Estadística Podemos ver el mismo histograma en el que, en vez de tener frecuencias absolutas, tenemos frecuencias relativas (proporciones): Comparando los diagramas de las frecuencias absolutas y relativas observamos que la escala del eje vertical ha variado, pero la representación gráfica es exactamente la misma pero, en este caso, si el ancho de cada rectángulo (barra) es 1, al sumar el área de todos los rectángulos obtenemos un valor total igual a 1. Amplitud y número de intervalos: En el ejemplo anterior, todos los intervalos excepto el primero, tienen la misma amplitud (5 años) y los teníamos definidos en una columna. Puede ocurrir que tengamos un gran número de datos (más de 1000) con los que podemos definir el número de intervalos (discretización). En esta imagen se ve el histograma correspondiente al peso de 1030 pacientes con el número de intervalos (rangos) generado automáticamente con Excel©: Y, en esta imagen, vemos el histograma del mismo conjunto de datos con 10 intervalos (rangos): 2.7.1 Histogramas con Excel© (Prácticas) Para realizar esta práctica, debe tener descargado en su ordenador el archivo 1.practicas.xlsx y abrir la hoja/pestaña correspondiente. En los siguentes vídeos se muestran los pasos para realizar las prácticas. "],["otros-gráficos.html", "2.8 Otros gráficos", " 2.8 Otros gráficos Existen muchos otros tipos de gráficos que son útiles dependiendo de la información que queramos mostrar. The Extreme Presentation(tm) Method "],["medidas-de-posición-dispersión-y-forma.html", "2.9 Medidas de posición, dispersión y forma", " 2.9 Medidas de posición, dispersión y forma Cuando tenemos un conjunto de datos, podemos obtener información muy resumida de los mismos a través de una serie de valores. En este apartado veremos las siguientes medidas y valores: 2.9.1 Medidas de posición centrales La media aritmética de un conjunto de datos numéricos es quizá la medida más intuitiva que tenemos todos en mente. Simplemente, se obtiene sumando los valores de todos los datos y se divide el valor obtenido entre el número de datos. Por ejemplo, para el siguiente conjunto de datos: 4, 5, 6, 9, 11, 13, 64 la media \\(\\overline{x}\\) es 16: \\(\\frac{4+5+6+9+11+13+64}{7}=16\\) La expresión matemática, siendo \\(x_i\\) los valores, n el número de datos y \\(f_i\\) la frecuencia absoluta es: \\(\\overline{x}=\\frac{\\sum_{i=1}^{n}x_i}{n}= \\frac{1}{n}\\sum_{i=1}^{k}x_i\\cdot f_i\\) La mediana es el valor que está justo en medio de todos los demás valores. Eso significa que la mitad de los valores son más altos y la mitad son más bajos que este valor, independientemente de cuánto más altos o bajos sean. En el ejemplo anterior 4, 5, 6, 9, 11, 13, 64 tenemos 7 valores ordenados de menor a mayor. El 9 es el que ocupa el valor central por lo que la mediana es 9. Si el número de datos fuese par, habría 2 valores centrales por lo que la mediana se calcularía como la media aritmética de esos dos valores. Así, en este sencillo ejemplo, vemos que la media es 15 y la mediana es 9. El valor 15 es intuitivamente una sobreestimación ya que sólo uno de los valores (64) es más grande que él, lo que hace que de alguna manera no sea representativo de los otros valores. Es por esto que siempre es interesante calcular media y mediana en un conjunto de datos. Además, algunos test estadísticos se aplican sobre la mediana. La moda es el valor que más se repite y se suele utilizar para describir variables cualitativas. Puede haber más de una moda. En este ejemplo sobre el grado de una enfermedad: la moda es “Moderado”. En este otro conjunto de datos: 5, 6, 7, 8, 9, 11, 5, 3, 2, 4, 5, 5, 9, 10, 5, 11 la moda es 5. 2.9.2 Medidas centrales (Práctica) Para realizar esta práctica, debe tener descargado en su ordenador el archivo 1.practicas.xlsx y abrir la hoja/pestaña correspondiente. En el siguente vídeo se muestran los pasos para realizar la práctica. 2.9.3 Medidas de posición no centrales El cuantil de orden p de un conjunto de datos es un valor tal que la proporción de valores menores que él es p. De este modo, la mediana es el cuantil más conocido ya divide la muestra en dos partes de proporción 0.5 (50%). Así, la mediana es un cuantil de orden 0.5. Los cuartiles dividen al conjunto de datos en 4 partes, cada una de ellas de frecuencia 25%. Se denotan por \\(Q_1\\), \\(Q_2\\) y \\(Q_3\\). Así, el porcentaje de valores menores que \\(Q_1\\) es el 25%, el porcentaje de valores menores que \\(Q_2\\) es el 50% (\\(Q_2\\) es la mediana) y el porcentaje de valores menores que \\(Q_3\\) es el 75%. Si dividimos la muestra, el conjunto de datos en 100 partes iguales, obtenemos los percentiles, que van de \\(p_1\\) a \\(p_{99}\\). De nuevo, la mediana coincide con el percentil 50 y los cuartiles \\(Q_1\\) y \\(Q_3\\) coinciden con \\(p_{25}\\) y \\(p_{75}\\) respectivamente. 2.9.4 Medidas no centrales (Práctica) Para realizar esta práctica, debe tener descargado en su ordenador el archivo 1.practicas.xlsx y abrir la hoja/pestaña correspondiente. En el siguente vídeo se muestran los pasos para realizar la práctica. 2.9.5 Medidas de dispersión Este tipo de medidas nos dan información sobre si nuestro conjunto de datos tiene mucha variabilidad o no, es decir, si los datos están muy dispersos o concentrados en torno a las medidas centrales. Veamos intuitivamente qué información nos aportan las medidas de dispersión. Si vemos los histogramas de estas dos distribuciones de 200 datos cada una: en ambos casos la media es 9.8. Las escalas son iguales y podemos observar que en la distribución A, los valores están más agrupados en torno a la media que en la distribución B donde están más separados, más “dispersos”. Las medidas de dispersión son números que concretan esta idea. El rango es la diferencia entre el máximo valor y el mínimo valor de un conjunto de datos. El rango intercuartílico (IQR) es la diferencia entre el cuartil 3 y el cuartil 1, es decir, indica la amplitud del intervalo en el que está el 50% de los datos. Es un dato que complementa a la mediana. El dato del rango intercuartílico y la mediana permite hacer una representación gráfica de los datos mediante los diagramas de cajas y bigotes (boxplot o box and whisker plot) además de localizar datos atípicos (outliers). En el ejemplo utilizado para la media y la mediana: 4, 5, 6, 9, 11, 13, 64 comprobamos que el valor 64 es un dato atípico (outlier) ya que está muy distante del resto. Veamos otro ejemplo. En esta tabla tenemos 30 datos distribuidos en 3 grupos. Podemos obtener el rango y el rango intercuartílico: y los diagramas de cajas y bigotes de estas 3 distribuciones de datos: Al estar en sentido vertical, en cada caso el valor inferior de la caja corresponde a \\(Q_1\\) y el superior a \\(Q_3\\). Así, la longitud de la caja es el rango intercuartílico. La línea en la caja es el valor de la mediana y aparece el valor de la media con una X. Para los datos A y C, los extremos de los bigotes corresponden a los valores máximo y mínimo. En el caso de los datos B, vemos 2 puntos arriba y abajo correspondientes a 2 valores atípicos. Hay varias formas de calcular la longitud de los bigotes. Uno de ellos es considerar que un valor es atípico si se encuentra 1.5 veces de la longitud de la caja. La varianza es la medida de dispersión más utilizada en estadística ya que tiene en cuenta la distancia, la diferencia de todos los valores con respecto a la media. Si a cada dato le restamos la media y sumamos todos esos resultados, es fácil comprobar que vamos a obtener 0: \\(\\sum(x_i-\\overline{x})=0\\) ya que al sumarse las diferencias de los datos superiores, positivas al ser mayores de la media, éstas se van a anular con las inferiores, negativas al ser menores que la media. Una solución es tomar todos esas diferencias con signo positivo, es decir, en valor absoluto. Así obtenemos la desviación media: \\(D=\\frac{\\sum|x_i-\\overline{x}|}{n}\\) Sin embargo, esta solución conlleva algunos problemas técnicos al considerarse positivos números que, en realidad, son negativos. Para analizar eficientemente las diferencias a la media, la idea es elevar esas diferencias al cuadrado, obteniéndose así siempre números positivos. Por otro lado, al elevar al cuadrado se ponderan los valores cercanos y lejanos a la media. De este modo, se calcula la media de los cuadrados de las diferencias de los datos a la media. Esa es la varianza: \\(s^2=\\frac{\\sum(x_i-\\overline{x})^2}{n}\\) Así, la unidad de medida de la varianza es la unidad de medida que con la que estemos trabajando elevada al cuadrado (pulsaciones al cuadrado, peso al cuadrado, etc.). La varianza también puede obtenerse como: $s^2= - ^2 $ En este caso, se calculan los cuadrados de los datos, se suman y se divide entre el número de datos. Al resultado se le resta el cuadrado de la media. La unidad de medida de la varianza es la unidad de medida de los datos elevada al cuadrado. Para utilizar la misma unidad de medida que los datos, se define la desviación típica o estándar como la raíz cuadrada de la varianza. Se suele denotar por s (si es relativa una muestra) o con la letra griega sigma minúscula (si es relativa a toda la población): \\(\\sigma=\\sqrt{\\frac{\\sum(x_i-\\overline{x})^2}{n}}\\) La desviación típica es un complemento de la media ya que indica el grado de dispersión de los datos respecto al centro de los datos, respecto a la media. La desigualdad de Chevyshev es ampliamente utilizada para distinguir datos que se separan “excesivamente” de la media. Cuando sabemos que los datos toman valores “normales” como los resultados de un análisis de sangre, podemos establecer que: en el intervalo \\((\\overline{x}-2\\sigma, \\overline{x}+2\\sigma)\\) están, al menos, el 75% de los datos en el intervalo \\((\\overline{x}-3\\sigma, \\overline{x}+3\\sigma)\\) están, al menos, el 88% de los datos. Finalmente, podemos considerar esa desviación en porcentaje para poder comparar conjuntos de datos con distintas medias. Obtenemos el coeficiente de variación dividiendo la desviación típica entre la media y multiplicando el resultado por 100: \\(C.V.=\\frac{\\sigma}{n}\\cdot 100\\) 2.9.6 Medidas de dispersión (Práctica) Para realizar esta práctica, debe tener descargado en su ordenador el archivo 1.practicas.xlsx y abrir la hoja/pestaña correspondiente. En el siguente vídeo se muestran los pasos para realizar la práctica. "],["normalización-de-datos.html", "2.10 Normalización de datos", " 2.10 Normalización de datos Frecuentemente se deben ajustar los valores medidos en diferentes escalas respecto a una escala común, a menudo previamente a un proceso de realizar promedios. Este ajuste se conoce como normalización. Existen varios tipos de normalizaciones en estadística. Vamos a comentar dos de ellos. Normalización basada en la unidad (Max-Min): se define una nueva variable X’ teniendo en cuenta los valores máximo y mínimo de los datos originales X obteniéndose datos entre 0 y 1. La nueva variable se define por: \\(X&#39;=\\frac{X-X_{min}}{X_{max}-X_{min}}\\) Normalización residual: en este caso, se define una nueva variable X’ teniendo en cuenta la media y la desviación típica: \\(X&#39;=\\frac{X-\\mu}{\\sigma}\\) Cabe indicar que la media y la desviación típica pueden ser la de la población (\\(\\mu\\) y \\(\\sigma\\) en caso de ser conocidas) o la de la muestra (\\(\\overline{x}\\) y s). Si los datos se distribuyen “normalmente”, la variable X’ tiene media 0 y desviación típica 1. 2.10.1 Normalización de datos (Práctica) Para realizar esta práctica, debe tener descargado en su ordenador el archivo 1.practicas.xlsx y abrir la hoja/pestaña correspondiente. En el siguente vídeo se muestran los pasos para realizar la práctica. "],["medidas-de-forma.html", "2.11 Medidas de forma", " 2.11 Medidas de forma Observemos los histogramas de estos 3 conjuntos de datos: En naranja, podemos ver la curva correspondiente a cada distribución de datos; la línea morada corresponde a la media y la línea verde corresponde a la median. Así, los 3 conjuntos de datos presentan distintas formas: podemos observar que los datos A están agrupados a la izquierda presentando una cola hacia la derecha (mediana &lt; media). Los datos B están centrados en torno a la media y la mediana (mediana ≈ media) con 2 colas a ambos lados y los datos están agrupados a la derecha con una cola a la izquierda (media &lt; mediana). Para cuantificar la simetría (skewness) de los datos, partimos de un resultado matemático: si los datos son simétricos (datos B), la suma de las diferencias a la media elevadas al cubo es 0, es decir: \\(\\sum(x_i-\\overline{x})^3=0\\) Si los datos presentan la cola a la derecha (datos A), ese valor es positivo mientras que si la cola está a la izquierda (datos C), ese valor es negativo. De este modo, el valor que cuantifica esta forma de los datos se conoce como coeficiente de asimetría y se calcula dividiendo la media de los cubos de las diferencias a la media entre el cubo de la desviación típica: \\(skewness=\\frac{\\frac{1}{n}\\sum(x_i-\\overline{x})^3}{\\sigma^3}\\) Al numerador, es decir, a la media de los cubos de las desviaciones a la media, se le conoce como tercer momento central denotado por \\(\\mu_3\\). De este modo, \\(skewness=\\frac{\\mu_3}{\\sigma^3}\\) Cuando los datos son simétricos, vamos a ver otro valor, la curtosis**, que nos da idea de cómo se distribuyen los datos entre el centro y los extremos. Si nos fijamos en esta imagen: vemos la curva asociada a 3 distribuciones simétricas. En azul, vemos unos datos que se distribuyen “normalmente” (curva llamada mesocúrtica). En naranja, la curva es más plana (llamada platicúrtica) y en gris, la curva es más apuntada (llamada leptocúrtica). En una distribución normal (que estudiaremos más adelante), se cumple que el cuarto momento central \\(\\mu_4=\\frac{1}{n}\\sum(x_i-\\overline{x})^4\\) esto es, la media de las desviaciones a la media elevadas a la cuarta potencia, dividida entre la desviación típica elevada a la cuarta es 3: \\(\\frac{\\mu_4}{\\sigma^4}=3\\) si la distribución es normal. De este modo, para ver el “apuntamiento” de una distribución, se compara con ese valor 3 obteniéndose el coeficiente de curtosis: \\(curtosis=\\frac{\\frac{1}{n}\\sum(x_i-\\overline{x})^4}{\\sigma^4}-3=\\frac{\\mu_4}{\\sigma^4}-3\\) De este modo, se ha restado 3 para que: si la curva es mesocúrtica, la curtosis es 0. si es leptocúrtica, el coeficiente de curtosis es positivo. si es platicúrtica, el coeficiente de curtosis es negativo. "],["análisis-de-datos-con-excel-práctica.html", "2.12 Análisis de datos con Excel© (Práctica)", " 2.12 Análisis de datos con Excel© (Práctica) Para realizar esta práctica, debe tener descargado en su ordenador el archivo 1.practicas.xlsx y abrir la hoja/pestaña correspondiente. En el siguente vídeo se muestran los pasos para realizar la práctica. "],["relación-entre-variables.html", "Capítulo 3 Relación entre variables", " Capítulo 3 Relación entre variables Una vez estudiada descriptivamente una variable, vamos a proceder a estudiar la relación entre dos o más variables de un modo descriptivo. Entendemos que existe relación o dependencia entre dos variables cuando un cambio en el valor de una de ellas se asocia a un cambio en el de la otra. Si no es el caso, se habla de independencia de variables. Vamos a estudiar la relación entre dos variables numéricas y trataremos muy brevemente el estudio de la relación entre una variable cualitativa y otra numérica terminando con el estudio de la relación entre variables cualitativas. De este modo, veremos cómo calcular valores que nos van a indicar la relación entre variables así como realizar representaciones gráficas que nos van a ayudar a interpretar esas posibles relaciones. "],["relación-entre-variables-numéricas.html", "3.1 Relación entre variables numéricas", " 3.1 Relación entre variables numéricas Para llevar a cabo el estudio de la relación entre dos variables numéricas es preciso efectuar un análisis previo de las mismas por separado. Para ello, la representaremos gráficamente y calcularemos los respectivos valores típicos. Para unificar la notación empleada, consideremos n individuos sobre los que se han medido 2 variables cuantitativas llamadas X e Y. De este modo, obtenemos n pares de datos numéricos representados por (\\(x_i\\), \\(y_i\\)) donde i = 1,2, …, n. Veamos un sencillo ejemplo: en la siguiente tabla podemos observar el peso X (kg.) y la estatura Y (cm.) de 12 personas: Debemos comenzar con un estudio estadística descriptivo de cada variable por separado, que podría incluir sendos histogramas, así como al menos una medida de centralización y otra de dispersión (generalmente la media y la desviación típica). A continuación, vamos a realizar el estudio descriptivo de la relación entre ambas variables. 3.1.1 Diagramas de dispersión Para representar gráficamente las dos variables se utilizan los diagramas de dispersión o nubes de puntos. Son gráficos que se obtiene al representar en unos ejes de coordenadas todos los pares correspondientes a los datos observados. En nuestro ejemplo, el diagrama de dispersión quedaría: En este otro caso, tenemos representada la relación entre la tensión arterial diastólica (TAD) y el nivel de colesterol medidos en n = 1000 adultos: En el primer caso, vemos una relación directa (o positiva) entre las variables peso y altura, es decir, el aumento de una implica el aumento en la otra. Daría lo mismo si hubiésemos representado las variables cambiadas de eje, la relación se mantendría. En el segundo caso, ya no es tan evidente la relación entre variables TAD - colesterol. Finalmente, en este diagrama de dispersión para las variables concentración de hormona paratiroidea, [Pth], y concentración de calcio, [Ca]: Observamos que hay una relación inversa o negativa, pues el aumento en la concentración de la hormona se asocia a una disminución del calcio en sangre. En los ejemplos presentados, la relación entre variables es constante, es decir, las nubes de puntos se agrupan en torno a una línea recta que puede ser creciente o decreciente o que será plana cuando la relación sea nula. Este tipo de relación se denomina lineal y es el objeto principal de estudio en este capítulo. Con ello no queremos decir que sea la única relación posible, aunque sí es la más sencilla. 3.1.2 Covarianza Vamos a obtener unos valores que cuantifiquen la relación entre variables que acabamos de ver. Para ello, vamos a utilizar el ejemplo de las alturas y pesos de las n = 12 personas anterior: En este caso, la media y desviación típica de cada variable es: Un valor que relacione las 2 variables debe incluir información aportada por ambas. Se define así la covarianza (\\(\\sigma_{xy}\\)) como: \\(\\sigma_{xy}=\\frac{\\sum(x_i-\\overline{x})(y_i-\\overline{y})}{n}\\) Es decir, se multiplica la desviación a la media correspondiente de cada par de datos, se suman y se divide por el número total de pares de datos. La covarianza puede ser tanto positiva como negativa y su valor está comprendido entre los siguientes valores: \\(-\\sigma_x\\cdot \\sigma_y \\leq \\sigma_{xy} \\leq \\sigma_x\\cdot \\sigma_y\\) En nuestro ejemplo, la covarianza estará medida en kg·cm y estará entre -612,64 y +612,64. Utilizando la hoja de cálculo, obtenemos para nuestro ejemplo que \\(\\sigma_{xy}\\) = 566.27 kg·cm. Vamos a interpretar ese valor. Si representamos el diagrama de dispersión añadiendo las líneas correspondientes a las medias vemos 4 cuadrantes: Los puntos situados en los cuadrantes superior derecha e inferior izquierda, aportan valores positivos a la suma \\((x_i-\\overline{x})(y_i-\\overline{y})\\) mientras que los puntos en los otros 2 cuadrantes (superior izquierdo e inferior derecho) aportan valores negativos. En nuestro ejemplo, son mayoría los valores positivos por lo que la suma resultante es un número positivo grande (566.27) en relación a los valores de las variables y al máximo valor que puede tomar (\\(\\sigma_x \\cdot \\sigma_y\\)) = 612.64). 3.1.3 Coeficiente de correlación Como hemos visto, la covarianza tiene una unidad de medida igual al producto de las unidades de medida de las variables y un valor que depende de las desviaciones típicas de las mismas. Para obtener un valor sin unidades que nos relacione la dependencia de variables, se define el coeficiente de correlación lineal de Pearson (\\(r_{xy}\\)) como el cociente entre la covarianza y el producto de las desviaciones típicas de las variables, es decir: \\(r_{xy}=\\frac{\\sigma_{xy}}{\\sigma_x \\cdot \\sigma_y}\\) Se suele representar simplemente como r, no tiene unidades (es adimensional) y toma valores entre -1 y 1. Así, cuanto más cerca esté de 1, la correlación (dependencia entre variables) ser ámás fuerte y positiva, cuanto más cerca esté de -1, la correlación será fuerte y negativa. Cuando tome valores cercanos a 0, los datos no están correlacionados. En nuestro ejemplo sobre pesos y altura de 12 personas, el coeficiente de correlación es 0,924, valor que confirma lo que habíamos observado en el diagrama de dispersión: correlación fuerte positiva entre las variables peso y altura. En el caso del ejemplo TAD - colesterol, el valor de r es 0,187, es decir, no hay correlación o la correlación es muy débil lo que queda claro observando el diagrama de dispersión con las líneas de referencia en las medias con muchos puntos en los 4 cuadrantes: Finalmente, en el ejemplo de las variables concentración de hormona paratiroidea, [Pth], y concentración de calcio, [Ca]: el valor de r es -0,982 lo que conforma la correlación fuerte negativa observada en el diagrama de dispersión. 3.1.4 Correlación entre 2 variables numéricas (Práctica) Para realizar esta práctica, debe tener descargado en su ordenador el archivo 2.practicas.xlsx y abrir la hoja/pestaña correspondiente. En el siguente vídeo se muestran los pasos para realizar la práctica. 3.1.5 Regresión lineal Como hemos comentado, cuando hay una correlación lineal fuerte, los puntos se pueden “ajustar” a una recta que minimice las distancias de los puntos a dicha recta. Esto es importante cuando una de las variables puede medirse de forma sencilla y la otra no ya que puede usarse una variable para pronosticar el valor de la otra, Así, llamamos recta de regresión a la recta que mejor se ajusta a una nube de puntos. La regresión pretende explicar el comportamiento de una variable según los valores que toma la otra . Si deseamos saber el valor de la variable Y según los valores que toma X, la regresión de llama de Y sobre X. La recta de regresión de Y sobre X debe hacer mínima la suma de las distancias entre las ordenadas de cada punto y la recta. Su expresión será de la forma \\(Y=B_0+B_1X\\) Así, conocidos \\(B_0\\) y \\(B_1\\), con un valor de X podemos estimar el correspondiente valor de Y. Matemáticamente, la ecuación de la recta de regresión se obtiene con: \\(y-\\overline{y}=\\frac{\\sigma_{xy}}{\\sigma_x^2}(x-\\overline{x})\\) En el ejemplo de las alturas y los pesos, tenemos: \\(\\overline{x}=57\\), \\(\\overline{y}=152.08\\), \\(\\sigma_x=21.68\\) y \\(\\sigma_{xy}=566.27\\). de donde la ecuación de la recta de regresión es: \\(y-152.08=\\frac{566.27}{21.68^2}(x-57)\\) Calculando y despejando y, obtenemos la ecuación de la recta de regresión: \\(y=83.434+1.2044x\\). Así, dando un valor a x (peso), a partir de los datos podemos estimar un valor y (altura) en base a los datos disponibles. 3.1.6 Regresión (Práctica) Para realizar esta práctica, debe tener descargado en su ordenador el archivo 2.practicas.xlsx y abrir la hoja/pestaña correspondiente. En el siguente vídeo se muestran los pasos para realizar la práctica. 3.1.7 Regresión lineal múltiple Hay situaciones en las que queremos estimar en valor de una variable Y en función no de una sino de varias variables \\(X_1\\), \\(X_2\\), … , \\(X_n\\). Es lo que se conoce como regresión lineal múltiple. Si suponemos 3 variables \\(X_1\\), \\(X_2\\) y \\(X_3\\), el objetivo es encontrar una ecuación del tipo: \\(Y=B_0+B_1X_1+B_2X_2+B_3X_3\\) Con Excel® es posible encontrar esos coeficientes \\(B_1\\), \\(B_2\\) y \\(B_3\\) mediante el complemento de análisis de datos. 3.1.8 Regresión múltiple (Práctica) Para realizar esta práctica, debe tener descargado en su ordenador el archivo 2.practicas.xlsx y abrir la hoja/pestaña correspondiente. En el siguente vídeo se muestran los pasos para realizar la práctica. "],["relación-entre-variable-numérica-y-cualitativa.html", "3.2 Relación entre variable numérica y cualitativa", " 3.2 Relación entre variable numérica y cualitativa Para realizar el estudio descriptivo de la relación entre un variable cualitativa y otra numérica, podemos realizar la comparación de las medias que dicha variable numérica alcanza en las distintas categorías de la variable cualitativa. Esto lo podemos visualizar con diagramas de cajas y bigotes. Por ejemplo, en el artículo Data analysis using Box and Whisker Plot for Lung Cancer se utilizan los diagramas de cajas y bigotes para comparar resultados de personas con cáncer de pulmón: Según el artículo, al comparar los 3 grupos (ex fumadores, no fumadores y fumadores), los fumadores tienen mayores posibilidades de verse afectados por un cáncer de pulmón. Dado que la gráfica de caja de los fumadores tiene una mediana más alta, cuando se comparan con la edad, las personas fumadoras de 25 a 40 años son los que tienen posibilidades más altas de contraer cáncer. Otro tipo de comparativa algo más compleja se puede realizar al comparar al menos 2 variables numéricas y una cualitativa o, lo que es lo mismo, estudiar la relación entre 2 variables numéricas en diferentes categorías de una variable cualitativa. Como ejemplo, tenemos un estudio de 40 hombres y 40 mujeres a las que se midió el perímetro de la cintura (X) y la cadera (Y). Al representar el diagrama de dispersión con la recta de regresión, se obtuvo: En naranja aparecen los datos correspondientes a los hombres y en azul a las mujeres. Podemos apreciar que, para valores similares de cadera, los hombres tienden a presentar valores de cintura superiores a los de las mujeres. Eso explica que el índice cintura cadera tienda a ser superior en hombres que en mujeres. 3.2.1 Relación entre variable cualitativa y numérica (Práctica) Para realizar esta práctica, debe tener descargado en su ordenador el archivo 2.practicas.xlsx y abrir la hoja/pestaña correspondiente. En el siguente vídeo se muestran los pasos para realizar la práctica. "],["relación-entre-variables-cualitativas.html", "3.3 Relación entre variables cualitativas", " 3.3 Relación entre variables cualitativas Vamos a estudiar la relación entre variables cualitativas. Es lógico pensar que existe relación entre ambas variables cuando un cambio de categoría en una se asocia a un cambio de categoría en la otra y viceversa. Es relativamente sencillo expresar un carácter de forma cualitativa pero, desde un punto de vista estadístico, el tratamiento de las variables cualitativas es mucho más engorroso que el de las numéricas, en especial a la hora de estudiarlas conjuntamente. En este apartado estudiaremos las variables de forma descriptiva, es decir, mediante tablas, representaciónes gráficas y cálculo de los valores típicos. A diferencia del estudio de variables numéricas, la representación en forma de tabla de los datos tiene interés en nuestro caso porque, al tratarlos de manera categórica, se registrarán muchas repeticiones. 3.3.1 Tablas de contingencia Para realizar una tabla de contigencia, tenemos una muestra de n individuos (u observaciones) sobre los que se evalúan simultáneamente dos variables cualitativas X e Y. Se construye una tabla con tantas columnas como valores tome X y tantas filas como valores tome Y en la distribución. Hallamos la frecuencia absoluta de cada par de valores de la variable (X,Y). Para ello, contamos el número de veces que se repite ese par de valores en la distribución y lo anotamos en la celda correspondiente. Esa es la frecuencia absoluta conjunta. Después, se añade una última fila y una última columna en la tabla que contiene las frecuencias absolutas de las variable X e Y por separado. Estas son las frecuencias marginales. Veamos un ejemplo; tenemos datos de 258 personas categorizadas por la variable colesterol, con tres grupos: bajo, medio y alto y la variable sexo, con dos grupos: hombre y mujer. La tabla de contingencia de los datos es: Así, tenemos 115 hombres con el colesterol bajo (frecuencia absoluta conjunta), 99 mujeres en total (frecuencia marginal) así como 52 individuos con el colesterol medio (frecuencia marginal). Una vez tabulados los datos, podemos calcular proporciones (porcentajes) de especial utilidad para estudios estadísticos de relación entre variables. Comenzamos con la proporción marginal, esto es, las frecuencias relativas correspondientes a las frecuencias marginales. Utilizamos la notación \\(\\widehat{P}\\) con un circunflejo para indicar que son proporciones obtenidas de una muestra. P se reserva para indicar una probabilidad referida a toda la población. \\(\\widehat{P}(Bajo)=\\frac{168}{258}=0.651\\) \\(\\widehat{P}(Medio)=\\frac{52}{258}=0.202\\) \\(\\widehat{P}(Alto)=\\frac{38}{258}=0.147\\) \\(\\widehat{P}(Hombre)=\\frac{159}{258}=0.616\\) \\(\\widehat{P}(Mujer)=\\frac{99}{258}=0.384\\) ˆ Vamos con las proporciones condicionadas. Con \\(\\widehat{P}(Hombre/Medio)\\) entendemos la proporción de individuos que, con nivel de colesterol medio, son hombres. Sin embargo, \\(\\widehat{P}(Alto/M ujer)\\) sería la proporción de individuos que, siendo mujeres, tendrían el colesterol alto. Así calculamos por filas: \\(\\widehat{P}(Bajo/Hombre)=\\frac{115}{159}=0.723\\) \\(\\widehat{P}(Medio/Hombre)=\\frac{23}{159}=0.145\\) \\(\\widehat{P}(Alto/Hombre)=\\frac{21}{159}=0.132\\) \\(\\widehat{P}(Bajo/Mujer)=\\frac{53}{99}=0.535\\) \\(\\widehat{P}(Medio/Mujer)=\\frac{29}{99}=0.293\\) \\(\\widehat{P}(Alto/Mujer)=\\frac{17}{99}=0.172\\) Y por columnas: \\(\\widehat{P}(Hombre/Bajo)=\\frac{115}{168}=0.685\\) \\(\\widehat{P}(Hombre/Medio)=\\frac{23}{52}=0.442\\) \\(\\widehat{P}(Hombre/Alto)=\\frac{21}{38}=0.553\\) \\(\\widehat{P}(Mujer/Bajo)=\\frac{53}{168}=0.315\\) \\(\\widehat{P}(Mujer/Medio)=\\frac{29}{52}=0.558\\) \\(\\widehat{P}(Mujer/Alto)=\\frac{17}{38}=0.447\\) Por último, las proporciones conjuntas indican la proporción de individuos que cumplen 2 características de las variables. Por ejemplo, P(Mujer y Bajo) = P(Mujer \\(\\cap\\) Bajo) indica la proporción de individuos que son mujeres y tienen el colesterol bajo. \\(\\widehat{P}(Bajo \\cap Hombre)=\\frac{115}{258}=0.446\\) \\(\\widehat{P}(Medio \\cap Hombre)=\\frac{23}{258}=0.089\\) \\(\\widehat{P}(Alto \\cap Hombre)=\\frac{21}{258}=0.081\\) \\(\\widehat{P}(Bajo \\cap Mujer)=\\frac{53}{258}=0.205\\) \\(\\widehat{P}(Medio \\cap Mujer)=\\frac{29}{258}=0.112\\) \\(\\widehat{P}(Alto \\cap Mujer)=\\frac{17}{258}=0.066\\) Una propiedad de estas proporciones se deriva del concepto de probabilidad condicionada. Establece que: \\(\\widehat{P}(A \\cap B)=\\widehat{P}(A) \\cdot \\widehat{P}(B/A)\\) Por ejemplo, según este resultado: \\(\\widehat{P}(Bajo \\cap Hombre)=\\widehat{P}(Bajo) \\cdot \\widehat{P}(Hombre/Bajo)\\) Vamos a comprobarlo con las proporciones obtenidas anteriormente: \\(\\left. \\begin{array}{r} \\hat{P}(Bajo \\cap Hombre)=0,446 \\\\ \\hat{P}(Bajo)=0,651 \\\\ \\hat{P}(Hombre/Bajo)=0,685 \\end{array} \\right\\} \\Rightarrow 0,446=0,651\\cdot 0,685\\) 3.3.2 Diagrama de barras agrupadas Otra forma de comparar variables cuantitativas es mediante el uso de diagramas de barras agrupadas. En nuestro ejemplo, podemos agrupar los datos en función del nivel de colesterol: o en función del sexo: Estos diagramas nos proporcionan una información visual sobre los posibles cambios en las proporciones tanto por filas como por columnas. En términos estadísticos, entendemos que la correlación a nivel muestral entre las dos variables cualitativas observadas es más fuerte cuanto mayores sean las diferencias entre las proporciones condicionadas al pasar de una categoría a otra. 3.3.3 Gráficos de rectángulos para comparar variables cuantitativas Para medir intuitivamente el grado de correlación entre variables cuantitativas, vamos a utilizar un tipo de gráfico, el de rectángulos. Seguimos con nuestro ejemplo: Una forma muy interesante de visualizar esos datos es mediante diagramas de rectángulos en los que el área de cada rectángulo es proporcional a cada frecuencia. Así, el diagrama de rectángulos de la tabla anterior es el siguiente: Para comprobar si las variables estudiadas (nivel colesterol y sexo en nuestro ejemplo) son independientes, podemos compararlas con los datos teóricos o esperados que tendríamos si hay independencia entre variables. Para calcular dichos datos esperados en caso de independencia entre variables, partimos de un resultado de teoría de probabilidades: “si 2 sucesos son independientes la probabilidad de que ocurran a la vez es el producto de la probabilidad de que ocurra uno por la probabilidad de que ocurra otro”. En notación matemática: \\(P(A \\cap B)= P(A) \\cdot P(B)\\) Esto lo podemos ver de una forma sencilla con el lanzamiento de dos monedas. Los resultados son independientes ya que el resultado de lanzar una moneda (cara o cruz) no influye en el resultado obtenido al lanzar la otra moneda. Así, la probabilidad de obtener 2 caras es el producto de obtener cara en una moneda (0.5) multiplicado por la probabilidad de obtener cara con la otra moneda (0.5). Así P(2 caras) = 0.5 · 0.5 = 0.25. De este modo, si partimos de la tabla con las frecuencias marginales de nuestro conjunto de datos: vamos a calcular los valores esperados en caso de independencia de variables, es decir, vamos a completar esa tabla con los valores que se supone que debería haber en caso de que las 2 variables (sexo y nivel de colesterol) sean independientes. Empezamos con el valor esperado para hombres con nivel de colesterol bajo. Si la proporción esperada es P(Hombre \\(\\cap\\) Bajo ), el número de individuos esperado será 258·P(Hombre \\(\\cap\\)Bajo). Por ejemplo, si tenemos 200 individuos y la probabilidad de ser rubio es 0.36, el número esperado de individuos rubios será 200·0.36 = 72. Volviendo a nuestro ejemplo, para calcular los individuos esperados y suponiendo que las variables son independientes, aplicamos el resultado de probabilidad que hemos comentado: \\(\\widehat{P}(Hombre \\cap Bajo)=\\widehat{P}(Hombre) \\cdot \\widehat{P}(Bajo)\\) Como \\(\\widehat{P}(Hombre)=\\frac{159}{258}\\) y \\(\\widehat{P}(Bajo)=\\frac{168}{258}\\), el número esperado de hombres con el colesterol bajo es: \\(258 \\cdot \\widehat{P}(Hombre \\cap Bajo) = 258 \\cdot \\widehat{P}(Hombre) \\cdot \\widehat{P}(Bajo)\\) \\(258 \\cdot \\widehat{P}(Hombre \\cap Bajo) = 258 \\cdot \\frac{159}{258} \\cdot \\frac{168}{258} = \\frac{159 \\cdot 168}{258}=103.5\\) En el resultado final, al ser individuos, no tiene sentido usar decimales pero dejamos uno para tener más exactitud en cálculos posteriores. De esto modo, vemos que, para obtener el número de individuos esperado no hay más que multiplicar las frecuencias marginales y dividir el resultado por el número total de individuos: De este modo, podemos obtener de una forma muy sencilla la tabla de contingencia de datos teóricos suponiendo que las variables son independientes a partir de las frecuencias marginales de nuestra muestra: así como el diagrama de rectángulos correspondiente: Comparando los 2 gráficos de rectángulos obtenidos (datos observado y teóricos), parece que se ajustan bien, es decir, que con los valores observados, podemos deducir intuitivamente que las variables son independientes y que no hay relación entre ellas. 3.3.4 Gráficos o diagramas de rectángulos (Práctica) Para realizar esta práctica, debe tener descargado en su ordenador el archivo 2.practicas.xlsx y abrir la hoja/pestaña correspondiente. En el siguente vídeo se muestran los pasos para realizar la práctica. 3.3.5 Diagnóstico clínico Una cuestión de gran interés en Medicina es el estudio de la eficacia de los diferentes procedimientos de diagnóstico que guarda una estrecha relación con las tablas de contingencia 2 x 2. Cabe destacar que una gran cantidad de procedimientos de diagnóstico tienen una importante componente estadística . Partimos de métodos que consisten en medir una variable de tipo numérico (analítica, ecografía, TAC, etc.) en el caso de conocer la distribución (proporción) aproximada para los individuos sanos de una variable concreta, es decir, qué valores puede tomar y en qué proporciones. De este modo, un valor anómalo respecto a dicha distribución puede ser considerado en principio patológico. Ya vimos que se puede considerar anómal un valor que está a más de 3 desviaciones típicas de la media, utilizando la desigualdad de Chevyshev donde en el intervalos \\((\\overline{x}-3\\sigma, (\\overline{x}+3\\sigma)\\) están, al menos, el 88% de los datos. Sin embargo, un valor dentro de los límites correspondientes a la población sana supondrá un resultado en el diagnóstico negativo, lo cual no tiene por qué excluir la posibilidad de que el individuo esté enfermo. Consideremos la elección de una prueba o investigación médica. Tenemos que ser conscientes del hecho de que las pruebas no son completamente precisas. Se producen falsos resultados positivos y negativos. Al confrontar la enfermedad con el resultado del diagnóstico se pueden dar las situaciones presentes en esta tabla Así, puede ocurrir que un individuo sano sea diagnosticado erróneamente como enfermo (positivo), lo cual se denomina falso positivo. También es posible que un individuo enfermo sea diagnosticado como sano (negativo), lo cual sería un ** falso negativo**. Ppara estudiar la fiabilidad de un procedimiento de diagnóstico, vamos a considerar unos datos ficticios dispuestos en una tabla 2 x 2 donde se relacionan la enfermedad (sano, enfermo) con el resultado del diagnóstico (positivo, negativo): En cualquier estudio interesa que los verdaderos positivos y negativos sean alcancen los máximos valores posibles. Para cuantificar estos resultados verdaderos, se definen las siguientes medidas: Sensibilidad: es la proporción de enfermos que son diagnosticados como positivos (proporción de verdaderos positivos). Especificidad: es la proporción de sanos diagnosticados como negativos (proporción de verdaderos negativos). De este modo, en nuestro ejemplo: Sensibilidad = \\(\\widehat{P}(+/E)=\\frac{90}{100}=0.90\\) Especificidad = \\(\\widehat{P}(-/S)=\\frac{810}{900}=0.90\\) Tenemos una sensibilidad del 90% y una especificidad también del 90%. Parecen buenos resultados pero vamos a obtener otros valores, los valores predictivos, que nos van a indicar la fiabilidad de los diagnóstico. El valor predictivo positivo (VPP) es la probabilidad de que la enfermedad esté presente cuando la prueba es positiva. Para calcularlo, se divide el número de verdaderos positivos entre el número total de positivos, es decir: \\(VPP=\\frac{Verdaderos ~ positivos}{Total ~ positivos}=\\frac{Verdaderos ~ positivos}{Verdaderos ~ positivos ~ + ~ Falsos ~ positivos}\\) El valor predictivo negativo (VPN) es la probabilidad de que la enfermedad no esté presente cuando la prueba es negativa. Para calcularlo, se divide el número de verdaderos negativos entre el número total de negativos, es decir: \\(VPN=\\frac{Verdaderos ~ negativos}{Total ~ negativos}=\\frac{Verdaderos ~ negativos}{Verdaderos ~ negativos ~ + ~ Falsos ~ negativos}\\) Volviendo a nuestro ejemplo: Tenemos que los valores predictivos son: \\(VPP=\\frac{90}{180}=0.50\\) \\(VPN=\\frac{810}{820}=0.99\\) De este modo, tenemos un valor predictivo positivo del 50% (solo la mitad de los pacientes con un resultado positivo realmente tendrá la enfermedad) y un valor predictivo negativo del 99%, lo que significa que solo casi todos los pacientes con un resultado negativo en realidad no tendrán la enfermedad. Los valores predictivos dependen mucho de la prevalencia de una enfermedad. En nuestro ejemplo, teníamos una muestra de 1000 pacientes en los que la enfermedad existe en solo el 10%. Es esta baja prevalencia la que nos da el pobre valor predictivo positivo. Al interpretar valores predictivos positivos y negativos, siempre debe comparar la prevalencia de la enfermedad en la muestra del estudio frente a la prevalencia de la enfermedad en la población de pacientes. 3.3.6 Curvas ROC (Receiver Operating characteristic Curve) Vamos a presentar un tipo de gráfico que relaciona de la sensibilidad de un test de diagnóstico y el complementario de la especificidad en función del punto de corte que indica que un test es positivo. Son las conocidas como curvas características o curvas ROC. A menudo se usan para elegir entre varios test aunque el procedimiento no tiene en cuenta la prevalencia de la enfermedad que se estudia. Vamos a utilizar un ejemplo real tomado del artículo Body mass index and waist circumference are predictor biomarkers of breast cancer risk in Iranian women en el que se obtienen datos respecto al punto de corte del Índice de Masa Corporal (BMI Body Mass Index) para la detección del cáncer de mama. Los datos están en la siguiente tabla: Tenemos entonces valores de la sensibilidad y la especificidad para distintos puntos de corte. Si representamos su variación: vemos que cuando al aumentar el punto de corte (criterio), aumenta la especificidad (proporción de verdaderos negativos) y disminuye la sensibilidad (proporción de verdaderos positivos). Para ver si el biomarcador del Índice de Masa Corporal tiene capacidad predictiva para discriminar el cáncer de mama de los sujetos normales, vamos a construir la curva ROC e interpretarla. Para ello, calculamos los siguientes valores: La proporción de verdaderos positivos (TPR: True Positive Rate): cociente entre los verdaderos positivos y la suma de los verdaderos positivos y los falsos negativos. Coincide con la sensibilidad. La proporción de falsos positivo s (FPR: False Positive Rate): cociente entre los verdaderos positivos y la suma de los falsos positivos y los verdaderos negativos. Es el complementario de la especificidad (1 - especificidad). Un ejemplo de curva ROC asociada a un clasificador para el diagnóstico clínico es: donde se ha representado la curva que relaciona la proporción de falsos positivos y la proporción de verdaderos positivos. Para entender el significado de esta curva, vamos a presentar algunos ejemplos “precocinados” que muestran situaciones extremas. Adivinando: el primer ejemplo es el más simple: una línea diagonal. Una línea diagonal indica que el clasificador solo está haciendo conjeturas completamente al azar. Dado que este clasificador sólo será correcto el 50% del tiempo, es lógico que su TPR y FPR también sean iguales. Esta línea diagonal se suele mostrar en todas las curvas ROC. Clasificador perfecto: hace que cada predicción sea correcta. En este caso se tiene una compensación perfecta entre TPR y FPR lo que significa que hay un 100% de verdaderos positivos (TPR = 1) y un 0% de falsos positivos (FPR = 0). Peor que adivinar: un mal clasificador (es decir, algo que es peor que adivinar) aparecerá por debajo de la línea diagonal. Si esto aparece, mal negocio. Mejor que adivinar: por el contrario, un buen clasificador supone que la curva esté por encima de la diagonal. Cuanto más se acerque al clasificador perfecto, mejor. En la imagen, la curva ROC corresponde a un clasificador no muy bueno. En nuestro ejemplo del biomarcador del Índice de masa corporal, la curva ROC es: Por lo que parece que el biomarcador del Índice de masa corporal tiene capacidad predictiva para discriminar el cáncer de mama de los sujetos normales. Para ello se calcula un valor, el área debajo de la curva (AUC Area Under the Curve) que, en este caso, es de 0.78. El mejor valor es 1 (clasificador perfecto) mientras que el peor es 0.5 (adivinando). Intuitivamente, si consideramos que un AUC = 0.75 se encuentra a medio camino entre la no-discriminación (AUC = 0.50) y la discriminación perfecta (AUC = 1.00), el AUC del biomarcador del Índice de masa corporal se encuentra más cercana a la perfección que a la no-discriminación (AUC = 0.78), por lo tanto, resulta razonable plantear que es un test diagnóstico con una capacidad aceptable de discriminar pacientes con y sin cáncer de mama. Se ha pretendido mostrar la eficacia de un clasificador o método de diagnóstico clínico desde un punto de vista descriptivo. En el apartado de estadística inferencial veremos con más detalle todos estos aspectos. "],["inferencia-estadística.html", "Capítulo 4 Inferencia Estadística", " Capítulo 4 Inferencia Estadística El propósito final de la Estadística en Medicina es intentar explicar fenómenos que estarán, en principio, sujetos cierto nivel de incertidumbre con el propósito de eliminarla o minimizarla en la medida de lo posible. De este modo, primero se procede a un análisis descriptivo de una o varias variables obtenidas a partir de una muestra en la que se podrá observar un grado mayor o menor de correlación entre las mismas y en un sentido determinado. La Inferencia Estadística puede definirse como el conjunto de técnicas que nos permiten obtener conclusiones sobre una población objeto de estudio a partir de un subconjunto de datos representativos que denominaremos muestra. Así, la Inferencia Estadística debe formularse en un lenguaje probabilístico. Para ello, haremos un uso intuitivo del concepto de probabilidad que, a efectos prácticos, se trata de una proporción. Es más, en un contexto médico podemos permitirnos la licencia de identificar probabilidad con proporción calculada respecto al total de una población. Así, por ejemplo, la probabilidad de tener un nivel de colesterol mayor que 200 se entiende como la proporción de individuos de la población estudiada que verifica tal propiedad. En Inferencia Estadística distinguiremos dos tipos de problemas: los problemas de contraste de hipótesis y los problemas de estimación. "],["métodos-de-muestreo.html", "4.1 Métodos de muestreo", " 4.1 Métodos de muestreo Para conocer características de una población, lo ideal es estudiar toda la población. Sin embargo, en la mayoría de los casos, su excesivo tamaño, el coste que supondría o la imposibilidad de acceder a todos los individuos de la población, hacen necesario el estudio de esas características en muestras extraídas de dicha población. Si estudiamos toda la población, el estudio se llama censo y los valores obtenidos son parámetros de la población. Si estudiamos una muestra, estamos realizando un estudio estadístico y los valores obtenidos son medidas estadísticas. Para que los resultados obtenidos a partir de un estudio estadístico se puedan aplicar de forma veraz a toda la población, la muestra extraída debe ser representativa de la población. El muestreo es el conjunto de técnicas que se aplican para extraer muestras representativas de la población. Un muestreo es aleatorio cuando todos los elementos tienen la misma probabilidad de ser seleccionados como elementos de la muestra Un muestreo es no aleatorio cuando los elementos que van a ser incluidos en la muestra no tienen la misma probabilidad de ser seleccionados Hay que advertir claramente que, generalmente, la obtención de la muestra aleatoria en la población es casi utópica y que debemos conformarnos con analizar los datos de los que disponemos, siempre y cuando podamos descartar un claro sesgo o intencionalidad a la hora de incluirlos en el estudio. Si es así, la muestra puede considerarse, si no aleatoria, al menos arbitraria, lo cual puede ser suficiente si no sobrevaloramos los métodos que vamos a aplicar. Al extraer información de una muestra e inferirla sobre toda la población, es decir, al generalizar los resultados, se cometen errores que pueden ser debidos a la elección de la muestra. Si el muestreo es aleatorio, el error se puede minimizar aumentando el tamaño de la muestra. Si el muestreo no es aleatorio, el error no se puede corregir y esto se conoce como sesgo. Decimos que un muestreo aleatorio es con reposición cuando, tras elegir cualquier elemento, éste puede volver a ser elegido. Si cada elemento de la población puede ser escogido una sola vez para la muestra, decimos que el muestreo es sin reposición. Para extraer una muestra aleatoria de tamaño n de una población de tamaño N mediante un muestreo aleatorio simple: numeramos los N elementos de la población elegimos al azar n elementos del total Para extraer una muestra aleatoria de tamaño n de una población de tamaño N mediante un muestreo aleatorio sistemático: numeramos de forma aleatoria los elementos de la población fijamos el tamaño de la muestra que queremos obtener, n, y hallamos el cociente entre el tamaño de la población y el tamaño de la muestra: h = N/n; este valor se llama constante de elevación. elegimos, al azar, un elemento entre los primeros h elementos y, a partir de él, escogemos de h en h hasta completar los n elementos de la muestra. Este tipo de muestreo es fácil de aplicar. Sin embargo, hay que tener en cuenta que el criterio para numerar a los elementos de la población no debe tener ninguna relación con la característica que se va a estudiar en la muestra. En caso contrario, la muestra no sería representativa de la población. Para extraer una muestra aleatoria de tamaño n de una población de tamaño N mediante muestreo por conglomerados: segmentamos la población en grupos más pequeños llamados conglomerados de forma que los elementos de cada conglomerado son heterogéneos respecto de la característica que se quiere estudiar y los conglomerados son muy parecidos entre sí. tomamos una muestra aleatoria simple de conglomerados de modo que la muestra estará formada por todos sus elementos o por muestras aleatorias extraídas de ellos. Para extraer una muestra aleatoria de tamaño n de una población de tamaño N mediante muestreo aleatorio estratificado: segmentamos la población en grupos más pequeños llamados estratos de forma que los elementos de cada estrato son homogéneos respecto de la característica que se quiere estudiar siendo los estratos muy diferentes entre sí. El rasgo más común es el género, pero también puede ser la clase socioeconómica, la edad y muchos otros. tomamos una muestra aleatoria simple de cada estrato el muestreo estratificado es con afijación igual cuando el tamaño de las muestras en cada estrato es igual. el muestreo estratificado es sin afijación igual cuando el tamaño de las muestras en cada estrato es proporcional al tamaño de la población en dicho estrato. "],["valor-p.html", "4.2 Valor p", " 4.2 Valor p Cuando realizamos investigación relacionada con la Medicina, hemos comentado que la Inferencia Estadística debe formularse en un lenguaje probabilístico. Así, aparece el término valor p junto con el “estándar de oro” de significación estadística, 0.05 aceptado por consenso en Medicina. ¿Qué es el valor p? El valor p explica la probabilidad de que ocurra un evento. Se basa en el cálculo de un área geométrica. Las Matemáticas detrás de un valor de p dibujan una curva y simplemente calculan el área bajo una cierta parte de esa curva. Así, cuando trabajamos con un conjunto de datos, por ejemplo estudiando si existen diferencias significativas en la eficacia clínica de dos fármacos, un valor p de 0.05 representa una seguridad del 95% que la asociación que estamos estudiando no sea por el azar. Es decir, un valor p &lt; 0,05 indica que en menos de 5 veces de cada 100 que repitiéramos el mismo estudio, nuestro resultado se debería al AZAR. Si queremos trabajar con un margen de seguridad de 99%, éste lleva implícito un valor de p inferior a 0,01 . Si elegimos un valor p menor a 0,05 para indicar una diferencia significativa, las matemáticas calcularán un corte en el eje x (en azul en la imagen) llamado valor crítico que indica un área bajo la curva (en rojo) de 0,05 (5% del área total). Mediante técnicas estadísticas, al realizar un estudio como el de si existen diferencias significativas en la eficacia clínica de dos fármacos, vamos a obtener un valor del estadístico observado (en verde en la imagen) a comparar con el valor crítico. Así, si ese valor está en la zona roja tendremos un valor p &lt; 0,05 (el áreaa la derecha para ese valor es menor que 0,05) y podemos etiquetar el resultado como estadísticamente significativo. Pero ¿qué significa que el valor p sea superior a 0.05? Si esto ocurre, se puede suponer que los resultados pueden estar influidos por el azar y que el resultado no es estadísticamente significativo. Hay que tener en cuenta que obtener un resultado estadísticamente significativo no implica obtener un resultado clínicamente relevante. Hay que recordar que estamos hablando de un concepto matemático, por lo que una asociación estadísticamente significativa puede no ser clínicamente relevante; una asociación estadísticamente significativa puede no ser causal y una asociación estadísticamente no significativa puede deberse a un problema de tamaño de muestra insuficiente. Por ello es que el valor de p debe ser observado con cautela y siempre tomado en cuenta en el contexto del estudio, su diseño, las características de la muestra o la población en estudio, de los potenciales sesgos, etc y no como una cifra mágica que nos invite o autorice a tomar decisiones o cambiar conductas relacionadas con la práctica clínica cotidiana. "],["distribuciones-de-probabilidad.html", "4.3 Distribuciones de probabilidad", " 4.3 Distribuciones de probabilidad Cuando obtenemos datos en un experimento, los resultados obtenidos constituyen uno de los muchísimos resultados posibles. Así, unos resultados ocurren con más frecuencia que otros. Una variable aleatoria tiene en cuenta todos los posibles resultados que puedan darse en un fenómeno aleatorio, asignando un valor numérico a cada uno de ellos, de modo que podamos calcular su probabilidad. Para el cálculo del valor p, utilizaremos distribuciones de probabilidad. Una distribución de probabilidad de una variable aleatoria es una función que asigna a cada suceso definido sobre la variable la probabilidad de que dicho suceso ocurra. Resulta que hay muchas distribuciones de probabildad para variables aleatorias tanto discretas como continuas. Más aún, los promedios, las desviaciones estándar y otras estadísticas también tienen distribuciones. Es importante comprender los diversos tipos de distribuciones porque influyen en la elección del análisis estadístico que se debe realizar en ellas. Por ejemplo, sería bastante incorrecto realizar la famosa prueba t en valores de datos para una muestra que no proviene de una variable con una distribución normal en la población de la que se tomó la muestra. Vamos a explicar la más utilizadas para variables continuas. 4.3.1 Distribución normal La distribución normal es quizás la distribución más importante. También conocida como distribución gaussiana o campana de Gauss, es la más conocidas entre los modelos continuos. Se utiliza para modelar prácticamente la totalidad de las medidas antropométricas (longitudes, pesos,…), los efectos de fármacos, los errores cometidos al medir ciertas magnitudes, etc. Necesitamos saber que los valores del conjunto de datos para una muestra se toman de una población en la que esa variable se distribuye normalmente antes de decidir qué tipo de prueba estadística usar. Además, la distribución de todos los resultados posibles se distribuye normalmente. La distribución normal tiene las siguientes propiedades: la mayoría de los valores se centran alrededor de la media a medida que se aleja de la media, hay menos datos es simétrica respecto de la media curva en forma de campana el área encerrada entre la curva y el eje OX es 1 casi todos datos (99.7%) están a menos de 3 desviaciones estándar de la media La probabilidad de que el valor de una variable normal esté entre dos valores corresponde con la diferencia de la función de distribución en dichos valores. Para este cálculo se han utilizado históricamente tablas. Hoy en día tanto las hojas de cálculo como programas específicos nos dan esos valores. Generalmente, se utiliza el estadístico asociado a la distribución normal en contrastes de hipótesis que involucran a medias. 4.3.2 Normalidad de los datos Asumir el supuesto de normalidad significa aceptar que la distribución de frecuencias relativas de los datos de la población se adaptan aproximadamente a una curva normal. Una primera aproximación a la comprobación de la normalidad de datos puede ser mediante la representación gráfica del histograma comprobando si se ajusta a una curva normal. En el siguiente ejemplo: vemos dos conjunto de datos A y B. Para A (a la izquierda de la imagen), el histograma parece que se ajusta a una curva normal con algunos outliers. En cambio, los datos B presentan una asimetría hacia la derecha bastante considerable. Existen diversos métodos, (test de Shapiro-Wilk, test de Levenne, …) para contrastar si cierta variable sigue un modelo de distribución normal a partir de una muestra aleatoria de tamaño n. La mayoría de ellos están vinculados a aspectos gráficos . Veamos gráficamente cómo comprobar si nuestros datos provienen de una distribución normal usando los gráficos cuantil-cuantil (qq plot). La construcción del gráfico de probabilidad normal se realiza a través de los cuantiles de la normal estándar, de forma que aceptaremos normalidad de los datos siempre que los puntos en el gráfico tengan un comportamiento “suficientemente rectilíıneo”. En la siguiente imagen: podemos ver el gráfico cuantil cuantil de dos conjuntos de datos A y B. Para el conjunto de datos A (a la izquierda) observamos una linealidad en el gráfico, esto es, se ajusta a una recta. En este caso, aceptaríamos la hipótesis de normalidad, es decir, que los datos provienen de una distribución normal. En el caso de los datos B (a la derecha) no se observa dicha linealidad por lo que la distribución de frecuencias relativas de los datos de la población no se adaptan a una curva normal. 4.3.3 Normalidad de los datos (Práctica) Para realizar esta práctica, debe tener descargado en su ordenador el archivo 3.practicas.xlsx y abrir la hoja/pestaña correspondiente. En el siguente vídeo se muestran los pasos para realizar la práctica. 4.3.4 Distribución Z Si consideramos X una variable aleatoria normal de media \\(\\mu\\) y desviación típica \\(\\sigma\\), N(\\(\\mu\\), \\(\\sigma\\)), entonces, la variable \\(Z=\\frac{X-\\mu}{\\sigma}\\) cumple que es una distribución normal de media 0 y desviación típica 1, es decir, Z ~ N(0,1). En resumen, este cambio de variable transforma cualquier variable normal de cualquier media y desviación típica en una con media 0 y desviación típica 1. A esta variable se le llama distribución normal estándar o tipificada. No se usa comúnmente en estadísticas médicas, ya que requiere el conocimiento de algunos parámetros de la población (media \\(\\mu\\) y desviación típica \\(\\sigma\\)) que, en la mayoría de los casos, se desconocen. Es mucho más común usar la distribución t, que sólo requiere el conocimiento que está disponible a partir de los datos de una muestra (media \\(\\overline{x}\\) y desviación típica \\(s\\)). 4.3.5 Cálculo del valor p (Práctica) En el siguente vídeo se muestran los pasos para realizar la práctica. El sitio web al que se hace referencia en el vídeo es https://homepage.divms.uiowa.edu/~mbognar/. 4.3.6 Distribución t de Student Esta es la distribución muestral más utilizada. Sólo requiere cálculos que se pueden realizar a partir de un conjunto de datos para una variable que se conoce a partir de los datos del conjunto de muestras para un estudio. Se suele utilizar cuando se dispone de pocos datos (n &lt; 30) o no se cumplen necesariamente las condiciones de normalidad de la variable de datos X. Uno de los valores que hay que calcular al utilizar la distribución t es el de grados de libertad (df: degrees of freedom). Es un concepto bastante interesante con muchas interpretaciones y usos. En el contexto que lo estamos usando, depende del número de participantes en un estudio y se calcula fácilmente como la diferencia entre el número total de participantes y el número total de grupos. Por ejemplo, si tenemos un total de 30 sujetos en un estudio y los tenemos divididos en dos grupos, tendremos un grado de libertad igual a 28 (28 = 30 - 2). Cuanto mayores son los grados de libertad, más se asemeja la forma de la distribución t de la distribución normal. En la imagen podemos ver la gráfica de la distribución t de Student con 1, 5, 10 y 20 grados de libertad. Al igual que con la distribución normal, la probabilidad de que el valor de una variable esté entre dos valores corresponde con la diferencia de la función de distribución en dichos valores. Para este cálculo se han utilizado históricamente tablas. Hoy en día tanto Excel© como programas específicos nos dan esos valores. En la imagen, podemos ver el valor de la distribución t para un valor p de 0,05 y 5 grados de libertad. Se suele utilizar el estadístico asociado a la distribución t de Student en pruebas de hipótesis que involucran a porcentajes. 4.3.7 Distribución \\(\\chi^2\\) (chi-cuadrado o ji.cuadrado) Del mismo modo que los estadísticos “z”, con su distribución normal y “t”, con su distribución t de Student, nos van a servir para realizar contrastes de hipótesis que involucran a promedios y porcentajes, el estadístico chi-cuadrado, que tiene distribución de probabilidad del mismo nombre, nos servirá para someter a prueba hipótesis referidas a distribuciones de frecuencias. La distribución chi-cuadrado puede definirse como la suma de los cuadrados de n variables aleatorias independientes que siguen una normal de media 0 y desviación típica 1. Es decir, si \\(X_1\\), \\(X_2\\), … , \\(X_n\\) son variables aleatorias independientes e idénticamente distribuidas,\\(X_i\\) ∼ N (0,1), diremos que la variable aleatoria X sigue una distribución chi-cuadrado con n grados de libertad, y escribiremos X ∼ \\(\\chi^2_n\\) si \\(X=\\sum{X_i^2}\\) En la imagen podemos ver la gráfica de la distribución \\(\\chi^2\\) con 1, 5, 10 y 20 grados de libertad. Al ser una suma de cuadrados, la distribución chi-cuadrado sólo toma valores positivos. La probabilidad de que el valor de una variable esté entre dos valores corresponde con la diferencia de la función de distribución en dichos valores. Para este cálculo se han utilizado históricamente tablas. Hoy en día tanto Excel© como programas específicos nos dan esos valores. "],["estimación-de-parámetros.-intervalos-de-confianza.html", "4.4 Estimación de parámetros. Intervalos de confianza", " 4.4 Estimación de parámetros. Intervalos de confianza Cuando queremos obtener parámetros poblacionales (media, proporción) a partir de una muestra aleatoria, estamos en condiciones de acotar el error con un cierto grado de confianza, es decir, de aportar un intervalo en el cual esperamos que se encuentre el valor desconocido del parámetro poblacional. Los márgenes de error se basan en cálculos probabilísticos. Así, vamos a ver cómo obtener una estimación de entre qué dos valores se puede encontrar un cierto parámetro poblacional a partir de los datos de una muestra con una probabilidad prefijada. A esto nos dedicaremos en este punto en el que abordaremos la estimación mediante intervalos de confianza. Llamamos intervalo de confianza para un parámetro poblacional (media \\(\\mu\\) o proporción p) al intervalo que contiene a dicho parámetro con una probabilidad 1-\\(\\alpha\\), también llamado nivel de confianza 1-α. Al valor de \\(\\alpha\\) se le llama nivel de significación. 4.4.1 Intervalo de confianza para la media Si queremos inferir el valor de la media poblacional \\(\\mu\\) a partir de los valores de una muestra con una confianza del 95%, las Matemáticas detrás de los intervalos de confianza construyen una distribución a partir de la muestra basada en los valores de los datos y calculan qué área estaría cubierta por el 95% (para un nivel de confianza del 95%) de la curva. Los valores del eje X se reconstituyen a valores reales, que son los valores inferior y superior del intervalo de confianza. De este modo, si \\(E_{max}\\) es el margen máximo de error de la estimación de \\(\\mu\\) con una confianza del 95 %, es decir, la diferencia entre el valor superior y la media muestral \\(\\overline{x}\\), podemos inferir que la media poblacional \\(\\mu\\), con una confianza del 95%, estará entre los valores \\(\\overline{x}\\) - \\(E_{max}\\)x y \\(\\overline{x}\\) + \\(E_{max}\\). Si conocemos la desviación típica poblacional \\(\\sigma\\) , la distribución para el cálculo del intervalo de confianza será una normal pero si no conocemos dicha desviación típica poblacional (que es lo más frecuente) y únicamente disponemos de la desviación típica de la muestra \\(s\\), la distribución a utilizar será la t de Student. Para la distribución normal de media 0 y desviación típica 1. el valor crítico de 1,96 indica que el área entre -1,96 y 1,96 es 0,95. Ese valor se puede obtener tanto con programas estadísticos como con la hoja de cálculo con la función =INV.NORM.ESTAND(0,975). En el caso de la t de Student, para obtener el valor de \\(t_{\\alpha/2}\\) debemos tener en cuenta los grados de libertad (nº de datos nº de categorías). Por ejemplo, para 10 grados de libertad, el valor crítico con confianza del 95% es 2,23. Ese valor se puede obtener tanto con programas estadísticos como con la hoja de cálculo con la función =INV.T.2C(0,05;10). La instrucción 2C hace referencia a 2 colas, es decir, a una área tanto a la izquierda como a la derecha. El verdadero significado del nivel de confianza de un 95% es que si el estudio se repite 100 veces (cada uno con su propia muestra aleatoria de pacientes de la población, cada uno con su propia media e intervalos de confianza del 95%), 95 de dichos estudios tendrán correctamente el parámetro de población dentro de los intervalos y 5 no lo tendrán. Sin embargo, no hay manera de saber cuál tiene para un estudio determinado. 4.4.2 Intervalo de confianza para la media (Práctica) Para realizar esta práctica, debe tener descargado en su ordenador el archivo 3.practicas.xlsx y abrir la hoja/pestaña intervalo_confianza. Tenemos datos de la siguiente muestra de 30 individuos: y queremos un intervalo de confianza para la media poblacional \\(\\mu\\) con una confianza del 95%. Con la herramienta de Estadística Descriptiva del análisis de datos, activando el Nivel de confianza para la media al 95% con los datos distribuidos en una columna: obtenemos una media muestral \\(\\overline{x}\\) de 10,08 valor \\(E_{max}\\) de 0.57. Entonces a partir de los resultados de la muestra, el intervalo de confianza al 95% para la media poblacional \\(\\mu\\) es: \\((10,07666667 - 0,572688088, 10,07666667 + 0,572688088)\\) Lo que es lo mismo que decir que, con los datos disponibles y una confianza del 95%, la media poblacional \\(\\mu\\) estará entre 9,5 y 10,6 (redondeando a un decimal). También podemos utilizar la aplicación web Statistical Inference for \\(\\mu\\) disponible en https://homepage.divms.uiowa.edu/~mbognar/applets/mu.raw.html Debemos introducir: el número de datos n: 30 en nuestro caso la media muestral \\(\\overline{x}\\): 10.08 en nuestro caso la desviación típica muestral s (ya que no conocemos la poblacional \\(\\sigma\\)): 1.53 en nuestro caso por defecto, en nivel de confianza es del 95% Atención: para valores decimales, Excel© utiliza una coma y la aplicación web utiliza un punto. Si vemos el resultado obtenemos un intervalo de confianza para la media poblacional de \\((9.50869, 10.65131) ~ (9.5, 10.6)\\) igual que con Excel©, evidentemente. Si en la aplicación web activa la opcion Show Equations puede comprobar que la distribución de probabilidad utilizada es la t de Student con un valor p de \\(t_{\\alpha/2}\\) de 2.045 para 29 (n-1) grados de libertad. En el siguiente vídeo tiene la práctica desarrollada 4.4.3 Intervalo de confianza para una proporción Cuando estudiamos una variable cualitativa con dos categorías, como por ejemplo el hecho de padecer o no cierta enfermedad, se pretende ahora calcular un intervalo de confianza para la proporción de enfermos en la población p a partir de la proporción \\(\\widehat{p}\\) de la muestra. En este caso, el intervalo de confianza para el 95% viene dado por: \\(\\widehat{p} \\pm 1.96 \\sqrt{\\frac{\\widehat{p} (1-\\widehat{p})}{n}}\\) Veamos un sencillo ejemplo: En un estudio sobre obesidad en una región, se ha obtenido que con una muestra de 220 individuos, 77 resultaron tener sobrepeso. Vamos a calcular el intervalo de confianza del 95% para la proporción de personas con sobrepeso en dicha región. El valor de la proporción muestral es \\(\\widehat{p}=\\frac{77}{220}=0.35\\) es decir, el 35% de los pacientes de la muestra tenían sobrepeso. El error máximo$ E_{max}$ para una confianza del 95% es: \\(1.96 \\cdot \\sqrt{\\frac{\\widehat{p}(1-\\widehat{p})}{n}}=1.96 \\cdot \\sqrt{\\frac{0.35(1-0.35)}{220}}=0.063\\) Entonces el intervalo de confianza al 95% de la proporción poblacional es: \\((0.35 - 0.063, 0.35 + 0.063)=(0.287, 0.413)\\) de donde podemos inferir que, a partir de los resultados de la muestra y con una confianza del 95%, el porcentaje de personas con sobrepeso en dicha región estará entre 28,7% y 41,3%. El intervalo de confianza obtenido es bastante amplio con un error máximo del 6.3%. Evidentemente, cuanto mayor sea el tamaño de la muestra, menor será el error máximo cometido. Es una equivocación muy común asumir por defecto un margen máximo de error del 5 % en la estimación de la proporción p (es decir, confundirlo con la probabilidad de que el intervalo sea correcto), porque esa cantidad puede resultar o no aceptable en función del propio valor de p (desconocido). Por ejemplo, es un error considerar un margen de error del 5 % en la estimación de la prevalencia de una enfermedad rara. "],["contrastes-de-hipótesis.html", "4.5 Contrastes de Hipótesis", " 4.5 Contrastes de Hipótesis El último paso en el estudio de la Inferencia Estadística que vamos a abordar es el llamado Contraste de Hipótesis, cuyo principal objetivo es tomar decisiones sobre si determinadas hipótesis o supuestos a partir de muestras, pueden extrapolarse a la población con un determinado nivel de confianza. Un contraste o test de hipótesis es el procedimiento estadístico mediante el cual se investiga la veracidad o falsedad de una hipótesis acerca de algún parámetro poblacional. Llamaremos hipótesis nula \\(H_0\\) a la hipótesis que se formula y que se desea contrastar y llamaremos hipótesis alternativa \\(H_1\\) a cualquiera otra situación que sea contraria a la hipótesis nula . Se llaman pruebas de hipótesis a los procedimientos que permiten decidir si una hipótesis se acepta o rechaza o determinar si las muestras observadas difieren significativamente de los resultados esperados. Como en todo estudio, podemos cometer errores debidos a que la información muestral nos da a pensar en algo distinto a las hipótesis debido a que la muestra, por el motivo que sea, no es lo suficientemente representativa de la población estudiada. Tomemos como ejemplo juzgar a un individuo por la presunta comisión de un delito. Consideramos como hipótesis nula \\(H_0\\) que el individuo es inocente (no se encuentran indicios de culpabilidad). La hipótesis alternativa (contraria y excluyente a la hipótesis nula) sería \\(H_1\\) que el individuo es culpable (se encuentran indicios de culpabilidad). \\(H_0\\): inocente \\(H_1\\): culpable Así, los datos pueden refutar la hipótesis nula (que es inocente). Es la hipótesis que se acepta si las pruebas no indican lo contrario. Rechazarla por error tiene graves consecuencias (condenar a un inocente). Sin embargo, la hipótesis alternativa (es culpable) no debería ser aceptada sin una gran evidencia a favor. Rechazarla por error tiene consecuencias consideradas menos graves que la anterior (liberar a un delincuente). Es decir, el contraste de hipótesis consiste en evidencias de que es culpable (hipótesis de investigación). Si no se encuentran, se concluye que es inocente. Se distinguen entonces 2 tipos de error al tomar la decisión sobre un contraste de hipótesis: el error \\(\\alpha\\) y el error \\(\\beta\\). Siguiendo con nuestro ejemplo, en esta tabla se muestran las posibilidades: Es decir, para condenar al individuo (rechazar la hipótesis nula) se deben tener pruebas muy convincentes. En Estadística, para aceptar o rechazar la hipótesis nula, se tiene en cuenta un valor p (generalmente &lt; 0,05). Este valor p que se va a obtener al realizar un contraste de hipótesis debe entenderse como la medida de la verosimilitud de la muestra según el modelo teórico inicial \\(H_0\\) un valor p grande (&gt; 0,1) expresa que la muestra es verosímil (no extrema) según la hipótesis inicial, por lo que no estamos en condiciones de rechazarla. Por contra, un valor p pequeño (&lt; 0,05) indica que la muestra es poco verosímil (extrema) según \\(H_0\\) por lo que debemos rechazar la hipótesis inicial $H_0 $en favor de su alternativa \\(H_1\\). Consideremos ahora que estamos comparando la eficacia clínica de 2 fármacos A y B. Establecemos las hipótesis: \\(H_0\\): No existen diferencias significativas en la eficacia clínica de dos fármacos A y B (A=B) \\(H_1\\): Existen diferencias en la eficacia clínica de dos fármacos A y B (A̸ \\(\\neq\\) B) Tenemos entonces: Error tipo I (alfa): rechazamos la \\(H_0\\) siendo ésta verdadera (se concluye que existe diferencia cuando en realidad no la hay). Error tipo II (beta): no rechazamos la \\(H_0\\) siendo ésta falsa (se concluye que no se ha podido encontrar encontrar una diferencia que existe en la realidad). La potencia estadística (1 -\\(\\beta\\)) es la capacidad del estudio para detectar una diferencia si ésta existe realmente. \\(\\beta\\) es la probabilidad de cometer un error beta (tipo II). El nivel de confianza (1 - \\(\\alpha\\)) es la probabilidad a priori de que el intervalo de confianza (IC) a calcular contenga al verdadero valor del parámetro. Es la probabilidad de un error alfa (tipo I). La situación ideal sería elegir una prueba (contraste) para el que las dos probabilidades de error sean cero, pero esto no es posible. Además, para un tamaño muestral fijo, si una de las dos probabilidades de error disminuye entonces la otra aumenta. La única forma de que las dos probabilidades de error disminuyan a la vez es aumentando el tamaño de la muestra. 4.5.1 Contrastes bilaterales y unilaterales Tenemos 2 formas de establecer la hipótesis de investigación (hipótesis alternativa \\(H_1\\)): Bilateral: cualquiera de los dos parámetros a comparar puede ser mayor o menor que el otro (no hay dirección) (A ≠ B). Unilateral: cuando se considera que uno debe ser mayor que el otro (dirección de las diferencias) (A &lt; B). Siguiendo con el ejemplo de comparar la eficacia de 2 fármacos A y B, la prueba unilateral se utiliza cuando se pretende determinar si el fármaco nuevo B es más eficaz que el clásico A, es decir, tan sólo interesa una de las direcciones de la comparación (B &gt; A) ya que interesa demostrar que B sea más efectivo que A. Sin embargo, la prueba bilateral se utiliza para determinar si los dos fármacos A y B difieren en su efectividad clínica (A ≠ B). La siguiente imagen ilustra estas 2 opciones: En rojo tenemos la región de rechazo de la hipótesis nula para un contraste unilateral y para uno bilateral. Como hemos comentado, un valor p pequeño (en la zona de rechazo) indica que la muestra es poco verosímil (extrema) segun \\(H_0\\) por lo que debemos rechazar la hipótesis nula en favor de su alternativa \\(H_1\\). En el caso contrario, un valor p grande (fuera de la zona de rechazo) expresa que la muestra es verosímil según la hipótesis inicial, por lo que no estamos en condiciones de rechazarla. Para aclarar estos conceptos, vamos a considerar el siguiente ejemplo: Una empresa farmacéutica vende un producto cuyos efectos tienen una duración que se distribuye normalmente con media \\(\\mu_0\\) = 36 horas y desviación típica poblacional \\(\\sigma\\) = 1 hora. La empresa está probando una variante del producto diseñada para cambiar la duración media pero no la desviación típica. Para contrastar si esta variante mejora el producto original se probó en 9 pacientes y se obtuvieron las siguientes duraciones: 36.72, 35.71, 37.12, 36.49, 36.81, 35.90,37.48, 37.19 y 36.66 horas. ¿Respaldan estos datos un cambio en la duración media de la variante del producto? Consideremos las siguientes hipótesis: \\(H_0\\): no hay cambio, es decir \\(\\mu\\) = \\(\\mu_0\\) = 36 \\(H_1\\) sí́ hay cambio en la duración media \\(\\mu\\) \\(\\neq\\) 36 Como no estamos suponiendo que la media \\(\\mu\\) de la variante es mayor o menor que la media del original \\(\\mu_0\\), es un contraste bilateral. Calculamos con Excel© el intervalo de confianza para \\(\\mu\\) al 95% con los datos de la muestra (Análisis de datos &gt; Estadística descriptiva &gt; Activar Nivel de confianza para la media) Así, el intervalo de confianza al 95% viene dado por (36,23 , 37,12) y la media \\(\\mu\\) = 36 queda en la zona de rechazo (valor p &lt; 0,05). Si \\(H_0\\) es cierta, hay una probabilidad del 95% de que la media \\(\\mu\\) = 36 pertenezca a ese intervalo. De este modo, \\(\\mu\\) = 36 es un valor muy improbable si suponemos que la hipótesis \\(H_0\\) es cierta por lo que rechazamos la hipótesis nula y concluimos que la muestra respalda que la variante del producto tiene una duración media distinta de la del producto original. El sencillo ejemplo anterior ilustra el procedimiento general para contrastes de hipótesis. Una vez establecida la hipótesis nula \\(H_0\\) elegimos una medida D de la discrepancia entre los datos muestrales y la hipótesis \\(H_0\\). Esta medida se denomina estadístico de contraste y es una variable aleatoria que es función de la muestra con distribución conocida cuando \\(H_0\\) es cierta. Los valores del estadístico de contraste correspondientes a discrepancias grandes (valor p &lt; 0.05) llevan a rechazar \\(H_0\\) y forman la llamada región de rechazo. El conjunto complementario de valores se conoce como región de aceptación. 4.5.2 Nivel de confianza y potencia estadística Vamos a visualizar los valores \\(\\alpha\\) y \\(\\beta\\), los errores asociados y el nivel de confianza (1 - \\(\\alpha\\)) y la potencia estadística (1 - $). En la imagen vemos un contraste de hipótesis unilateral para la media poblacional \\(\\mu\\) a partir de los datos de una muestra de media \\(\\overline{x}\\). Suponemos que la distribución de datos es normal y tenemos la curva asociada a la distribución muestral (\\(\\overline{x}\\))en azul y a la poblacional (\\(\\mu\\)) en negro con el valor crítico para una significación \\(\\alpha\\) (nivel de confianza 1 - \\(\\alpha\\)). Una vez fijado el nivel de significación \\(\\alpha\\) (color verde oscuro) que es la probabilidad de cometer un Error de tipo I (rechazar \\(H_0\\) cuando \\(H_0\\) es cierta), el valor crítico asociado a \\(\\alpha\\) determina el valor de \\(\\beta\\) (color rojo), es decir, la probabilidad de cometer un error de tipo II (aceptar \\(H_0\\) cuando \\(H_0\\) es falsa). El error tipo II depende del parámetro \\(\\mu\\). Cuanto más cerca se encuentre éste del valor supuesto bajo la hipótesis nula, mayor es la probabilidad de ocurrencia del error tipo II. Debido a que el verdadero valor de \\(\\mu\\) es desconocido al hacer la presunción de la hipótesis alternativa, la probabilidad del error tipo II, en contraste con el error tipo I , no se puede calcular. Para cada contraste de hipótesis que analicemos veremos el estadístico concreto con el que se mide la discrepancia entre la muestra observada y la hipótesis nula, y la correspondiente región de rechazo. Estos contrastes garantizan que la probabilidad de error tipo I sea a lo sumo \\(\\alpha\\) y que la probabilidad de rechazar \\(H_0\\) cuando \\(H_0\\) es falsa, es decir la potencia, sea máxima con lo que la probabilidad de error tipo II va a ser mínima. Así pues, el procedimiento de un contraste de hipótesis consiste en: Formular adecuadamente la hipótesis nula \\(H_0\\) y la hipóteis alternativa \\(H_1\\). Elegir un nivel de significación α y un tamaño muestral n. Buscar el estadístico de contraste óptimo. Determinar la región de rechazo. Calcular el valor del estadístico de contraste elegido en la muestra concreta. Comprobar el valor del estadístico de contraste está en la zona de rechazo o no. Otra forma de realizar el contraste de hipótesis consiste en calcular el nivel de significación crítico o valor p, es decir, la probabilidad de obtener una discrepancia mayor o igual que la observada en la muestra cuando \\(H_0\\) es cierta. 4.5.3 Tamaño de la muestra No hay que confundir un contraste de hipótesis con una demostración matemática ya que el resultado de un contraste de hipótesis es una decisión razonable a partir de los datos de una muestra que debe relativizarse. Hay que tener muy en cuenta que los contrastes de hipótesis tienden a aportar resultados no significativos cuando se aplican a muestras de pequeño tamaño. Por contra, con muestras muy numerosas se pueden obtener resultados significativos por pequeñas evidencias contra \\(H_0\\). Así el tamaño muestral es de gran importancia a la hora de efectuar un contraste de hipótesis. Las muestras pequeñas están sometidas a una gran variabilidad. De este modo, la mayor parte de las circunstancias teóricamente posibles pueden ocurrir con una probabilidad aceptable. Por otro lado, las muestras grandes presentan un comportamiento muy regular. Así, cualquier pequeña desviación respecto al valor medio teórico correspondiente a \\(H_0\\) puede hacer que se rechaze la hipótesis nula. El cálculo del tamaño de la muestra depende del nivel de significación \\(\\alpha\\), la potencia deseada de la prueba 1 - \\(\\beta\\), la variabilidad del resultado y el tamaño del efecto. El tamaño del efecto es la diferencia en el parámetro de interés que representa una diferencia clínicamente significativa. Al igual que el margen de error en las aplicaciones de intervalo de confianza, el tamaño del efecto se determina en función de criterios clínicos o prácticos y no de criterios estadísticos. Lectura recomendada: https://www.fisterra.com/formacion/metodologia-investigacion/determinacion-tamano-muestral/ "],["contrastes-paramétricos-y-no-paramétricos.html", "4.6 Contrastes paramétricos y no paramétricos", " 4.6 Contrastes paramétricos y no paramétricos A la hora de elegir el contraste de hipótesis adecuado debemos tener en cuenta la distribución de los datos (generalmente un distribución normal) aunque no siempre es posible saber, a priori, qué distribución siguen los datos o no tenemos un número suficiente de datos en la muestra (generalmente n &gt; 30) para decidir su normalidad. Así, tenemos contrastes paramétricos y no paramétricos. Las pruebas paramétricas asumen distribuciones estadísticas subyacentes a los datos, generalmente distribución normal. Por tanto, deben cumplirse algunas condiciones de validez, de modo que el resultado de la prueba paramétrica sea fiable. Las pruebas no paramétricas no deben ajustarse a ninguna distribución (por ejemplo cuando se da un fuerte sesgo o se tienen pocos datos). Pueden por tanto aplicarse incluso aunque no se cumplan las condiciones de validez paramétricas. En definitiva y muy resumidamente: Distribución original normal o muchos datos -&gt; Método paramétrico Distribución original no normal y pocos datos -&gt; Método no paramétrico. El siguiente gráfico no puede dar una idea de qué contraste utilizar en función del número de datos disponibles aunque no debe tomarse al pie de la letra. Con un número muy grande de datos (&gt; 3000) con un estudio descriptivo sería suficiente ya que dicho tamaño muestral se podría considerar suficientemente representativo de la población. "],["métodos-de-inferencia-estadística.html", "4.7 Métodos de Inferencia Estadística", " 4.7 Métodos de Inferencia Estadística Vamos a ver las técnicas de Inferencia Estadística más utilizadas en los problemas de relación entre variables. Se pretende que, dado un problema concreto, el alumno sea capaz de identificar el procedimiento estadístico a seguir, aplicarlo e interpretar los resultados. Veremos ejemplos concretos y sencillos para cada uno de los métodos presentados que, evidentemente, no son todos los existentes pero pueden ser suficientes en la gran mayoría de casos. La siguiente tabla puede servirnos como resumen de los métodos y como guión a seguir durante ste apartadolo. Presentamos el método paramétrico así como su equivalente no paramétrico. 4.7.1 Test de Student para muestras independientes También conocido como t-test, es posiblemente el más utilizado en Bioestadística. Se utiliza para tratar de determinar si existe una relación significativa entre una variable cualitativa binaria (como, por ejemplo, estar sano o enfermo, ser tratado o no tratado) y una variable numérica (glucemia, presión arterial, etc) . El problema de relación entre ambas variables se traduce en un problema de comparación de las medias poblacionales de la variable numérica, \\(\\mu_1\\) y\\(\\mu_2\\), correspondientes a cada una de las categorías consideradas. Es decir, la hipótesis inicial a contrastar es: \\(H_0:\\mu_1=\\mu_2\\) Si seleccionamos de manera independiente sendas muestras aleatorias para cada categoría,el algoritmo al que se someten los datos se denomina test de Student para muestras independientes. A pesar de la sencillez y utilidad del t-test, para que sus resultados sean válidos es necesario que se cumplan una serie de condiciones, entre las que se encuentran: Independencia: Las observaciones tienen que ser independientes las unas de las otras. Para ello, el muestreo debe ser aleatorio y el tamaño de la muestra inferior al 10% de la población. Normalidad: Las poblaciones que se comparan tienen que seguir una distribución normal. Si bien la condición de normalidad recae sobre las poblaciones, no se suele disponer de información sobre ellas, por lo que se emplean las muestras (dado que son reflejo de la población) para determinarlo. En caso de cierta asimetría, los t-test son considerablemente robustos si el tamaño de las muestras es mayor o igual a 30. Igualdad de varianza (homocedasticidad): la varianza de las poblaciones comparadas debe de ser igual. Tal como ocurre con la condición de normalidad, si no se dispone de información de las poblaciones, esta condición se ha de asumir a partir de las muestras. En caso de no cumplirse esta condición se puede emplear otra prueba como un Welch Two Sample t-test, que incorpora una corrección a través de los grados de libertad que compensa la diferencia de varianzas, con el inconveniente de que pierde poder estadístico. Consideramos el siguiente ejemplo con 2 pares de muestras (A1, B1) y (A2, B2). Representadas mediante diagramas de cajas y bigotes: Observamos que en el primer ejemplo con las variables A1, B1, no se observa diferencia significativa entre ambas mientras que en el segundo ejemplo con los datos A2, B2, al menos por término medio (y mediano), parece que hay diferencia. Vamos analizar si esa diferencia apreciada en la segunda muestra concreta es significativa. Inicialmente, supondremos que ambas variables no guardan relación (\\(\\mu_A\\) = \\(\\mu_b\\)) y evaluaremos si la muestra estudiada contradice claramente dicha suposición. Según el modelo inicial las medias muestrales \\(\\overline{x}_A\\) y \\(\\overline{x}_B\\) deberían ser parecidas, es decir, la diferencia (en bruto) \\(\\overline{x}_A\\) - \\(\\overline{x}_B\\) debería ser prácticamente nula (~ 0). Obviamente, no podemos exigir que sea exactamente igual a 0 porque debemos asumir diferencias entre las muestras debidas exclusivamente al azar inherente al muestreo. El problema es cuantificar qué estamos dispuestos a achacar al azar, lo cual es un problema de Cálculo de Probabilidades. Para ello elegimos el estadístico de contraste. Concretamente, según el modelo inicial, la diferencia de medias muestrales debería seguir un modelo de distribución normal de media 0,de manera que, al tipificarlo, la diferencia de medias muestrales debería seguir una distribución N(0,1). De esta forma, obtenemos el valor del estadístico de contraste \\(t_{exp}\\) como: \\(t_{exp}=\\frac{\\overline{x}_A- \\overline{x}_B}{\\sqrt{\\frac{\\sigma_A^2}{n_A}+\\frac{\\sigma_B^2}{n_B}}}\\) Este valor recoge toda la información que aporta la muestra estudiada en lo referente a la hiopótesis nula del contraste de la hipótesis \\(H_0: \\mu_1=\\mu_2\\) De hecho, su valor absoluto se entiende como una distancia (tipificada) entre las dos medias muestrales que, bajo la hipótesis \\(H_0: \\mu_1=\\mu_2\\), debería ser pequeña. Más concretamente, debería ajustarse a un modelo de distribución N(0,1). El valor p se define en este problema concreto como la probabilidad, según N(0,1), de obtener una distancia (tipificada) entre medias aritméticas al menos tan grande como la observada en la muestra. En otras palabras, el valor p es el área de las colas (contraste bilateral) que determinan | $t_{exp}| y -| $t_{exp}| lo cual expresa en qué medida es verosímil la muestra según \\(H_0\\). En nuestros ejemplos, obtenemos el valor del estadístico de contraste y el valor p asociado: Así, para A2, B2, el resultado es significativo (valor p &lt; 0,05), es decir, se opta por la hipótesis alternativa \\(H_1:\\mu_{A2} \\neq \\mu_{B2}\\) son distintas como habíamos intuído a la vista de los diagramas de cajas y bigotes. Sin embargo, para A1, B1, el valor \\(t_{exp}\\) indica una escasa diferencia entre las medias muestrales, sería verosímil desde el punto de vista de la hipótesis inicial \\(H_0:\\mu_{A1=\\mu_{B1}}\\) asociándose a un valor p alto (0,2898 &gt; 0,05) según la distribución N(0,1). Se entendería entonces que la muestra es compatible con la hipótesis inicial y, en definitiva, no hay diferencia entre las medias. Con la hoja de cálculo Excel® tenemos los resultados de la prueba que nos da el valor del estadístico t y el valor p así como el valor crítico de t tanto para una cola como para dos colas para una confianza del 95%. En nuestro caso, hemos supuesto que el contraste es bilateral (\\(H_0:\\mu_1=\\mu_2\\)) por lo que tenemos que mirar el resultado para dos colas. 4.7.2 t-test (Práctica) Para realizar esta práctica, debe tener descargado en su ordenador el archivo 3.practicas.xlsx y abrir la hoja/pestaña correspondiente. En el siguente vídeo se muestran los pasos para realizar la práctica. 4.7.3 Prueba de Mann-Whitney Es una alternativa no paramétrica al test de Student que no exige la normalidad de la variable estudiada y que es, por lo tanto, de especial utilidad con muestras pequeñas. Se conoce también como la prueba de la suma de rangos de Wilcoxon (Wilcoxon Sum Rank Test). Básicamente consiste en una comparación de los rangos o posiciones promedios de la variable numérica en función de las categorías consideradas. En este caso, se utiliza la mediana en vez de la media. Se establece como hipótesis nula que las dos muestras son iguales. La idea en la que se fundamenta este test es la siguiente: si las dos muestras comparadas proceden de la misma población, al juntar todas las observaciones y ordenarlas de menor a mayor, cabría esperar que las observaciones de una y otra muestra estuviesen intercaladas aleatoriamente. Por lo contrario, si una de las muestras pertenece a una población con valores mayores o menores que la otra población, al ordenar las observaciones, estas tenderán a agruparse de modo que las de una muestra queden por encima de las de la otra. Consideremos como ejemplo un ensayo clínico de Fase II diseñado para investigar la efectividad de un nuevo medicamento para reducir los síntomas del asma en niños. Un total de n = 10 participantes se asignaron al azar para recibir el nuevo medicamento o un placebo. Se les pide a los participantes que registren la cantidad de episodios de falta de aliento durante un período de 1 semana después de recibir el tratamiento asignado. Los datos se muestran a continuación. ¿Hay alguna diferencia en el número de episodios de falta de aliento durante un período de 1 semana en los participantes que reciben el nuevo medicamento en comparación con los que recibieron el placebo? A la vista de los datos, parece que los participantes que reciben el placebo tienen más episodios de dificultad respiratoria, pero ¿es esto estadísticamente significativo? En este ejemplo, el resultado es un recuento y en esta muestra los datos no siguen una distribución normal. Además, el tamaño de la muestra es pequeño (\\(n_1\\) = \\(n_2\\) = 5) por lo que es apropiado usar una prueba no paramétrica. Establecemos como hipótesis nula \\(H_0\\) las dos muestras son iguales y un nivel de confianza del 95% (es decir, \\(\\alpha\\) = 0.05). Si la hipótesis nula es cierta (es decir, las dos poblaciones son iguales), esperamos ver un número similar de episodios de dificultad respiratoria en cada uno de los dos grupos de tratamiento y esperaríamos ver algunos participantes con pocos episodios y otros con más episodios en cada grupo. Este no parece ser el caso con los datos observados. Se necesita una prueba de hipótesis para determinar si los datos observados son evidencia de una diferencia estadísticamente significativa en las poblaciones . El primer paso es asignar rangos y para ello ordenamos los datos de menor a mayor. Esto se hace en la muestra total o combinada (es decir, agrupando los datos de los dos grupos de tratamiento (n = 10)), y asignando rangos de 1 a 10, de la siguiente manera: El rango 4.5 se corresponde al valor 4 de los 2 grupos. Serían los rangos 4 y 5 pero, al ser iguales, se toma como rango 4.5. Análogamente sucede con los rangos 7 y 8. Vemos que los rangos inferiores (por ejemplo, 1, 2 y 3) se asignan a las respuestas en el nuevo grupo de medicamentos, mientras que los rangos más altos (por ejemplo, 9, 10) se asignan alas respuestas en el grupo de placebo. El objetivo de la prueba es determinar si los datos observados apoyan una diferencia en las poblaciones de respuestas. En las pruebas paramétricas (analizadas en los módulos sobre pruebas de hipótesis), al comparar las medias entre dos grupos, analizamos la diferencia en las medias de la muestra en relación con su variabilidad y resumimos la información de la muestra en un estadístico de prueba. Un enfoque similar se emplea aquí. Específicamente, producimos una prueba basada en los rangos. Primero, sumamos los rangos de cada grupo. Para el placebo, obtenemos una suma de 37 mientras que para el nuevo medicamento, obtenemos una suma de rangos de 18. Como notación, llamamos 1 al grupo del placebo y 2 al grupo del nuevo medicamento. De este modo, si llamamos \\(R_1\\) a la suma de rangos del grupo 1 (placebo) y \\(R_2\\) a la suma de rangos del grupo 2 (nuevo medicamento), tenemos que \\(R_1\\) = 37 y \\(R_2\\) = 18. Si la hipótesis nula fuese cierta ( las dos muestras son iguales), esperamos valores similares de \\(R_1\\) y \\(R_2\\). En este ejemplo, los valores más bajos (rangos inferiores) se agrupan en el nuevo grupo de nuevo medicamento (grupo 2), mientras que los valores más altos (rangos más altos) se agrupan en el grupo de placebo (grupo 1). Sin embargo, ¿es la diferencia observada en las sumas de los rangos simplemente debido al azar? Para responder esto, vamos a calcular un estadístico de prueba para resumir la información de la muestra y buscar el valor correspondiente en una distribución de probabilidad. El estadístico de contraste para la prueba de Mann-Whitney se denota como U y es el valor más pequeño entre \\(U_!\\) y \\(U_2\\) definidos como: \\(U_1=n_1\\cdot n_2+\\frac{n_1(n_1+1)}{2}-R_1\\) \\(U_2=n_1\\cdot n_2+\\frac{n_2(n_2+1)}{2}-R_1\\) En nuestro ejemplo: \\(U_1=5\\cdot 5+\\frac{5\\cdot6}{2}-37= 40 - 37 = 3\\) \\(U_2=5\\cdot 5+\\frac{5\\cdot6}{2}-18 = 40-18=22\\) El valor del estadístico de contraste U es el menor de esos valores, es decir U = 3. ¿Es esta evidencia en apoyo de la hipótesis nula? Antes de abordar esta pregunta, consideramos el rango del estadístico de prueba U en dos casos extremos. Los dos grupos son diferentes En este caso, suponemos que los grupos son completamente diferentes. En nuestro ejemplo, esto implica que los 5 primeros rangos corresponden a un grupo y los otros 5 al otro, es decir, si todos los números más altos de episodios de dificultad respiratoria (y, por lo tanto, todos los rangos más altos) están en el grupo de placebo, y todos los números más bajos de episodios (y rangos) están en el nuevo grupo de fármacos, entonces: \\(R_1= 6 + 7 + 8 + 9 + 10 = 40\\) y \\(R_2= 1 + 2 + 3 + 4 + 5 = 15\\) . de donde \\(U_1= 40-40 =0\\) y \\(U_2=40-15=25\\). Así U, el menor de esos valores, es 0 cuando hay una diferencia clara entre grupos. Los dos grupos son iguales El otro caso extremo es considerar que los grupos son exactamente iguales. Así, en nuestro ejemplo, si los rangos de 2, 4, 6, 8 y 10 se asignan a la cantidad de episodios de dificultad respiratoria en el grupo de placebo y los rangos de 1, 3, 5, 7 y 9 se asignan a la cantidad de episodios de insuficiencia en el grupo de nuevo medicamento, entonces: \\(R_1= 2 + 4 + 6 + 8 + 10 = 30\\) y \\(R_2= 1 + 3 + 5 + 7 + 9 = 25\\) . de donde \\(U_1=40-30=10\\) y \\(U_2=40-25=15\\). Así U sería 10 cuando no hay una diferencia clara entre grupos. Si tenemos en cuenta que en cada prueba, \\(U_1\\) + \\(U_2\\) es siempre igual a n 1 · n 2, en el ejemplo anterior, U puede variar de 0 a 25 y valores más pequeños de U apoyan la hipótesis alternativa (es decir, rechazamos H 0 si U es pequeña). El procedimiento para determinar exactamente cuándo rechazar H 0 se describe a continuación. El valor crítico de U se puede encontrar en la siguiente tabla: Para determinar el valor crítico, necesitamos los tamaños de muestra (\\(n_1\\) = \\(m_2\\) = 5) y nuestro nivel de significancia bilateral \\(\\alpha\\) = 0.05 (la tabla da los valores críticos para 0.05 y 0.01). En nuestro caso, el valor crítico que nos da la tabla es 2 y la regla de decisión es rechazar $H_0$0 si U &lt; 2. Nosotros habíamos obtenido un valor U = 3 por lo que no rechazamos \\(H_0\\) ya que 3 &gt; 2. También podemos calcular el valor p con la aplicación web https://homepage.divms.uiowa.edu/~mbognar/applets/mw.html: Obtenemos un valor p = 0,02778 que es mayor, por muy poco, que 0,025 (es un contraste bilateral, de 2 colas). De este modo, no tenemos pruebas estadísticamente significativas a \\(\\alpha\\) = 0.05 para mostrar que las dos poblaciones de episodios de dificultad respiratoria son distintos. Sin embargo, en este ejemplo, el hecho de no alcanzar una significación estadística puede deberse a una baja potencia. Los datos de la muestra sugieren una diferencia pero los tamaños de la muestra son demasiado pequeños para concluir que existe una diferencia estadísticamente significativa. Para realizar esta práctica, debe tener descargado en su ordenador el archivo 3.practicas.xlsx y abrir la hoja/pestaña correspondiente. En el siguente vídeo, además de la explicaciones teóricas, se muestran los pasos para realizar la práctica. 4.7.4 Anova de un factor Este test es una generalización del test de Student para dos muestras independientes que se aplica para un mismo tipo de estudio y de diseño, con la salvedad de que podemos distinguir un número de categorías y, por lo tanto, de medias, mayor de dos. El test que resuelve el contraste se denomina anova de una vía o factor (analisis of variance i. e. análisis de la varianza) y requiere en principio de las mismas condiciones de validez que el test de Student para dos muestras independientes, es decir; Las muestras aleatorias elegidas deben ser independientes. Además, dentro de cada tratamiento, las observaciones son independientes entre sí. Las observaciones proceden de poblaciones normales de modo que las variables correspondientes al mismo tratamiento tienen la misma media. Hipotesis de homocedasticidad: cada población tiene la misma varianza La prueba Anova es una prueba de hipótesis que es apropiada para comparar medias de una variable continua en dos o más grupos de comparación independientes. Por ejemplo, en algunos ensayos clínicos hay más de dos grupos de comparación. En un ensayo clínico para evaluar un nuevo medicamento para el asma, los investigadores podrían comparar un medicamento experimental con un placebo y con un tratamiento estándar (es decir, un medicamento que se esté usando actualmente). En un estudio observacional como el estudio del corazón de Framingham, podría ser interesante comparar la presión arterial media o los niveles medios de colesterol en personas con bajo peso, peso normal, sobrepeso y obesidad. Vamos a considerar un ejemplo con grupos independientes y una medida de resultado continua. Los grupos independientes pueden definirse por una característica particular de los participantes, como el IMC (p. ej., Bajo peso, peso normal, sobrepeso, obesidad) o por el investigador (p. ej., Asignación aleatoria de participantes a uno de los cuatro tratamientos A, B, C y D). Supongamos que el resultado es la presión arterial sistólica y queremos comprobar si existe una diferencia estadísticamente significativa en la presión arterial sistólica media entre los cuatro grupos. Los datos de muestra se organizan de la siguiente manera: Las hipótesis son: \\(H_0:\\mu_1 = \\mu_2 = ... = \\mu_k\\) \\(H_1\\): las medias no son iguales Al aplicar ANOVA de un factor se calcula un estadístico de contraste denominado F. El estadístico F o F-test (se llama F en honor al estadístico Ronald Fisher) se obtiene al estimar la variación de las medias entre los grupos de la variable independiente y dividirla por la estimación de la variación de las medias dentro de los grupos. Así, si N es el número total de observaciones \\(\\overline{x}\\) es la media de todos los datos \\(\\overline{x_i}\\) es la media del grupo i = 1, 2, …, k El estadístico F se obtiene como: \\(F=\\frac{\\frac{\\sum n_j(\\overline{x}_j-\\overline{x})^2}{k-1}}{\\frac{\\sum\\sum(x_i-\\overline{x}_j)^2}{N-k}}\\) El cálculo del estadístico F divide la variación entre los grupos por la variación dentro de los grupos. Si las medias entre los grupos varían mucho y la media dentro de un grupo varía poco, es decir, los grupos son heterogéneos entre ellos y similares internamente, el valor de F será más alto, y por tanto, las variables estarán relacionadas. El estadístico F se distribuye según el modelo de probabilidad F de Snedecor siendo los grados de libertad del numerador el número de grupos menos 1 y los del denominador, el número total de observaciones menos el número de grupos). En conclusión, cuanto más difieren las medias de la variable dependiente entre los grupos de la variable independiente, más alto será el valor de F. Si hacemos varios análisis de ANOVA de un factor, aquel con F más alto indicará que hay más diferencias y por tanto una relación más fuerte entre las variables. Vamos a considerar el siguiente ejemplo: se realiza un ensayo clínico para comparar programas de pérdida de peso y los participantes se asignan al azar a uno de los programas de comparación y los participantes siguen el programa asignado durante 8 semanas. El resultado de interés es la pérdida de peso, definida como la diferencia en el peso medido al inicio del estudio (línea de base) y el peso medido al final del estudio (8 semanas), medido en kilogramos. Las diferencias positivas indican pérdidas de peso y las negativas indican ganancias de peso. Suponemos que las muestras elegidas son independientes y dentro de cada tratamiento, las observaciones son independientes entre sí, que las observaciones proceden de poblaciones normales y que cada población tiene la misma varianza. Con la hoja de cálculo, hacemos el Análisis de varianza de un factor obteniendo los siguientes resultados: Obtenemos pues un valor del estadístico de contraste F = 8,56 siendo el valor crítico 3,24 para α = 0,05. Además, nos indica un valor p de 0,001277742. Entonces rechazamos \\(H_0\\) porque 8,56 &gt; 3.24 (o porque 0,001 &lt; 0,05), es decir, tenemos pruebas estadísticamente significativas con una confianza del 95% (\\(\\alpha\\)= 0.05) para concluir que existe una diferencia en la pérdida de peso promedio entre las cuatro dietas. Para realizar esta práctica, debe tener descargado en su ordenador el archivo 3.practicas.xlsx y abrir la hoja/pestaña correspondiente. En el siguente vídeo, además de la explicaciones teóricas, se muestran los pasos para realizar la práctica. 4.7.5 Prueba de Kruskal-Wallis Hemos visto técnicas para probar la igualdad de medias en más de dos muestras independientes utilizando análisis de varianza (ANOVA). Un supuesto subyacente para el uso apropiado de ANOVA es que el resultado continuo se distribuye aproximadamente de manera normal o que las muestras eran suficientemente grandes (generalmente \\(n_j\\) &gt; 30, donde j = 1, 2, …, k y k denota el número de grupos). Un supuesto adicional para el uso apropiado de ANOVA es la igualdad de varianzas en los k grupos de comparación. ANOVA es generalmente robusto cuando los tamaños de muestra son pequeños pero iguales. Cuando el resultado no se distribuye normalmente y las muestras son pequeñas, una prueba no paramétrica es apropiada. Una prueba no paramétrica popular para comparar resultados entre más de dos grupos independientes es la prueba de Kruskal Wallis. La prueba de Kruskal Wallis se usa para comparar medianas entre k grupos de comparación (k&gt; 2) y algunas veces se describe como un ANOVA con los datos reemplazados por sus rangos. Las hipótesis nula y de investigación para la prueba no paramétrica de Kruskal Wallis se exponen a continuación: \\(H_0\\): Las k medianas de la población son iguales \\(H_1\\): Las k medianas de población no son todas iguales El procedimiento para la prueba implica agrupar las observaciones de las k muestras en una muestra combinada, hacer un seguimiento de la muestra de cada observación y luego clasificar de 1 a N, con N = \\(n_1\\), \\(n_2\\), … , \\(n_k\\). Para ilustrar el procedimiento, vamos a considerar el siguiente ejemplo: Un estudio clínico está diseñado para evaluar las diferencias en los niveles de albúmina en adultos que siguen dietas con diferentes cantidades de proteínas. Las dietas bajas en proteínas a menudo se prescriben para pacientes con insuficiencia renal. La albúmina es la proteína más abundante en la sangre y su concentración en el suero se mide en gramos por decilitro (g / dL). Clínicamente, las concentraciones de albúmina sérica también se utilizan para evaluar si los pacientes obtienen suficiente proteína en sus dietas. Se comparan tres dietas, que varían de 5% a 15% de proteínas, y la dieta de 15% de proteínas representa una dieta típica estadounidense. Los niveles de albúmina de los participantes después de cada dieta se muestran a continuación. Parece que que hay una diferencia en los niveles de albúmina sérica entre los sujetos en las tres dietas diferentes. Como referencia, los niveles normales de albúmina están generalmente entre 3.4 y 5.4 g / dL. A simple vista, parece que los participantes que siguen la dieta con 15% de proteínas tienen niveles de albúmina más altos que los que siguen la dieta con 5% de proteínas. El problema es comprobar si esta diferencia observada es estadísticamente significativa. En este ejemplo, la variable es cuantitativa continua, pero los tamaños de muestra son pequeños y no son iguales entre los grupos de comparación (\\(n_1\\) = 3, \\(n_2\\) = 5, \\(n_3\\) = 4). Por lo tanto, una prueba no paramétrica es apropiada. Las hipótesis que se van a probar se dan a continuación y tomaremos un nivel de significación del 5% (\\(\\alpha\\) = 0.05). \\(H_0\\): las medianas de los grupos son iguales \\(H_1\\): al menos uno de los grupos tiene mediana distinta a las otras Para realizar la prueba, primero ordenamos los datos en la muestra total combinada de 12 sujetos, de menor a mayor y asignar los rangos correspondientes: Se observa que los rangos más bajos (por ejemplo, 1, 2.5, 4) se asignan al grupo de dieta con 5% de proteínas, mientras que los rangos más altos (por ejemplo, 10, 11 y 12) se asignan al grupo de dieta con 15% de proteínas. Nuevamente, el objetivo de la prueba es determinar si los datos observados apoyan una diferencia en las tres medianas de la población. Recuerde que en las pruebas paramétricas cuando comparamos medias entre más de dos grupos, analizamos la diferencia entre las medias muestrales (media cuadrada entre grupos) en relación con su variabilidad dentro del grupo y resumimos la información de la muestra en una prueba estadística (estadística F). En la prueba de Kruskal Wallis, nuevamente resumimos la información de la muestra en una estadística de prueba basada en los rangos. El estadístico de prueba para la prueba de Kruskal Wallis se denota H y se define como sigue: \\(H=\\left( \\frac{12}{N(N+1)}\\sum_{j=1}^k \\frac{R_j^2}{n_j}\\right) -3(N+1)\\) donde k es el número de grupos de comparación, N el tamaño total de la muestra, \\(n_j\\) es el tamaño de la muestra en el grupo j y R j es la suma de los rangos en el grupo j. En este ejemplo, \\(R_1\\) = 7.5, \\(R_2\\) = 30.5 y \\(R_3\\) = 40. Recuerde que la suma de los rangos siempre será igual a \\(\\frac{n(n-1)}{2}\\). El estadístico H para este ejemplo se calcula de la siguiente manera: \\(H=\\left( \\frac{12}{N(N+1)}\\sum_{j=1}^k \\frac{R_j^2}{n_j}\\right) -3(N+1)= \\frac{12}{12\\cdot 13}\\left( \\frac{7,5^2}{3}+\\frac{30,5^2}{5}+\\frac{40^2}{4}\\right) -3(13)=7.52\\) Ahora debemos determinar si el estadístico de prueba obtenido H respalda la hipótesis nula o de investigación. Una vez más, esto se hace estableciendo un valor crítico de H. Si el valor observado de H es mayor o igual al valor crítico, rechazamos \\(H_0\\) a favor de \\(H_1\\). Si el valor observado de H es menor que el valor crítico, no rechazamos \\(H_0\\) El valor crítico de H se puede encontrar en la siguiente tabla: Para determinar el valor crítico apropiado, al tener 3 observaciones con tamaños de muestra \\(n_1\\) = 3, \\(n_2\\) = 5 y \\(n_3\\)= 4 con un nivel de significación \\(\\alpha\\) = 0.05, buscamos en la fila 5, 4, 3 y la columna \\(\\alpha\\) = 0.05. Para este ejemplo, el valor crítico es 5,656. Por lo tanto rechazamos \\(H_0\\) porque 7,52 &gt; 5,656 y concluimos que al menos uno de los grupos tiene mediana distinta a las otras entre las tres dietas diferentes. Hay que tener en cuenta que la tabla contiene valores críticos para la prueba de Kruskal Wallis para pruebas que comparan 3, 4 o 5 grupos con tamaños de muestra pequeños. Si hay 3 o más grupos de comparación y 5 o más observaciones en cada uno de los grupos de comparación, se puede mostrar que el estadístico de prueba H se aproxima a una distribución chi-cuadrado con el número de grados de libertad df = k - 1. Por lo tanto, en una prueba de Kruskal Wallis con 3 o más grupos de comparación y 5 o más observaciones en cada grupo, el valor crítico para la prueba se puede encontrar en la tabla de Valores críticos de la distribución \\(\\chi^2\\) a continuación. Vamos a verlo con otro ejemplo ¿El ejercicio físico alivia la depresión? Realizamos un estudio con un grupo de personas deprimidas de manera equivalente. Luego asignamos a cada persona al azar a uno de tres grupos: sin ejercicio; 20 minutos de ejercicio físico por día o 60 minutos de ejercicio por día. Al final de un mes, le pedimos a cada participante que califique su grado de depresión en una escala Likert que va desde 1 (totalmente deprimido) hasta 100 (totalmente feliz) obteniendo los siguientes resultados: Parece que hay diferencias entre los 3 grupos: Para comprobar si hay diferencias estadísticamente significativas (α = 0.05), aplicamos la prueba de Kruskal-Wallis. Las hipótesis nula y de investigación para la prueba no paramétrica de Kruskal Wallis son: \\(H_0\\): las medianas de los grupos son iguales \\(H_1\\): al menos uno de los grupos tiene mediana distinta a las otras Establecemos el rango para cada medición: El estadístico de prueba para la prueba de Kruskal Wallis es: \\(H=\\left( \\frac{12}{N(N+1)}\\sum_{j=1}^k \\frac{R_j^2}{n_j}\\right) -3(N+1)\\) En este ejemplo, \\(R_1\\) = 77, \\(R_2\\) = 80.5 y \\(R_3\\) = 142,5 con 8 datos en cada grupo para un total de 24. Así, haciendo los cálculos, obtenemos: \\(H=\\left( \\frac{12}{N(N+1)}\\sum_{j=1}^k \\frac{R_j^2}{n_j}\\right) -3(N+1)= \\frac{24}{24\\cdot 25}\\left( \\frac{77^2}{8}+\\frac{80,5^2}{8}+\\frac{142,5^2}{8}\\right) -3(25)=6,78875\\) Como hemos comentado, en este segundo ejemplo usamos la tabla de la chi-cuadrado. Tenemos que los grados de libertad son igual al número de grupos menos uno, es decir 3 -1 = 2 grados de libertad (df). Entonces, en la tabla de la \\(\\chi^2\\) buscamos el valor crítico para 2 grados de libertad con un nivel de significación \\(\\alpha\\) = 0.05 obteniendo un valor \\(\\chi^2_{.0.05}\\) = 5,991. Comenzamos comparando nuestro H de 6,79 con 5.99. Con 2 grados de libertad, es probable que un valor de Chi-cuadrado tan grande como 5.99 ocurra por casualidad solo 5 veces en cien, es decir, tiene una p de 0,05. Nuestro valor obtenido de 6,79 es incluso mayor que esto, por lo que esto nos dice que nuestro valor de H es incluso menos probable que ocurra por casualidad. Nuestra H ocurrirá por casualidad con una probabilidad de menos de 0,05. Así, podemos concluir que la prueba de Kruskal-Wallis indica que hay un efecto significativo del ejercicio en los niveles de depresión (H = 6,79, p &lt; 0,05). Las medias de cada grupo sugieren que, en comparación con el grupo de control “sin ejercicio”, la depresión se redujo significativamente con 60 minutos de ejercicio diario, pero no con 20 minutos de ejercicio. Hay que tener en cuenta que una puntuación más alta en este estudio equivale a un nivel de ánimo más alto y, por lo tanto, un nivel de depresión más bajo). Sin utilizar la tabla, podríamos haber obtenido el valor p correspondiente a 6,79 con 2 grados de libertad utilizando la hoja de cálculo o la aplicación web: 4.7.6 Test de Student para muestras relacionadas Cuando se trata de comparar dos grupos de observaciones, es importante distinguir el caso en el que son independientes de aquel en el que los datos están apareados. Las series dependientes surgen normalmente cuando se evalúa un mismo dato más de una vez en cada sujeto de la muestra. También se puede encontrar este tipo de observaciones en estudios de casos y controles donde cada caso se aparea individualmente con un control. Así, podemos seleccionar una muestra aleatoria de n individuos a los que se les mide una variable numérica antes de iniciar un tratamiento para volver a medírsela después. En tal caso, no estaremos hablando de una variable sino de dos variables distintas, \\(X_1\\) y \\(X_2\\), medidas antes y después del tratamiento respectivamente, sobre una única población, sin distinguir categorías. Si el tratamiento es efectivo debe producirse una evolución, es decir, un cambio entre los valores de \\(X_1\\) y \\(X_2\\). No estamos en condiciones de exigir que ese cambio se dé en el mismo sentido para todos los individuos, pero sí al menos que se dé por término medio, de ahí que el problema se traduzca finalmente en una comparación entre las respectivas medias \\(\\mu_1\\) y \\(\\mu_2\\). Tomemos el siguiente ejemplo: en la siguiente tabla: tenemos el peso de 75 individuos antes y después de someterse a una dieta y queremos comprobar si realmente se produce una pérdida de peso significativa. Así, no interesa la variabilidad que puede haber entre los individuos sino en las diferencias que se observan en un mismo sujeto entre un momento y otro. Por este motivo, se establece como hipótesis: \\(H_0\\): La pérdida de peso es nula frente a la alternativa de que la pérdida de peso sea importante (es decir, distinta de cero). La veracidad de dicha hipótesis puede ser contrastada mediante el test t de Student. Este tipo de métodos tienen como hipótesis fundamental la normalidad de los datos. En este caso, sin embargo, no será necesario que las observaciones en ambos grupos provengan de poblaciones normales, sino que únicamente se requiere verificar la normalidad de su diferencia. Si representamos los datos mediante diagramas de cajas y bigotes: se observa una diferencia (descenso) entre los mismos. El estadístico de contrastedel t.test para muestras emparejadas es: \\(t=\\frac{\\overline{d}}{s_d}\\sqrt{n}\\) donde \\(\\overline{d}\\) denota la media de la pérdida de peso estimada a partir de la muestra, \\(s_d\\) es la cuasivarianza muestral de la diferencia y n el número de datos. Utilizando la Prueba t para medias de dos muestras emparejadas del análisis de datos de Excel©, obtenemos: Es decir, el valor del estadístico t obtenido es 18,645, muy superior a los valores críticos para una cola (1,6657) o para dos colas (1,9925) para una confianza del 95% (valor p &lt; 0,05) con valores p en ambos casos casi nulos (5\\(5,5\\cdot 10^{-30}\\) y \\(1,1\\cdot 10^{-29}\\) respectivamente). De este modo, podemos concluir que hay una pérdida de peso significativamente distinta de cero. 4.7.7 t-test emparejadas (Práctica) Para realizar esta práctica, debe tener descargado en su ordenador el archivo 3.practicas.xlsx y abrir la hoja/pestaña correspondiente. En el siguente vídeo, además de la explicaciones teóricas, se muestran los pasos para realizar la práctica. 4.7.8 Prueba de rangos con signo de Wilcoxon El test no paramétrico prueba de los rangos con signo de Wilcoxon (Wilcoxon signed-rank test), permite comparar poblaciones cuando sus distribuciones (normalmente interpretadas a partir de las muestras) no satisfacen las condiciones necesarias para otros test paramétricos. Es una alternativa a la prueba t de Student (t-test) para muestras dependientes cuando las muestras no siguen una distribución normal (muestran asimetría o colas) o cuando tienen un tamaño demasiado reducido para poder determinar si realmente proceden de poblaciones normales. Como condiciones para utilizar la prueba de rangos con signo de Wilcoxon tenemos: Los datos tienen que ser dependientes. Los datos tienen que ser ordinales, es decir, se tienen que poder ordenar de menor a mayor o viceversa. No es necesario asumir que las muestras se distribuyen de forma normal o que proceden de poblaciones normales pero sea cual sea el tipo de distribución de las diferencias, tiene que ser simétrica. A pesar de considerarse el equivalente no paramétrico del t-test, el Wilcoxon signed-rank test trabaja con medianas, no con medias. Preferible al t-test cuando hay valores atípicos, no hay normalidad de los datos o el tamaño de las muestras es pequeño. Vamos a trabajar con el siguiente ejemplo: se estudia la efectividad de un nuevo medicamento diseñado para reducir las conductas repetitivas en niños afectados con autismo. Un total de 8 niños con autismo se inscriben en el estudio y la cantidad de tiempo que cada niño está involucrado en un comportamiento repetitivo durante períodos de observación de tres horas se mide antes del tratamiento y luego nuevamente después de tomar la nueva medicación durante un período de 1 semana. Los datos se muestran a continuación. Ahora, calculamos las diferencias para cada paciente: El siguiente paso es ordenar de menor a mayor esas diferencias en valor absoluto, esto es, sin tener en cuenta el signo y asignarles un rango (un número de posición) siendo la posición 1 para el valor más pequeño. En caso de haber valores repetidos, fenómeno conocido como ligadura o ties, se les asigna como valor de posición la media de las posiciones que ocupan. En la asignación de posiciones se ignoran las diferencias que sean 0. Finalmente, se añade el signo (positivo o negativo) de las diferencias observadas a cada rango como se muestra a continuación. Las hipótesis para la prueba se refieren a la mediana de la población de las puntuaciones de diferencia. La hipótesis de investigación puede ser unilateral o bilateral (una cola o dos colas). Aquí consideramos una prueba unilateral con \\(\\alpha\\) = 0.05 y como hipótesis: \\(H_0\\): La diferencia de medianas es cero \\(H_1\\): La diferencia de medianas es positiva El estadístico de contraste para la prueba es W, definido como el menor de W+ (suma de los rangos positivos) y W- (valor absoluto de la suma de los rangos negativos). Si la hipótesis nula es cierta, esperamos ver números similares de rangos más altos y más bajos que sean positivos y negativos (es decir, W+ y W- serían similares). Si la hipótesis alternativa es cierta, esperamos ver rangos más altos y positivos (en este ejemplo, más niños con una mejora sustancial en el comportamiento repetitivo después del tratamiento en comparación con el anterior), es decir, W+ mucho más grande que W-). En nuestro ejemplo \\(W+ = 3 + 3 + 5 + 6 +7+8=32\\) y \\(W-=|-1-3|=4\\) por lo que el estadístico de contraste en nuestro ejemplo es el menor de esos valores, es decir, \\(W = 4\\). Ahora, debemos determinar si el estadístico de contraste obtenido W = 4 respalda la hipótesis nula o la alternativa. Así, determinamos un valor crítico de W tal que si el valor observado de W es menor o igual al valor crítico, rechazamos \\(H_0\\) a favor de \\(H_1\\) y, si el valor observado de W excede el valor crítico, no rechazamos \\(H_0\\). El valor crítico de W para dos colas se puede encontrar en la siguiente tabla: Para una prueba de una cola, se duplica el valor alfa (0,05·2 = 0,10) y se usa la misma tabla. De este modo, el valor crítico W para nuestro ejemplo (n = 8) es 5 y la regla de decisión es rechazar \\(H_0\\) si W &lt; 5. Por lo tanto, rechazamos \\(H_0\\) ya que 4 &lt; 5. Podemos concluir que, con los datos de la muestra, hay diferencias estadísticamente significativas que avalan la efectividad del nuevo medicamento diseñado para reducir las conductas repetitivas en niños afectados con autismo. Sin utilizar tablas, también podemos calcular tanto el valor del estadístico de contraste W como el valor p para la prueba con la aplicación web https://homepage.divms.uiowa.edu/~mbognar/applets/wilcoxon-signed-rank.html: Vemos un valor p = 0,027 &lt; 0,05 por lo que es estadísticamente significativo. Por lo tanto, tenemos evidencia estadísticamente significativa en \\(\\alpha\\) = 0.05, para mostrar que la mediana de la diferencia es positiva (es decir, que el medicamento mejora el comportamiento repetitivo). 4.7.9 Test de correlación r Hemos visto cómo calcular el coeficiente de correlación de Pearson (r) para 2 variables cuantitativas que nos indica el grado de relación lineal entre ambas variables. En Excel® se calcula con la función =COEF.DE.CORREL. En esta imagen, tenemos un ejemplo: Ahora, una vez calculado dicho coeficiente, debemos determinar si dicho coeficiente es estadísticamente diferente de cero, es decir, si las variables X e Y están relacionadas en realidad o tan solo presentan dicha relación como consecuencia del azar. Para dicho cálculo se aplica un test basado en la distribución de la t de student. El coeficiente de correlación de Pearson (r) puede calcularse en cualquier grupo de datos numéricos pero del test de hipótesis sobre la correlación entre las variables requiere: que las dos variables procedan de una muestra aleatoria de individuos. que al menos una de las variables tenga una distribución normal en la población Para el cálculo válido de un intervalo de confianza del coeficiente de correlación de r ambas variables deben tener una distribución normal. Si los datos no tienen una distribución normal, se calcularía un coeficiente de correlación no paramétrico (coeficiente de correlación de Spearman) que tiene el mismo significado que el coeficiente de correlación de Pearson y se calcula utilizando el rango de las observaciones. Se dice que el coeficiente de correlación es significativo si se puede afirmar, con una cierta probabilidad, que es diferente de cero. En términos estadísticos, preguntarse por la significación de un cierto coeficiente de correlación no es otra cosa que preguntarse por la probabilidad de que tal coeficiente proceda de una población cuyo valor sea de cero. Así, establecemos como hipótesis: \\(H_0\\): r = 0 (las variables no están relacionadas) \\(H_1\\) r \\(\\neq\\) 0 (las variables están relacionadas) Desde el supuesto de la Hipótesis nula se demuestra que la distribución muestral de correlaciones procedentes de una población caracterizada por una correlación igual a cero (r = 0) sigue una distribución t de Student con n - 2 grados de libertad de media el valor poblacional y desviación típica: \\(S=\\sqrt{\\frac{1-r^2}{n-2}}\\) Entonces, una vez calculado r se trata de comprobar si dicho coeficiente es posible que se encuentre dentro de la distribución muestral especificada por la Hipótesis nula. A efectos prácticos, se calcula el número de desviaciones tipo que se encuentra el coeficiente obtenido del centro de la distribución mediante el estadístico de contraste: \\(S=\\frac{r}{\\sqrt{\\frac{1-r^2}{n-2}}}\\) que se compara el valor crítico de la t de Student para un cierto nivel de significación α (confianza 95%) y n - 2 grados de libertad. En nuestro ejemplo: \\(S=\\frac{0,92}{\\sqrt{\\frac{1-0,92^2}{12-2}}}=7,42\\) Como el contraste es bilateral (\\(H_0\\): r = 0), el valor crítico asociado a una confianza del 95% para una t de Student con 2 colas con 12 - 2 = 10 grados de libertad es 2,63. Este valor se puede obtener de la tabla, con Excel® mediante la función =INV.T.2C(0,025;10) o con la aplicación web: Como el valor del estadístico de contraste obtenido S = 8,03 es mayor que el valor crítico 2,63, rechazamos la hipótesis nula (\\(H_0\\): r = 0) y podemos concluir que, con una confianza del 95%, las variables están relacionadas. Para terminar, tenemos que indicar que correlación no implica causalidad: Cuando se dice que la frase correlación no implica causalidad (en latín, Cum hoc ergo procter hoc ) es cierta lo que se quiere decir es que el hecho de que haya correlación entre dos variables no significa que una provoque a la otra, pero eso no significa que si encontramos correlación entre dos variables automáticamente podamos descartar que una sea causa de la otra. Hay casos en los que A es la causa de que ocurra B, en otros es al revés, en otros hay alguna variable adicional la que hace que se produzca esa correlación…y a veces todo es fruto de la casualidad (sí, casualidad, no «causalidad»). Fuente 4.7.10 Correlación de Spearman En el caso de que no se cumplan los supuestos para calcular el coeficiente de correlación r de Pearson, tenemos la alternativa no paramétrica del coeficiente de correlación de Spearman. En este caso, este coeficiente es una medida de asociación lineal que utiliza los rangos o números de orden, de cada grupo de sujetos y compara dichos rangos. El coeficiente de correlación de Spearman es recomendable utilizarlo cuando los datos presentan valores externos ya que dichos valores afectan mucho el coeficiente de correlación de Pearson, o ante distribuciones no normales. El coeficiente de correlación de Spearman viene dado por la fórmula: \\(R_S=1-\\frac{6\\sum d_i^2}{n(n^2-1)}\\) Donde \\(D_i=r_{X_i}-r_{Y_i}\\) es la diferencia entre los rangos de X e Y. Veamos un ejemplo: dos médicos evalúan la condición de ocho pacientes que sufren ciertos síntomas. Para ello, clasifican a los pacientes de 1 (mejor) a 8 (peor). Los resultados de los 8 pacientes se muestran en la siguiente imagen: Veamos ahora la correlación entre las valoraciones de los 2 médicos. En este caso, tenemos una variable cualitativa ordinal (escala de valoración) que no cumple con los criterios de normalidad para el cálculo del coeficiente de correlación de Pearson. Vamos pues a calcular el coeficiente de correlación de Spearman. En este ejemplo tenemos ya el rango para cada paciente (X: valoración del médico A, Y: valoración del médico B). Si no estuviese ordenado por rangos, en Excel® utilizaríamos la función =JERARQUIA.MEDIA(). Calculamos las diferencias d de rangos y los cuadrados de dichas diferencias \\(d^2\\) así como la suma de dichos cuadrados obteniendo un valor = 12. Entonces, el coeficiente de correlación de Spearman es: \\(R_S=1-\\frac{6\\sum d_i^2}{n(n^2-1)}= 1-\\frac{6\\cdot 12}{8(8^2-1)}=0.857\\) Como la interpretación del coeficiente \\(R_S\\) de Spearman es similar a la Pearson, el valor obtenido (0.857) indica que existe evidencia de un buen acuerdo entre las evaluaciones de los médicos. El cálculo de los intervalos de confianza de \\(R_S\\) se puede realizar utilizando la misma metodología previamente explicada para el coeficiente de correlación de Pearson. Como hipótesis, tendremos: \\(H_0\\): \\(R_S\\) = 0 (no hay acuerdo entre las valoraciones de los médicos) \\(H_1\\): \\(R_S\\) ≠ 0 (hay acuerdo entre las valoraciones de los médicos) El estadístico de contraste S es: \\(S=\\frac{R_S}{\\sqrt{\\frac{1-R_S^2}{n-2}}}\\) En nuestro ejemplo, tenemos que: \\(S==\\frac{0.857}{\\sqrt{\\frac{1-0.857^2}{8-2}}}=4.08\\) que nos da un valor p = 0.0065. Como el valor p &lt; 0.05, se concluye que, con una confianza del 95%, rechazamos la hipótesis nula y aceptamos que hay acuerdo entre las valoraciones de los médicos. 4.7.11 Prueba de la chi-cuadrado Cuando nos encontramos con datos o variables de tipo cualitativo mediante las cuales un grupo de individuos se clasifican en dos o más categorías mutuamente excluyentes, la prueba de la \\(\\chi^2\\) (chi cuadrado o ji-cuadrado) nos permite comprobar si hay diferencias estadísticamente significativas entre los grupos. Para aplicarlo, es necesario que las frecuencias esperadas de las distintas modalidades no sea inferior a cinco. Las proporciones son una forma habitual de expresar frecuencias cuando la variable objeto de estudio tiene dos posibles respuestas (sano/enfermo, etc.). Cuando lo que se pretende es comparar dos o más grupos de sujetos con respecto a una variable categórica, los resultados se presentan mediante tablas de doble entrada llamadas tablas de contingencia. Del mismo modo que los estadísticos “z”, con su distribución normal y “t”, con su distribución t de Student, nos han servido para someter a prueba hipótesis que involucran a promedios y porcentajes, el estadístico chi cuadrado, que tiene distribución de probabilidad del mismo nombre, nos servirá para someter a prueba hipótesis referidas a distribuciones de frecuencias. Consideramos el siguiente ejemplo: tenemos datos de 258 personas categorizadas por la variable colesterol, con tres grupos: bajo, medio y alto y la variable sexo, con dos grupos: hombre y mujer. La tabla de contingencia de los datos es: Si suponemos que las variables son independientes, calculamos la tabla de contingencia de los datos teóricos (o esperados si las variables son independientes). Para obtener el número de individuos esperado no hay más que multiplicar las frecuencias marginales y dividir el resultado por el número total de individuos: Así, comparando los diagramas de rectángulos asociados a las dos tablas contingencia (datos observados y datos teóricos): donde parece no haber diferencia por lo que parece que la variables sexo y colesterol son independientes. Vamos a comprobarlo mediante la prueba de la chi cuadrado si hay diferencia estadísticamente significativa entre ambos conjuntos de datos. Establecemos como hipótesis: \\(H_0\\): No hay asociación entre las variables (son independientes) \\(H_1\\): Sí hay asociación entre las variables Es decir, nuestra hipótesis nula implica que el sexo y el nivel de colesterol son independientes. El estadístico de contraste es: \\(\\chi^2=\\sum_{i=1}^r \\sum_{j=1}^k \\frac{(O_{ij}-E_{ij})^2}{E_{ij}}\\) Donde: \\(O_{ij}\\) son las frecuencias observadas. Es el número de casos observados clasificados en la fila i de la columna j. \\(E_{ij}\\) son las frecuencias esperadas o teóricas. Es el número de casos esperados correspondientes a cada fila y columna. Así, el estadístico \\(\\chi^2\\) mide la diferencia entre el valor que debiera resultar si las dos variables fuesen independientes y el que se ha observado en la realidad. Cuanto mayor sea esa diferencia (y, por lo tanto, el valor del estadístico), mayor será la relación entre ambas variables. El hecho de que las diferencias entre los valores observados y esperados estén elevadas al cuadrado convierte cualquier diferencia en positiva. La prueba χ 2 es un test no dirigido (test de 2 colas), que nos indica si existe o no relación entre dos factores pero no en qué sentido se produce tal asociación. En nuestro ejemplo, el valor del estadístico \\(\\chi^2\\) es: \\(\\chi^2=\\frac{(115-103.5)^2}{103.5}+\\frac{(23-32)^2}{32}+\\frac{(21-23.4)^2}{23.4}+ \\frac{(53-64.5)^2}{64.5}+\\frac{(29-20)^2}{20}+\\frac{(17-14.6)^2}{14.6}=10.61\\) Ahora, debemos comparar el valor obtenido con el valor crítico de \\(\\chi^2\\) . Se sabe que bajo la hipótesis nula de independencia, los valores del estadístico \\(\\chi^2\\) se distribuyen según una distribución conocida denominada ji-cuadrado, que depende de un parámetro llamado “grados de libertad” (df). Para el caso de una tabla de contingencia de r filas y k columnas, los df son igual al producto del número de filas menos 1 (r-1) por el número de columnas menos 1 (k-1). Así, en nuestro ejemplo, el número de filas es 2 y el de columnas 3 por lo que los grados de libertad son 2 ((2 - 1)·(3 - 1) = 1·2 = 2). Si utilizamos la tabla de valores críticos de la distribución \\(\\chi^2\\) vemos que el valor crítico asociado a 2 grados de libertad y una confianza del 95% (valor p &lt; 0,05) es 5.991. En nuestro ejemplo, el valor del estadístico obtenido era 10.61. Como 10.61 &gt; 5.991 rechazamos la hipótesis nula \\(H_0\\) y aceptamos la hipótesis alternativa \\(H_1\\).como probablemente cierta y tenemos que concluir que, a la vista de los resultados, las dos variables no son independientes, sino que están asociadasa, es decir, que con los datos de la muestra, las variables sexo y nivel de colesterol están relacionadas. Otra forma de comprobar el contraste de hipótesis es con Excel© que nos calcula directamente el valor p mediante la función PRUEBA.CHICUAD: Así vemos que el valor p obtenido es 0.00495 &lt; 0,05 por lo que, evidentemente, llegaríamos a la misma conclusión. 4.7.12 Prueba \\(\\chi^2\\) (Práctica) Para realizar esta práctica, debe tener descargado en su ordenador el archivo 3.practicas.xlsx y abrir la hoja/pestaña correspondiente. En el siguente vídeo se muestran los pasos para realizar la práctica. 4.7.13 Prueba exacta de Fisher La prueba o test exacto de Fisher permite analizar si dos variables dicotómicas están asociadas cuando la muestra a estudiar es demasiado pequeña y no se cumplen las condiciones necesarias para que la aplicación del test \\(\\chi^2\\) sea adecuada. Estas condiciones exigían que los valoresesperados de al menos el 80% de las celdas en una tabla de contingencia fuesen mayores de 5. En la gran mayoría de casos, el test de Fisher se aplica para comparar dos variables categóricas con dos niveles cada una (tabla 2x2). A diferencia de la mayoría de las pruebas estadísticas, la prueba exacta de Fisher no usa una función matemática que estima la probabilidad de un valor de una estadística de prueba sino que calcula la probabilidad de obtener los datos observados y todos los conjuntos de datos con desviaciones más extremas, bajo la hipótesis nula de que las proporciones son las mismas. Vamos a considerar el siguiente ejemplo tomado de Nood et al. (2013). Se estudiaron pacientes con infecciones por Clostridium difficile, que causan diarrea persistente. Una variable nominal fue el tratamiento: a algunos pacientes se les administró el antibiótico vancomicina y a algunos pacientes se les realizó un trasplante fecal. La otra variable nominal fue el resultado: cada paciente se curó o no se curó. El porcentaje de personas que recibieron un trasplante fecal y se curaron (13 de 16 o el 81%) es mayor que el porcentaje de personas que recibieron vancomicina y se curaron (4 de 13 o 31%), lo que parece prometedor, Pero los tamaños de muestra parecen un poco pequeños. La prueba exacta de Fisher nos dirá si esta diferencia entre 81 y 31% es estadísticamente significativa. Los datos del estudio se muestran en la siguiente tabla: La hipótesis nula es que las proporciones relativas de una variable son independientes de la segunda variable; en otras palabras, las proporciones en una variable son las mismas para diferentes valores de la segunda variable. En nuestro ejemplo, la hipótesis nula es que la probabilidad de curarse es la misma si se recibe un trasplante fecal o vancomicina. El test exacto de Fisher se basa en evaluar la probabilidad asociada a cada una de las tablas 2 x 2 que se pueden formar manteniendo los mismos totales de filas y columnas que los de la tabla observada. Cada una de estas probabilidades se obtiene bajo la hipótesis nula de independencia de las dos variables que se están considerando. La probabilidad exacta de observar un conjunto concreto de frecuencias a, b, c y d en una tabla 2 x 2 cuando se asume independencia y los totales de filas y columnas se consideran fijos viene dada por la distribución hipergeométrica: \\(p=\\frac{(a+b)!~ (c+d)!~ (a+c)!~ (b+d)!}{n!~ a!~ b!~ c!~ d!}\\) Esta fórmula se obtiene calculando todas las posibles formas en las que podemos disponer n sujetos en una tabla 2 x 2 de modo que los totales de filas y columnas sean siempre los mismos, (a+b), (c+d), (a+c) y (b+d). Así, en nuestro ejemplo, la probabilidad asociada a los datos que han sido observados es: \\(p=\\frac{12!~ 17!~ 16!~ 13!}{29!~ 3!~ 9!~ 13!~ 4!}=0.007715441\\) Con Excel© no es muy complicado obtener dicho valor: Ahora, hacemos lo mismo con todas las posibles combinaciones de frecuencias que se podrían obtener con los mismos totales marginales. El valor de la p asociado al test exacto de Fisher puede entonces calcularse sumando las probabilidades de las tablas que resultan ser menores o iguales a la probabilidad de la tabla que ha sido observada, 0,0077 en nuestro ejemplo. Vemos que las probabilidades menores que ese valor corresponden a valores de Enfermos con transplante de 0, 1, 2, 11 y 12. Sumando esas 5 probabilidades a la probabilidad asociada a los datos que han sido observados: \\(p=0.007715441+0.000661+2.4E-05+2.51E-07+0.001094+3,51E-05=0.009530323\\) obtenemos un valor p de 0.009530323 que es menor que 0,05 lo que indica que aceptamos la hipótesis alternativa de que la probabilidad de curarse no es la misma si se recibe un trasplante fecal o vancomicina como habíamos intuido. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
